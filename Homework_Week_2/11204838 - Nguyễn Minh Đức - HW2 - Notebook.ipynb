{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irpeXYa4yd0O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bài 1:\n",
        "\n",
        "Cho bài toán XOR\n",
        "\n",
        "Implement thuật toán neural network để giải bài toán dùng Pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-7Q-m-lyd0P"
      },
      "outputs": [],
      "source": [
        "  class XORDataset(Dataset):\n",
        "    def __init__(self, size= 100):\n",
        "        super().__init__()\n",
        "        self.size = size\n",
        "        self.generate_continuous_xor()\n",
        "\n",
        "    def generate_continuous_xor(self):\n",
        "        data = torch.randint(low= 0, high= 2, size=(self.size, 2), dtype=torch.float32)\n",
        "        label = (data.sum(dim=1) == 1).to(torch.float32)\n",
        "        data += 0.1 * torch.randn(data.shape)\n",
        "\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_point = self.data[idx]\n",
        "        data_label = self.label[idx]\n",
        "        return data_point, data_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8iz1Yy5yd0Q"
      },
      "outputs": [],
      "source": [
        "dataset = XORDataset(size=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "F5LmGBGmyd0S",
        "outputId": "a84acab1-460c-4dfc-c956-b8a196fd9956"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7850d4849810>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data = dataset.data.numpy()\n",
        "label = dataset.label.numpy()\n",
        "data_0 = data[label == 0]\n",
        "data_1 = data[label == 1]\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "plt.title(\"Dataset samples\")\n",
        "plt.ylabel(r\"$x_2$\")\n",
        "plt.xlabel(r\"$x_1$\")\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POfN1bDDyd0T"
      },
      "outputs": [],
      "source": [
        "data_loader = DataLoader(dataset, batch_size= 16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DrmreUtyd0T"
      },
      "outputs": [],
      "source": [
        "class Neural_Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Neural_Network, self).__init__()\n",
        "        self.linear1 = nn.Linear(2, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKhZBFqQyd0T"
      },
      "outputs": [],
      "source": [
        "model = Neural_Network()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib1tvG5Vyd0V",
        "outputId": "c308ad66-8d9b-4cd5-d653-314df3bea295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 1.6044\n",
            "Epoch [20/100], Loss: 1.4549\n",
            "Epoch [30/100], Loss: 5.5472\n",
            "Epoch [40/100], Loss: 1.4778\n",
            "Epoch [50/100], Loss: 3.3548\n",
            "Epoch [60/100], Loss: 1.6473\n",
            "Epoch [70/100], Loss: 3.4198\n",
            "Epoch [80/100], Loss: 0.0546\n",
            "Epoch [90/100], Loss: 1.4189\n",
            "Epoch [100/100], Loss: 0.0305\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= 0.01)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    for data_inputs, data_labels in data_loader:\n",
        "        preds = model(data_inputs)\n",
        "        preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "\n",
        "        loss = criterion(preds, data_labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bài 2: \n",
        "\n",
        "Cho dataset MNIST\n",
        "\n",
        "Implement thuật toán neural network với dữ liệu trên sử dụng Pytorch\n",
        "\n",
        "Chỉnh learning rate, vẽ đồ thị loss tương ứng.\n",
        "\n",
        "Chia tập train/test tỉ lệ 80/20, tính các chỉ số MSE, RSME, MAE, MAPE trên tập test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjniMNAuyd0W",
        "outputId": "0179d8b8-36c9-4528-c0e4-ab34ac51132c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 129364193.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 44650089.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 35103553.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 21747178.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                            train=True,\n",
        "                                            transform= torchvision.transforms.ToTensor() ,download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                            train=False,\n",
        "                                            transform= torchvision.transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mzw2LL1uyd0Z"
      },
      "outputs": [],
      "source": [
        "class MNIST_Neural_Network(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MNIST_Neural_Network, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doU3BdRJyd0Z"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 200\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do3Bi3GEpFgJ"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "\n",
        "# Use random_split to split the dataset\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders for the training and validation sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsWiNCGFyd0a",
        "outputId": "c1905ec1-5f3f-48c1-ddbb-df0fb71cfd60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/200], Batch [100/750], Loss: 2.2894\n",
            "Epoch [1/200], Batch [200/750], Loss: 2.2607\n",
            "Epoch [1/200], Batch [300/750], Loss: 2.2504\n",
            "Epoch [1/200], Batch [400/750], Loss: 2.2147\n",
            "Epoch [1/200], Batch [500/750], Loss: 2.2002\n",
            "Epoch [1/200], Batch [600/750], Loss: 2.1719\n",
            "Epoch [1/200], Batch [700/750], Loss: 2.1577\n",
            "Epoch [1/200] Total train Cost: 1672.1589181423187\n",
            "---------------------------------------------\n",
            "Epoch [2/200], Batch [100/750], Loss: 2.0974\n",
            "Epoch [2/200], Batch [200/750], Loss: 2.0930\n",
            "Epoch [2/200], Batch [300/750], Loss: 2.0578\n",
            "Epoch [2/200], Batch [400/750], Loss: 2.0316\n",
            "Epoch [2/200], Batch [500/750], Loss: 2.0418\n",
            "Epoch [2/200], Batch [600/750], Loss: 1.9430\n",
            "Epoch [2/200], Batch [700/750], Loss: 1.9123\n",
            "Epoch [2/200] Total train Cost: 1524.2840538024902\n",
            "---------------------------------------------\n",
            "Epoch [3/200], Batch [100/750], Loss: 1.8903\n",
            "Epoch [3/200], Batch [200/750], Loss: 1.8827\n",
            "Epoch [3/200], Batch [300/750], Loss: 1.8707\n",
            "Epoch [3/200], Batch [400/750], Loss: 1.7600\n",
            "Epoch [3/200], Batch [500/750], Loss: 1.7416\n",
            "Epoch [3/200], Batch [600/750], Loss: 1.6404\n",
            "Epoch [3/200], Batch [700/750], Loss: 1.6775\n",
            "Epoch [3/200] Total train Cost: 1343.4131124019623\n",
            "---------------------------------------------\n",
            "Epoch [4/200], Batch [100/750], Loss: 1.6965\n",
            "Epoch [4/200], Batch [200/750], Loss: 1.5983\n",
            "Epoch [4/200], Batch [300/750], Loss: 1.5589\n",
            "Epoch [4/200], Batch [400/750], Loss: 1.4429\n",
            "Epoch [4/200], Batch [500/750], Loss: 1.4492\n",
            "Epoch [4/200], Batch [600/750], Loss: 1.4444\n",
            "Epoch [4/200], Batch [700/750], Loss: 1.4502\n",
            "Epoch [4/200] Total train Cost: 1144.4402836561203\n",
            "---------------------------------------------\n",
            "Epoch [5/200], Batch [100/750], Loss: 1.3000\n",
            "Epoch [5/200], Batch [200/750], Loss: 1.4460\n",
            "Epoch [5/200], Batch [300/750], Loss: 1.2408\n",
            "Epoch [5/200], Batch [400/750], Loss: 1.3626\n",
            "Epoch [5/200], Batch [500/750], Loss: 1.2440\n",
            "Epoch [5/200], Batch [600/750], Loss: 1.2176\n",
            "Epoch [5/200], Batch [700/750], Loss: 1.1775\n",
            "Epoch [5/200] Total train Cost: 961.600624024868\n",
            "---------------------------------------------\n",
            "Epoch [6/200], Batch [100/750], Loss: 1.1491\n",
            "Epoch [6/200], Batch [200/750], Loss: 0.9850\n",
            "Epoch [6/200], Batch [300/750], Loss: 1.1349\n",
            "Epoch [6/200], Batch [400/750], Loss: 1.2388\n",
            "Epoch [6/200], Batch [500/750], Loss: 1.0009\n",
            "Epoch [6/200], Batch [600/750], Loss: 0.9363\n",
            "Epoch [6/200], Batch [700/750], Loss: 1.0032\n",
            "Epoch [6/200] Total train Cost: 816.103445649147\n",
            "---------------------------------------------\n",
            "Epoch [7/200], Batch [100/750], Loss: 0.9081\n",
            "Epoch [7/200], Batch [200/750], Loss: 0.8946\n",
            "Epoch [7/200], Batch [300/750], Loss: 0.9984\n",
            "Epoch [7/200], Batch [400/750], Loss: 0.9385\n",
            "Epoch [7/200], Batch [500/750], Loss: 0.8951\n",
            "Epoch [7/200], Batch [600/750], Loss: 1.0718\n",
            "Epoch [7/200], Batch [700/750], Loss: 0.8526\n",
            "Epoch [7/200] Total train Cost: 708.0654987692833\n",
            "---------------------------------------------\n",
            "Epoch [8/200], Batch [100/750], Loss: 0.7466\n",
            "Epoch [8/200], Batch [200/750], Loss: 0.8182\n",
            "Epoch [8/200], Batch [300/750], Loss: 0.8937\n",
            "Epoch [8/200], Batch [400/750], Loss: 0.8554\n",
            "Epoch [8/200], Batch [500/750], Loss: 0.8045\n",
            "Epoch [8/200], Batch [600/750], Loss: 0.9185\n",
            "Epoch [8/200], Batch [700/750], Loss: 0.7585\n",
            "Epoch [8/200] Total train Cost: 628.7299156785011\n",
            "---------------------------------------------\n",
            "Epoch [9/200], Batch [100/750], Loss: 0.8759\n",
            "Epoch [9/200], Batch [200/750], Loss: 0.7384\n",
            "Epoch [9/200], Batch [300/750], Loss: 0.8968\n",
            "Epoch [9/200], Batch [400/750], Loss: 0.7787\n",
            "Epoch [9/200], Batch [500/750], Loss: 0.7979\n",
            "Epoch [9/200], Batch [600/750], Loss: 0.7579\n",
            "Epoch [9/200], Batch [700/750], Loss: 0.6821\n",
            "Epoch [9/200] Total train Cost: 569.4364153146744\n",
            "---------------------------------------------\n",
            "Epoch [10/200], Batch [100/750], Loss: 0.6629\n",
            "Epoch [10/200], Batch [200/750], Loss: 0.6166\n",
            "Epoch [10/200], Batch [300/750], Loss: 0.7227\n",
            "Epoch [10/200], Batch [400/750], Loss: 0.4937\n",
            "Epoch [10/200], Batch [500/750], Loss: 0.6823\n",
            "Epoch [10/200], Batch [600/750], Loss: 0.5051\n",
            "Epoch [10/200], Batch [700/750], Loss: 0.6012\n",
            "Epoch [10/200] Total train Cost: 523.9399082958698\n",
            "---------------------------------------------\n",
            "Epoch [11/200], Batch [100/750], Loss: 0.4821\n",
            "Epoch [11/200], Batch [200/750], Loss: 0.6783\n",
            "Epoch [11/200], Batch [300/750], Loss: 0.5862\n",
            "Epoch [11/200], Batch [400/750], Loss: 0.6097\n",
            "Epoch [11/200], Batch [500/750], Loss: 0.7134\n",
            "Epoch [11/200], Batch [600/750], Loss: 0.5897\n",
            "Epoch [11/200], Batch [700/750], Loss: 0.7610\n",
            "Epoch [11/200] Total train Cost: 488.1536822915077\n",
            "---------------------------------------------\n",
            "Epoch [12/200], Batch [100/750], Loss: 0.5718\n",
            "Epoch [12/200], Batch [200/750], Loss: 0.6166\n",
            "Epoch [12/200], Batch [300/750], Loss: 0.7755\n",
            "Epoch [12/200], Batch [400/750], Loss: 0.5880\n",
            "Epoch [12/200], Batch [500/750], Loss: 0.5910\n",
            "Epoch [12/200], Batch [600/750], Loss: 0.5271\n",
            "Epoch [12/200], Batch [700/750], Loss: 0.5209\n",
            "Epoch [12/200] Total train Cost: 459.279454767704\n",
            "---------------------------------------------\n",
            "Epoch [13/200], Batch [100/750], Loss: 0.6204\n",
            "Epoch [13/200], Batch [200/750], Loss: 0.6118\n",
            "Epoch [13/200], Batch [300/750], Loss: 0.6301\n",
            "Epoch [13/200], Batch [400/750], Loss: 0.5564\n",
            "Epoch [13/200], Batch [500/750], Loss: 0.5338\n",
            "Epoch [13/200], Batch [600/750], Loss: 0.5234\n",
            "Epoch [13/200], Batch [700/750], Loss: 0.5032\n",
            "Epoch [13/200] Total train Cost: 435.57937747240067\n",
            "---------------------------------------------\n",
            "Epoch [14/200], Batch [100/750], Loss: 0.7279\n",
            "Epoch [14/200], Batch [200/750], Loss: 0.5291\n",
            "Epoch [14/200], Batch [300/750], Loss: 0.5136\n",
            "Epoch [14/200], Batch [400/750], Loss: 0.4853\n",
            "Epoch [14/200], Batch [500/750], Loss: 0.5125\n",
            "Epoch [14/200], Batch [600/750], Loss: 0.4595\n",
            "Epoch [14/200], Batch [700/750], Loss: 0.4924\n",
            "Epoch [14/200] Total train Cost: 415.75225844979286\n",
            "---------------------------------------------\n",
            "Epoch [15/200], Batch [100/750], Loss: 0.5345\n",
            "Epoch [15/200], Batch [200/750], Loss: 0.4936\n",
            "Epoch [15/200], Batch [300/750], Loss: 0.5939\n",
            "Epoch [15/200], Batch [400/750], Loss: 0.5491\n",
            "Epoch [15/200], Batch [500/750], Loss: 0.4327\n",
            "Epoch [15/200], Batch [600/750], Loss: 0.5759\n",
            "Epoch [15/200], Batch [700/750], Loss: 0.5973\n",
            "Epoch [15/200] Total train Cost: 398.96372443437576\n",
            "---------------------------------------------\n",
            "Epoch [16/200], Batch [100/750], Loss: 0.5454\n",
            "Epoch [16/200], Batch [200/750], Loss: 0.4881\n",
            "Epoch [16/200], Batch [300/750], Loss: 0.5336\n",
            "Epoch [16/200], Batch [400/750], Loss: 0.6265\n",
            "Epoch [16/200], Batch [500/750], Loss: 0.4490\n",
            "Epoch [16/200], Batch [600/750], Loss: 0.4906\n",
            "Epoch [16/200], Batch [700/750], Loss: 0.7908\n",
            "Epoch [16/200] Total train Cost: 384.548228174448\n",
            "---------------------------------------------\n",
            "Epoch [17/200], Batch [100/750], Loss: 0.5968\n",
            "Epoch [17/200], Batch [200/750], Loss: 0.3686\n",
            "Epoch [17/200], Batch [300/750], Loss: 0.6840\n",
            "Epoch [17/200], Batch [400/750], Loss: 0.5431\n",
            "Epoch [17/200], Batch [500/750], Loss: 0.4914\n",
            "Epoch [17/200], Batch [600/750], Loss: 0.3929\n",
            "Epoch [17/200], Batch [700/750], Loss: 0.4724\n",
            "Epoch [17/200] Total train Cost: 372.0200856924057\n",
            "---------------------------------------------\n",
            "Epoch [18/200], Batch [100/750], Loss: 0.3598\n",
            "Epoch [18/200], Batch [200/750], Loss: 0.5496\n",
            "Epoch [18/200], Batch [300/750], Loss: 0.4648\n",
            "Epoch [18/200], Batch [400/750], Loss: 0.3864\n",
            "Epoch [18/200], Batch [500/750], Loss: 0.6285\n",
            "Epoch [18/200], Batch [600/750], Loss: 0.5307\n",
            "Epoch [18/200], Batch [700/750], Loss: 0.4210\n",
            "Epoch [18/200] Total train Cost: 361.0647213310003\n",
            "---------------------------------------------\n",
            "Epoch [19/200], Batch [100/750], Loss: 0.6101\n",
            "Epoch [19/200], Batch [200/750], Loss: 0.4322\n",
            "Epoch [19/200], Batch [300/750], Loss: 0.5143\n",
            "Epoch [19/200], Batch [400/750], Loss: 0.5669\n",
            "Epoch [19/200], Batch [500/750], Loss: 0.4343\n",
            "Epoch [19/200], Batch [600/750], Loss: 0.6639\n",
            "Epoch [19/200], Batch [700/750], Loss: 0.4824\n",
            "Epoch [19/200] Total train Cost: 351.4123717099428\n",
            "---------------------------------------------\n",
            "Epoch [20/200], Batch [100/750], Loss: 0.5612\n",
            "Epoch [20/200], Batch [200/750], Loss: 0.5197\n",
            "Epoch [20/200], Batch [300/750], Loss: 0.2884\n",
            "Epoch [20/200], Batch [400/750], Loss: 0.4415\n",
            "Epoch [20/200], Batch [500/750], Loss: 0.4755\n",
            "Epoch [20/200], Batch [600/750], Loss: 0.4207\n",
            "Epoch [20/200], Batch [700/750], Loss: 0.4872\n",
            "Epoch [20/200] Total train Cost: 342.8057274520397\n",
            "---------------------------------------------\n",
            "Epoch [21/200], Batch [100/750], Loss: 0.4773\n",
            "Epoch [21/200], Batch [200/750], Loss: 0.3763\n",
            "Epoch [21/200], Batch [300/750], Loss: 0.3364\n",
            "Epoch [21/200], Batch [400/750], Loss: 0.3843\n",
            "Epoch [21/200], Batch [500/750], Loss: 0.4525\n",
            "Epoch [21/200], Batch [600/750], Loss: 0.3152\n",
            "Epoch [21/200], Batch [700/750], Loss: 0.6127\n",
            "Epoch [21/200] Total train Cost: 335.11073188483715\n",
            "---------------------------------------------\n",
            "Epoch [22/200], Batch [100/750], Loss: 0.4692\n",
            "Epoch [22/200], Batch [200/750], Loss: 0.4657\n",
            "Epoch [22/200], Batch [300/750], Loss: 0.5162\n",
            "Epoch [22/200], Batch [400/750], Loss: 0.4110\n",
            "Epoch [22/200], Batch [500/750], Loss: 0.4272\n",
            "Epoch [22/200], Batch [600/750], Loss: 0.4892\n",
            "Epoch [22/200], Batch [700/750], Loss: 0.3866\n",
            "Epoch [22/200] Total train Cost: 328.17247918248177\n",
            "---------------------------------------------\n",
            "Epoch [23/200], Batch [100/750], Loss: 0.5919\n",
            "Epoch [23/200], Batch [200/750], Loss: 0.3350\n",
            "Epoch [23/200], Batch [300/750], Loss: 0.2974\n",
            "Epoch [23/200], Batch [400/750], Loss: 0.4321\n",
            "Epoch [23/200], Batch [500/750], Loss: 0.3641\n",
            "Epoch [23/200], Batch [600/750], Loss: 0.3767\n",
            "Epoch [23/200], Batch [700/750], Loss: 0.3523\n",
            "Epoch [23/200] Total train Cost: 321.89472280442715\n",
            "---------------------------------------------\n",
            "Epoch [24/200], Batch [100/750], Loss: 0.3527\n",
            "Epoch [24/200], Batch [200/750], Loss: 0.5042\n",
            "Epoch [24/200], Batch [300/750], Loss: 0.4776\n",
            "Epoch [24/200], Batch [400/750], Loss: 0.5388\n",
            "Epoch [24/200], Batch [500/750], Loss: 0.4864\n",
            "Epoch [24/200], Batch [600/750], Loss: 0.3051\n",
            "Epoch [24/200], Batch [700/750], Loss: 0.4868\n",
            "Epoch [24/200] Total train Cost: 316.12717458605766\n",
            "---------------------------------------------\n",
            "Epoch [25/200], Batch [100/750], Loss: 0.4554\n",
            "Epoch [25/200], Batch [200/750], Loss: 0.5451\n",
            "Epoch [25/200], Batch [300/750], Loss: 0.4548\n",
            "Epoch [25/200], Batch [400/750], Loss: 0.3462\n",
            "Epoch [25/200], Batch [500/750], Loss: 0.3551\n",
            "Epoch [25/200], Batch [600/750], Loss: 0.4114\n",
            "Epoch [25/200], Batch [700/750], Loss: 0.3909\n",
            "Epoch [25/200] Total train Cost: 310.9414406865835\n",
            "---------------------------------------------\n",
            "Epoch [26/200], Batch [100/750], Loss: 0.2960\n",
            "Epoch [26/200], Batch [200/750], Loss: 0.3309\n",
            "Epoch [26/200], Batch [300/750], Loss: 0.3039\n",
            "Epoch [26/200], Batch [400/750], Loss: 0.3760\n",
            "Epoch [26/200], Batch [500/750], Loss: 0.4179\n",
            "Epoch [26/200], Batch [600/750], Loss: 0.6013\n",
            "Epoch [26/200], Batch [700/750], Loss: 0.3187\n",
            "Epoch [26/200] Total train Cost: 306.06577402353287\n",
            "---------------------------------------------\n",
            "Epoch [27/200], Batch [100/750], Loss: 0.3125\n",
            "Epoch [27/200], Batch [200/750], Loss: 0.3856\n",
            "Epoch [27/200], Batch [300/750], Loss: 0.4977\n",
            "Epoch [27/200], Batch [400/750], Loss: 0.3954\n",
            "Epoch [27/200], Batch [500/750], Loss: 0.3730\n",
            "Epoch [27/200], Batch [600/750], Loss: 0.6245\n",
            "Epoch [27/200], Batch [700/750], Loss: 0.3584\n",
            "Epoch [27/200] Total train Cost: 301.6596632897854\n",
            "---------------------------------------------\n",
            "Epoch [28/200], Batch [100/750], Loss: 0.2715\n",
            "Epoch [28/200], Batch [200/750], Loss: 0.4622\n",
            "Epoch [28/200], Batch [300/750], Loss: 0.4483\n",
            "Epoch [28/200], Batch [400/750], Loss: 0.2662\n",
            "Epoch [28/200], Batch [500/750], Loss: 0.4259\n",
            "Epoch [28/200], Batch [600/750], Loss: 0.4107\n",
            "Epoch [28/200], Batch [700/750], Loss: 0.3204\n",
            "Epoch [28/200] Total train Cost: 297.53377318382263\n",
            "---------------------------------------------\n",
            "Epoch [29/200], Batch [100/750], Loss: 0.3061\n",
            "Epoch [29/200], Batch [200/750], Loss: 0.4375\n",
            "Epoch [29/200], Batch [300/750], Loss: 0.3763\n",
            "Epoch [29/200], Batch [400/750], Loss: 0.5041\n",
            "Epoch [29/200], Batch [500/750], Loss: 0.5315\n",
            "Epoch [29/200], Batch [600/750], Loss: 0.3305\n",
            "Epoch [29/200], Batch [700/750], Loss: 0.3365\n",
            "Epoch [29/200] Total train Cost: 293.6795559376478\n",
            "---------------------------------------------\n",
            "Epoch [30/200], Batch [100/750], Loss: 0.3873\n",
            "Epoch [30/200], Batch [200/750], Loss: 0.2711\n",
            "Epoch [30/200], Batch [300/750], Loss: 0.2702\n",
            "Epoch [30/200], Batch [400/750], Loss: 0.3504\n",
            "Epoch [30/200], Batch [500/750], Loss: 0.2474\n",
            "Epoch [30/200], Batch [600/750], Loss: 0.2845\n",
            "Epoch [30/200], Batch [700/750], Loss: 0.5387\n",
            "Epoch [30/200] Total train Cost: 290.09538672864437\n",
            "---------------------------------------------\n",
            "Epoch [31/200], Batch [100/750], Loss: 0.3880\n",
            "Epoch [31/200], Batch [200/750], Loss: 0.3155\n",
            "Epoch [31/200], Batch [300/750], Loss: 0.4706\n",
            "Epoch [31/200], Batch [400/750], Loss: 0.4365\n",
            "Epoch [31/200], Batch [500/750], Loss: 0.3959\n",
            "Epoch [31/200], Batch [600/750], Loss: 0.2658\n",
            "Epoch [31/200], Batch [700/750], Loss: 0.3337\n",
            "Epoch [31/200] Total train Cost: 286.72890996932983\n",
            "---------------------------------------------\n",
            "Epoch [32/200], Batch [100/750], Loss: 0.3607\n",
            "Epoch [32/200], Batch [200/750], Loss: 0.3504\n",
            "Epoch [32/200], Batch [300/750], Loss: 0.3830\n",
            "Epoch [32/200], Batch [400/750], Loss: 0.3793\n",
            "Epoch [32/200], Batch [500/750], Loss: 0.4080\n",
            "Epoch [32/200], Batch [600/750], Loss: 0.4313\n",
            "Epoch [32/200], Batch [700/750], Loss: 0.3657\n",
            "Epoch [32/200] Total train Cost: 283.5925064980984\n",
            "---------------------------------------------\n",
            "Epoch [33/200], Batch [100/750], Loss: 0.6574\n",
            "Epoch [33/200], Batch [200/750], Loss: 0.3571\n",
            "Epoch [33/200], Batch [300/750], Loss: 0.4679\n",
            "Epoch [33/200], Batch [400/750], Loss: 0.4768\n",
            "Epoch [33/200], Batch [500/750], Loss: 0.2928\n",
            "Epoch [33/200], Batch [600/750], Loss: 0.5546\n",
            "Epoch [33/200], Batch [700/750], Loss: 0.3533\n",
            "Epoch [33/200] Total train Cost: 280.59920659661293\n",
            "---------------------------------------------\n",
            "Epoch [34/200], Batch [100/750], Loss: 0.2405\n",
            "Epoch [34/200], Batch [200/750], Loss: 0.3067\n",
            "Epoch [34/200], Batch [300/750], Loss: 0.4067\n",
            "Epoch [34/200], Batch [400/750], Loss: 0.2895\n",
            "Epoch [34/200], Batch [500/750], Loss: 0.3939\n",
            "Epoch [34/200], Batch [600/750], Loss: 0.3335\n",
            "Epoch [34/200], Batch [700/750], Loss: 0.4325\n",
            "Epoch [34/200] Total train Cost: 277.7975421845913\n",
            "---------------------------------------------\n",
            "Epoch [35/200], Batch [100/750], Loss: 0.2882\n",
            "Epoch [35/200], Batch [200/750], Loss: 0.1654\n",
            "Epoch [35/200], Batch [300/750], Loss: 0.2498\n",
            "Epoch [35/200], Batch [400/750], Loss: 0.4458\n",
            "Epoch [35/200], Batch [500/750], Loss: 0.5052\n",
            "Epoch [35/200], Batch [600/750], Loss: 0.3165\n",
            "Epoch [35/200], Batch [700/750], Loss: 0.2985\n",
            "Epoch [35/200] Total train Cost: 275.13810020685196\n",
            "---------------------------------------------\n",
            "Epoch [36/200], Batch [100/750], Loss: 0.3284\n",
            "Epoch [36/200], Batch [200/750], Loss: 0.3788\n",
            "Epoch [36/200], Batch [300/750], Loss: 0.3566\n",
            "Epoch [36/200], Batch [400/750], Loss: 0.3608\n",
            "Epoch [36/200], Batch [500/750], Loss: 0.3257\n",
            "Epoch [36/200], Batch [600/750], Loss: 0.4471\n",
            "Epoch [36/200], Batch [700/750], Loss: 0.3037\n",
            "Epoch [36/200] Total train Cost: 272.6046393662691\n",
            "---------------------------------------------\n",
            "Epoch [37/200], Batch [100/750], Loss: 0.3716\n",
            "Epoch [37/200], Batch [200/750], Loss: 0.1597\n",
            "Epoch [37/200], Batch [300/750], Loss: 0.4564\n",
            "Epoch [37/200], Batch [400/750], Loss: 0.3875\n",
            "Epoch [37/200], Batch [500/750], Loss: 0.4440\n",
            "Epoch [37/200], Batch [600/750], Loss: 0.3122\n",
            "Epoch [37/200], Batch [700/750], Loss: 0.2856\n",
            "Epoch [37/200] Total train Cost: 270.18548572063446\n",
            "---------------------------------------------\n",
            "Epoch [38/200], Batch [100/750], Loss: 0.2753\n",
            "Epoch [38/200], Batch [200/750], Loss: 0.2586\n",
            "Epoch [38/200], Batch [300/750], Loss: 0.3552\n",
            "Epoch [38/200], Batch [400/750], Loss: 0.2880\n",
            "Epoch [38/200], Batch [500/750], Loss: 0.3213\n",
            "Epoch [38/200], Batch [600/750], Loss: 0.2213\n",
            "Epoch [38/200], Batch [700/750], Loss: 0.2717\n",
            "Epoch [38/200] Total train Cost: 267.8817804902792\n",
            "---------------------------------------------\n",
            "Epoch [39/200], Batch [100/750], Loss: 0.3340\n",
            "Epoch [39/200], Batch [200/750], Loss: 0.2381\n",
            "Epoch [39/200], Batch [300/750], Loss: 0.2391\n",
            "Epoch [39/200], Batch [400/750], Loss: 0.2195\n",
            "Epoch [39/200], Batch [500/750], Loss: 0.3347\n",
            "Epoch [39/200], Batch [600/750], Loss: 0.3327\n",
            "Epoch [39/200], Batch [700/750], Loss: 0.3196\n",
            "Epoch [39/200] Total train Cost: 265.6954897791147\n",
            "---------------------------------------------\n",
            "Epoch [40/200], Batch [100/750], Loss: 0.4460\n",
            "Epoch [40/200], Batch [200/750], Loss: 0.3011\n",
            "Epoch [40/200], Batch [300/750], Loss: 0.2303\n",
            "Epoch [40/200], Batch [400/750], Loss: 0.3752\n",
            "Epoch [40/200], Batch [500/750], Loss: 0.3557\n",
            "Epoch [40/200], Batch [600/750], Loss: 0.3795\n",
            "Epoch [40/200], Batch [700/750], Loss: 0.5119\n",
            "Epoch [40/200] Total train Cost: 263.60902877897024\n",
            "---------------------------------------------\n",
            "Epoch [41/200], Batch [100/750], Loss: 0.4723\n",
            "Epoch [41/200], Batch [200/750], Loss: 0.3047\n",
            "Epoch [41/200], Batch [300/750], Loss: 0.4164\n",
            "Epoch [41/200], Batch [400/750], Loss: 0.4958\n",
            "Epoch [41/200], Batch [500/750], Loss: 0.3438\n",
            "Epoch [41/200], Batch [600/750], Loss: 0.3244\n",
            "Epoch [41/200], Batch [700/750], Loss: 0.4319\n",
            "Epoch [41/200] Total train Cost: 261.60552018880844\n",
            "---------------------------------------------\n",
            "Epoch [42/200], Batch [100/750], Loss: 0.3191\n",
            "Epoch [42/200], Batch [200/750], Loss: 0.4330\n",
            "Epoch [42/200], Batch [300/750], Loss: 0.2952\n",
            "Epoch [42/200], Batch [400/750], Loss: 0.5474\n",
            "Epoch [42/200], Batch [500/750], Loss: 0.2567\n",
            "Epoch [42/200], Batch [600/750], Loss: 0.1940\n",
            "Epoch [42/200], Batch [700/750], Loss: 0.4614\n",
            "Epoch [42/200] Total train Cost: 259.6609347909689\n",
            "---------------------------------------------\n",
            "Epoch [43/200], Batch [100/750], Loss: 0.3874\n",
            "Epoch [43/200], Batch [200/750], Loss: 0.2222\n",
            "Epoch [43/200], Batch [300/750], Loss: 0.3316\n",
            "Epoch [43/200], Batch [400/750], Loss: 0.2574\n",
            "Epoch [43/200], Batch [500/750], Loss: 0.4251\n",
            "Epoch [43/200], Batch [600/750], Loss: 0.3593\n",
            "Epoch [43/200], Batch [700/750], Loss: 0.4146\n",
            "Epoch [43/200] Total train Cost: 257.78419460356236\n",
            "---------------------------------------------\n",
            "Epoch [44/200], Batch [100/750], Loss: 0.5212\n",
            "Epoch [44/200], Batch [200/750], Loss: 0.2470\n",
            "Epoch [44/200], Batch [300/750], Loss: 0.3071\n",
            "Epoch [44/200], Batch [400/750], Loss: 0.2705\n",
            "Epoch [44/200], Batch [500/750], Loss: 0.3015\n",
            "Epoch [44/200], Batch [600/750], Loss: 0.3114\n",
            "Epoch [44/200], Batch [700/750], Loss: 0.1401\n",
            "Epoch [44/200] Total train Cost: 255.99891629815102\n",
            "---------------------------------------------\n",
            "Epoch [45/200], Batch [100/750], Loss: 0.3661\n",
            "Epoch [45/200], Batch [200/750], Loss: 0.4607\n",
            "Epoch [45/200], Batch [300/750], Loss: 0.3980\n",
            "Epoch [45/200], Batch [400/750], Loss: 0.2039\n",
            "Epoch [45/200], Batch [500/750], Loss: 0.4603\n",
            "Epoch [45/200], Batch [600/750], Loss: 0.3587\n",
            "Epoch [45/200], Batch [700/750], Loss: 0.2132\n",
            "Epoch [45/200] Total train Cost: 254.2558101117611\n",
            "---------------------------------------------\n",
            "Epoch [46/200], Batch [100/750], Loss: 0.5434\n",
            "Epoch [46/200], Batch [200/750], Loss: 0.4200\n",
            "Epoch [46/200], Batch [300/750], Loss: 0.2657\n",
            "Epoch [46/200], Batch [400/750], Loss: 0.5851\n",
            "Epoch [46/200], Batch [500/750], Loss: 0.3020\n",
            "Epoch [46/200], Batch [600/750], Loss: 0.3386\n",
            "Epoch [46/200], Batch [700/750], Loss: 0.3399\n",
            "Epoch [46/200] Total train Cost: 252.59117802977562\n",
            "---------------------------------------------\n",
            "Epoch [47/200], Batch [100/750], Loss: 0.2960\n",
            "Epoch [47/200], Batch [200/750], Loss: 0.2807\n",
            "Epoch [47/200], Batch [300/750], Loss: 0.2577\n",
            "Epoch [47/200], Batch [400/750], Loss: 0.3947\n",
            "Epoch [47/200], Batch [500/750], Loss: 0.3602\n",
            "Epoch [47/200], Batch [600/750], Loss: 0.2204\n",
            "Epoch [47/200], Batch [700/750], Loss: 0.4307\n",
            "Epoch [47/200] Total train Cost: 250.9585805758834\n",
            "---------------------------------------------\n",
            "Epoch [48/200], Batch [100/750], Loss: 0.1738\n",
            "Epoch [48/200], Batch [200/750], Loss: 0.2486\n",
            "Epoch [48/200], Batch [300/750], Loss: 0.2945\n",
            "Epoch [48/200], Batch [400/750], Loss: 0.2090\n",
            "Epoch [48/200], Batch [500/750], Loss: 0.3754\n",
            "Epoch [48/200], Batch [600/750], Loss: 0.1992\n",
            "Epoch [48/200], Batch [700/750], Loss: 0.2902\n",
            "Epoch [48/200] Total train Cost: 249.35178101807833\n",
            "---------------------------------------------\n",
            "Epoch [49/200], Batch [100/750], Loss: 0.1708\n",
            "Epoch [49/200], Batch [200/750], Loss: 0.5764\n",
            "Epoch [49/200], Batch [300/750], Loss: 0.3311\n",
            "Epoch [49/200], Batch [400/750], Loss: 0.3619\n",
            "Epoch [49/200], Batch [500/750], Loss: 0.5304\n",
            "Epoch [49/200], Batch [600/750], Loss: 0.3447\n",
            "Epoch [49/200], Batch [700/750], Loss: 0.2002\n",
            "Epoch [49/200] Total train Cost: 247.86354050785303\n",
            "---------------------------------------------\n",
            "Epoch [50/200], Batch [100/750], Loss: 0.2753\n",
            "Epoch [50/200], Batch [200/750], Loss: 0.4244\n",
            "Epoch [50/200], Batch [300/750], Loss: 0.3922\n",
            "Epoch [50/200], Batch [400/750], Loss: 0.2843\n",
            "Epoch [50/200], Batch [500/750], Loss: 0.2939\n",
            "Epoch [50/200], Batch [600/750], Loss: 0.2591\n",
            "Epoch [50/200], Batch [700/750], Loss: 0.3576\n",
            "Epoch [50/200] Total train Cost: 246.37986433506012\n",
            "---------------------------------------------\n",
            "Epoch [51/200], Batch [100/750], Loss: 0.2825\n",
            "Epoch [51/200], Batch [200/750], Loss: 0.2019\n",
            "Epoch [51/200], Batch [300/750], Loss: 0.4091\n",
            "Epoch [51/200], Batch [400/750], Loss: 0.3949\n",
            "Epoch [51/200], Batch [500/750], Loss: 0.2323\n",
            "Epoch [51/200], Batch [600/750], Loss: 0.2608\n",
            "Epoch [51/200], Batch [700/750], Loss: 0.3579\n",
            "Epoch [51/200] Total train Cost: 244.93202981352806\n",
            "---------------------------------------------\n",
            "Epoch [52/200], Batch [100/750], Loss: 0.3506\n",
            "Epoch [52/200], Batch [200/750], Loss: 0.3293\n",
            "Epoch [52/200], Batch [300/750], Loss: 0.3363\n",
            "Epoch [52/200], Batch [400/750], Loss: 0.3775\n",
            "Epoch [52/200], Batch [500/750], Loss: 0.2679\n",
            "Epoch [52/200], Batch [600/750], Loss: 0.3329\n",
            "Epoch [52/200], Batch [700/750], Loss: 0.3075\n",
            "Epoch [52/200] Total train Cost: 243.522155046463\n",
            "---------------------------------------------\n",
            "Epoch [53/200], Batch [100/750], Loss: 0.2576\n",
            "Epoch [53/200], Batch [200/750], Loss: 0.2864\n",
            "Epoch [53/200], Batch [300/750], Loss: 0.2492\n",
            "Epoch [53/200], Batch [400/750], Loss: 0.4131\n",
            "Epoch [53/200], Batch [500/750], Loss: 0.2203\n",
            "Epoch [53/200], Batch [600/750], Loss: 0.3295\n",
            "Epoch [53/200], Batch [700/750], Loss: 0.1522\n",
            "Epoch [53/200] Total train Cost: 242.15559726208448\n",
            "---------------------------------------------\n",
            "Epoch [54/200], Batch [100/750], Loss: 0.3026\n",
            "Epoch [54/200], Batch [200/750], Loss: 0.1332\n",
            "Epoch [54/200], Batch [300/750], Loss: 0.5160\n",
            "Epoch [54/200], Batch [400/750], Loss: 0.2553\n",
            "Epoch [54/200], Batch [500/750], Loss: 0.3489\n",
            "Epoch [54/200], Batch [600/750], Loss: 0.2920\n",
            "Epoch [54/200], Batch [700/750], Loss: 0.2926\n",
            "Epoch [54/200] Total train Cost: 240.82999558001757\n",
            "---------------------------------------------\n",
            "Epoch [55/200], Batch [100/750], Loss: 0.3077\n",
            "Epoch [55/200], Batch [200/750], Loss: 0.4174\n",
            "Epoch [55/200], Batch [300/750], Loss: 0.3113\n",
            "Epoch [55/200], Batch [400/750], Loss: 0.4459\n",
            "Epoch [55/200], Batch [500/750], Loss: 0.3045\n",
            "Epoch [55/200], Batch [600/750], Loss: 0.2667\n",
            "Epoch [55/200], Batch [700/750], Loss: 0.3836\n",
            "Epoch [55/200] Total train Cost: 239.5366296991706\n",
            "---------------------------------------------\n",
            "Epoch [56/200], Batch [100/750], Loss: 0.2746\n",
            "Epoch [56/200], Batch [200/750], Loss: 0.2290\n",
            "Epoch [56/200], Batch [300/750], Loss: 0.2281\n",
            "Epoch [56/200], Batch [400/750], Loss: 0.5008\n",
            "Epoch [56/200], Batch [500/750], Loss: 0.2918\n",
            "Epoch [56/200], Batch [600/750], Loss: 0.4109\n",
            "Epoch [56/200], Batch [700/750], Loss: 0.3611\n",
            "Epoch [56/200] Total train Cost: 238.26196265220642\n",
            "---------------------------------------------\n",
            "Epoch [57/200], Batch [100/750], Loss: 0.2908\n",
            "Epoch [57/200], Batch [200/750], Loss: 0.4754\n",
            "Epoch [57/200], Batch [300/750], Loss: 0.3681\n",
            "Epoch [57/200], Batch [400/750], Loss: 0.2335\n",
            "Epoch [57/200], Batch [500/750], Loss: 0.4090\n",
            "Epoch [57/200], Batch [600/750], Loss: 0.3655\n",
            "Epoch [57/200], Batch [700/750], Loss: 0.4126\n",
            "Epoch [57/200] Total train Cost: 237.00667273253202\n",
            "---------------------------------------------\n",
            "Epoch [58/200], Batch [100/750], Loss: 0.3171\n",
            "Epoch [58/200], Batch [200/750], Loss: 0.3043\n",
            "Epoch [58/200], Batch [300/750], Loss: 0.2614\n",
            "Epoch [58/200], Batch [400/750], Loss: 0.4950\n",
            "Epoch [58/200], Batch [500/750], Loss: 0.3614\n",
            "Epoch [58/200], Batch [600/750], Loss: 0.4082\n",
            "Epoch [58/200], Batch [700/750], Loss: 0.3146\n",
            "Epoch [58/200] Total train Cost: 235.78058829158545\n",
            "---------------------------------------------\n",
            "Epoch [59/200], Batch [100/750], Loss: 0.2744\n",
            "Epoch [59/200], Batch [200/750], Loss: 0.2633\n",
            "Epoch [59/200], Batch [300/750], Loss: 0.2749\n",
            "Epoch [59/200], Batch [400/750], Loss: 0.4561\n",
            "Epoch [59/200], Batch [500/750], Loss: 0.3501\n",
            "Epoch [59/200], Batch [600/750], Loss: 0.3283\n",
            "Epoch [59/200], Batch [700/750], Loss: 0.1810\n",
            "Epoch [59/200] Total train Cost: 234.64279678463936\n",
            "---------------------------------------------\n",
            "Epoch [60/200], Batch [100/750], Loss: 0.1732\n",
            "Epoch [60/200], Batch [200/750], Loss: 0.3139\n",
            "Epoch [60/200], Batch [300/750], Loss: 0.4012\n",
            "Epoch [60/200], Batch [400/750], Loss: 0.2393\n",
            "Epoch [60/200], Batch [500/750], Loss: 0.3498\n",
            "Epoch [60/200], Batch [600/750], Loss: 0.2956\n",
            "Epoch [60/200], Batch [700/750], Loss: 0.2406\n",
            "Epoch [60/200] Total train Cost: 233.4658573716879\n",
            "---------------------------------------------\n",
            "Epoch [61/200], Batch [100/750], Loss: 0.2779\n",
            "Epoch [61/200], Batch [200/750], Loss: 0.4489\n",
            "Epoch [61/200], Batch [300/750], Loss: 0.1561\n",
            "Epoch [61/200], Batch [400/750], Loss: 0.2277\n",
            "Epoch [61/200], Batch [500/750], Loss: 0.3569\n",
            "Epoch [61/200], Batch [600/750], Loss: 0.1861\n",
            "Epoch [61/200], Batch [700/750], Loss: 0.3283\n",
            "Epoch [61/200] Total train Cost: 232.31453593820333\n",
            "---------------------------------------------\n",
            "Epoch [62/200], Batch [100/750], Loss: 0.2542\n",
            "Epoch [62/200], Batch [200/750], Loss: 0.2428\n",
            "Epoch [62/200], Batch [300/750], Loss: 0.3244\n",
            "Epoch [62/200], Batch [400/750], Loss: 0.2675\n",
            "Epoch [62/200], Batch [500/750], Loss: 0.2960\n",
            "Epoch [62/200], Batch [600/750], Loss: 0.2377\n",
            "Epoch [62/200], Batch [700/750], Loss: 0.2128\n",
            "Epoch [62/200] Total train Cost: 231.17454031854868\n",
            "---------------------------------------------\n",
            "Epoch [63/200], Batch [100/750], Loss: 0.3281\n",
            "Epoch [63/200], Batch [200/750], Loss: 0.3265\n",
            "Epoch [63/200], Batch [300/750], Loss: 0.3735\n",
            "Epoch [63/200], Batch [400/750], Loss: 0.3614\n",
            "Epoch [63/200], Batch [500/750], Loss: 0.1449\n",
            "Epoch [63/200], Batch [600/750], Loss: 0.2413\n",
            "Epoch [63/200], Batch [700/750], Loss: 0.4325\n",
            "Epoch [63/200] Total train Cost: 230.09261898696423\n",
            "---------------------------------------------\n",
            "Epoch [64/200], Batch [100/750], Loss: 0.2492\n",
            "Epoch [64/200], Batch [200/750], Loss: 0.2926\n",
            "Epoch [64/200], Batch [300/750], Loss: 0.4189\n",
            "Epoch [64/200], Batch [400/750], Loss: 0.2550\n",
            "Epoch [64/200], Batch [500/750], Loss: 0.2627\n",
            "Epoch [64/200], Batch [600/750], Loss: 0.2863\n",
            "Epoch [64/200], Batch [700/750], Loss: 0.2211\n",
            "Epoch [64/200] Total train Cost: 229.01705164462328\n",
            "---------------------------------------------\n",
            "Epoch [65/200], Batch [100/750], Loss: 0.4031\n",
            "Epoch [65/200], Batch [200/750], Loss: 0.1436\n",
            "Epoch [65/200], Batch [300/750], Loss: 0.4473\n",
            "Epoch [65/200], Batch [400/750], Loss: 0.2117\n",
            "Epoch [65/200], Batch [500/750], Loss: 0.3814\n",
            "Epoch [65/200], Batch [600/750], Loss: 0.4357\n",
            "Epoch [65/200], Batch [700/750], Loss: 0.2360\n",
            "Epoch [65/200] Total train Cost: 227.93258702009916\n",
            "---------------------------------------------\n",
            "Epoch [66/200], Batch [100/750], Loss: 0.2316\n",
            "Epoch [66/200], Batch [200/750], Loss: 0.2868\n",
            "Epoch [66/200], Batch [300/750], Loss: 0.4161\n",
            "Epoch [66/200], Batch [400/750], Loss: 0.2785\n",
            "Epoch [66/200], Batch [500/750], Loss: 0.3915\n",
            "Epoch [66/200], Batch [600/750], Loss: 0.2235\n",
            "Epoch [66/200], Batch [700/750], Loss: 0.2822\n",
            "Epoch [66/200] Total train Cost: 226.88320662081242\n",
            "---------------------------------------------\n",
            "Epoch [67/200], Batch [100/750], Loss: 0.4077\n",
            "Epoch [67/200], Batch [200/750], Loss: 0.2332\n",
            "Epoch [67/200], Batch [300/750], Loss: 0.3407\n",
            "Epoch [67/200], Batch [400/750], Loss: 0.1348\n",
            "Epoch [67/200], Batch [500/750], Loss: 0.2726\n",
            "Epoch [67/200], Batch [600/750], Loss: 0.4625\n",
            "Epoch [67/200], Batch [700/750], Loss: 0.2283\n",
            "Epoch [67/200] Total train Cost: 225.8838880509138\n",
            "---------------------------------------------\n",
            "Epoch [68/200], Batch [100/750], Loss: 0.3331\n",
            "Epoch [68/200], Batch [200/750], Loss: 0.3410\n",
            "Epoch [68/200], Batch [300/750], Loss: 0.4159\n",
            "Epoch [68/200], Batch [400/750], Loss: 0.3440\n",
            "Epoch [68/200], Batch [500/750], Loss: 0.2941\n",
            "Epoch [68/200], Batch [600/750], Loss: 0.4182\n",
            "Epoch [68/200], Batch [700/750], Loss: 0.2903\n",
            "Epoch [68/200] Total train Cost: 224.86816250532866\n",
            "---------------------------------------------\n",
            "Epoch [69/200], Batch [100/750], Loss: 0.4073\n",
            "Epoch [69/200], Batch [200/750], Loss: 0.3512\n",
            "Epoch [69/200], Batch [300/750], Loss: 0.4027\n",
            "Epoch [69/200], Batch [400/750], Loss: 0.2132\n",
            "Epoch [69/200], Batch [500/750], Loss: 0.3309\n",
            "Epoch [69/200], Batch [600/750], Loss: 0.2873\n",
            "Epoch [69/200], Batch [700/750], Loss: 0.1714\n",
            "Epoch [69/200] Total train Cost: 223.85777778923512\n",
            "---------------------------------------------\n",
            "Epoch [70/200], Batch [100/750], Loss: 0.2092\n",
            "Epoch [70/200], Batch [200/750], Loss: 0.3359\n",
            "Epoch [70/200], Batch [300/750], Loss: 0.4384\n",
            "Epoch [70/200], Batch [400/750], Loss: 0.3356\n",
            "Epoch [70/200], Batch [500/750], Loss: 0.3849\n",
            "Epoch [70/200], Batch [600/750], Loss: 0.2657\n",
            "Epoch [70/200], Batch [700/750], Loss: 0.1957\n",
            "Epoch [70/200] Total train Cost: 222.87031558156013\n",
            "---------------------------------------------\n",
            "Epoch [71/200], Batch [100/750], Loss: 0.2309\n",
            "Epoch [71/200], Batch [200/750], Loss: 0.4313\n",
            "Epoch [71/200], Batch [300/750], Loss: 0.2396\n",
            "Epoch [71/200], Batch [400/750], Loss: 0.3157\n",
            "Epoch [71/200], Batch [500/750], Loss: 0.5951\n",
            "Epoch [71/200], Batch [600/750], Loss: 0.1724\n",
            "Epoch [71/200], Batch [700/750], Loss: 0.4074\n",
            "Epoch [71/200] Total train Cost: 221.91216891258955\n",
            "---------------------------------------------\n",
            "Epoch [72/200], Batch [100/750], Loss: 0.1498\n",
            "Epoch [72/200], Batch [200/750], Loss: 0.1288\n",
            "Epoch [72/200], Batch [300/750], Loss: 0.2751\n",
            "Epoch [72/200], Batch [400/750], Loss: 0.4199\n",
            "Epoch [72/200], Batch [500/750], Loss: 0.2237\n",
            "Epoch [72/200], Batch [600/750], Loss: 0.3406\n",
            "Epoch [72/200], Batch [700/750], Loss: 0.4739\n",
            "Epoch [72/200] Total train Cost: 220.96615838259459\n",
            "---------------------------------------------\n",
            "Epoch [73/200], Batch [100/750], Loss: 0.2522\n",
            "Epoch [73/200], Batch [200/750], Loss: 0.4413\n",
            "Epoch [73/200], Batch [300/750], Loss: 0.3023\n",
            "Epoch [73/200], Batch [400/750], Loss: 0.3207\n",
            "Epoch [73/200], Batch [500/750], Loss: 0.2081\n",
            "Epoch [73/200], Batch [600/750], Loss: 0.2249\n",
            "Epoch [73/200], Batch [700/750], Loss: 0.3312\n",
            "Epoch [73/200] Total train Cost: 220.01978408545256\n",
            "---------------------------------------------\n",
            "Epoch [74/200], Batch [100/750], Loss: 0.1945\n",
            "Epoch [74/200], Batch [200/750], Loss: 0.3194\n",
            "Epoch [74/200], Batch [300/750], Loss: 0.2222\n",
            "Epoch [74/200], Batch [400/750], Loss: 0.3407\n",
            "Epoch [74/200], Batch [500/750], Loss: 0.4442\n",
            "Epoch [74/200], Batch [600/750], Loss: 0.1858\n",
            "Epoch [74/200], Batch [700/750], Loss: 0.1794\n",
            "Epoch [74/200] Total train Cost: 219.1184321641922\n",
            "---------------------------------------------\n",
            "Epoch [75/200], Batch [100/750], Loss: 0.2493\n",
            "Epoch [75/200], Batch [200/750], Loss: 0.4564\n",
            "Epoch [75/200], Batch [300/750], Loss: 0.4438\n",
            "Epoch [75/200], Batch [400/750], Loss: 0.3612\n",
            "Epoch [75/200], Batch [500/750], Loss: 0.3839\n",
            "Epoch [75/200], Batch [600/750], Loss: 0.2229\n",
            "Epoch [75/200], Batch [700/750], Loss: 0.2842\n",
            "Epoch [75/200] Total train Cost: 218.20026724785566\n",
            "---------------------------------------------\n",
            "Epoch [76/200], Batch [100/750], Loss: 0.3737\n",
            "Epoch [76/200], Batch [200/750], Loss: 0.2660\n",
            "Epoch [76/200], Batch [300/750], Loss: 0.3993\n",
            "Epoch [76/200], Batch [400/750], Loss: 0.1988\n",
            "Epoch [76/200], Batch [500/750], Loss: 0.3223\n",
            "Epoch [76/200], Batch [600/750], Loss: 0.4946\n",
            "Epoch [76/200], Batch [700/750], Loss: 0.2604\n",
            "Epoch [76/200] Total train Cost: 217.30500178784132\n",
            "---------------------------------------------\n",
            "Epoch [77/200], Batch [100/750], Loss: 0.2103\n",
            "Epoch [77/200], Batch [200/750], Loss: 0.1537\n",
            "Epoch [77/200], Batch [300/750], Loss: 0.3089\n",
            "Epoch [77/200], Batch [400/750], Loss: 0.3171\n",
            "Epoch [77/200], Batch [500/750], Loss: 0.3486\n",
            "Epoch [77/200], Batch [600/750], Loss: 0.2744\n",
            "Epoch [77/200], Batch [700/750], Loss: 0.3705\n",
            "Epoch [77/200] Total train Cost: 216.40896227955818\n",
            "---------------------------------------------\n",
            "Epoch [78/200], Batch [100/750], Loss: 0.2352\n",
            "Epoch [78/200], Batch [200/750], Loss: 0.2550\n",
            "Epoch [78/200], Batch [300/750], Loss: 0.3627\n",
            "Epoch [78/200], Batch [400/750], Loss: 0.2846\n",
            "Epoch [78/200], Batch [500/750], Loss: 0.2447\n",
            "Epoch [78/200], Batch [600/750], Loss: 0.1656\n",
            "Epoch [78/200], Batch [700/750], Loss: 0.1394\n",
            "Epoch [78/200] Total train Cost: 215.52350111305714\n",
            "---------------------------------------------\n",
            "Epoch [79/200], Batch [100/750], Loss: 0.3086\n",
            "Epoch [79/200], Batch [200/750], Loss: 0.3969\n",
            "Epoch [79/200], Batch [300/750], Loss: 0.2282\n",
            "Epoch [79/200], Batch [400/750], Loss: 0.2446\n",
            "Epoch [79/200], Batch [500/750], Loss: 0.2823\n",
            "Epoch [79/200], Batch [600/750], Loss: 0.1840\n",
            "Epoch [79/200], Batch [700/750], Loss: 0.3375\n",
            "Epoch [79/200] Total train Cost: 214.65794328600168\n",
            "---------------------------------------------\n",
            "Epoch [80/200], Batch [100/750], Loss: 0.2420\n",
            "Epoch [80/200], Batch [200/750], Loss: 0.1623\n",
            "Epoch [80/200], Batch [300/750], Loss: 0.2713\n",
            "Epoch [80/200], Batch [400/750], Loss: 0.3062\n",
            "Epoch [80/200], Batch [500/750], Loss: 0.2145\n",
            "Epoch [80/200], Batch [600/750], Loss: 0.2272\n",
            "Epoch [80/200], Batch [700/750], Loss: 0.3645\n",
            "Epoch [80/200] Total train Cost: 213.81582672894\n",
            "---------------------------------------------\n",
            "Epoch [81/200], Batch [100/750], Loss: 0.2780\n",
            "Epoch [81/200], Batch [200/750], Loss: 0.3965\n",
            "Epoch [81/200], Batch [300/750], Loss: 0.2765\n",
            "Epoch [81/200], Batch [400/750], Loss: 0.2479\n",
            "Epoch [81/200], Batch [500/750], Loss: 0.4336\n",
            "Epoch [81/200], Batch [600/750], Loss: 0.2895\n",
            "Epoch [81/200], Batch [700/750], Loss: 0.3659\n",
            "Epoch [81/200] Total train Cost: 212.97616996616125\n",
            "---------------------------------------------\n",
            "Epoch [82/200], Batch [100/750], Loss: 0.3328\n",
            "Epoch [82/200], Batch [200/750], Loss: 0.2218\n",
            "Epoch [82/200], Batch [300/750], Loss: 0.1897\n",
            "Epoch [82/200], Batch [400/750], Loss: 0.1353\n",
            "Epoch [82/200], Batch [500/750], Loss: 0.4585\n",
            "Epoch [82/200], Batch [600/750], Loss: 0.4539\n",
            "Epoch [82/200], Batch [700/750], Loss: 0.2941\n",
            "Epoch [82/200] Total train Cost: 212.11870803683996\n",
            "---------------------------------------------\n",
            "Epoch [83/200], Batch [100/750], Loss: 0.1833\n",
            "Epoch [83/200], Batch [200/750], Loss: 0.3101\n",
            "Epoch [83/200], Batch [300/750], Loss: 0.3793\n",
            "Epoch [83/200], Batch [400/750], Loss: 0.2994\n",
            "Epoch [83/200], Batch [500/750], Loss: 0.2882\n",
            "Epoch [83/200], Batch [600/750], Loss: 0.3274\n",
            "Epoch [83/200], Batch [700/750], Loss: 0.2291\n",
            "Epoch [83/200] Total train Cost: 211.30071917921305\n",
            "---------------------------------------------\n",
            "Epoch [84/200], Batch [100/750], Loss: 0.2588\n",
            "Epoch [84/200], Batch [200/750], Loss: 0.1571\n",
            "Epoch [84/200], Batch [300/750], Loss: 0.1950\n",
            "Epoch [84/200], Batch [400/750], Loss: 0.1570\n",
            "Epoch [84/200], Batch [500/750], Loss: 0.1678\n",
            "Epoch [84/200], Batch [600/750], Loss: 0.3846\n",
            "Epoch [84/200], Batch [700/750], Loss: 0.3994\n",
            "Epoch [84/200] Total train Cost: 210.48744206875563\n",
            "---------------------------------------------\n",
            "Epoch [85/200], Batch [100/750], Loss: 0.4899\n",
            "Epoch [85/200], Batch [200/750], Loss: 0.2813\n",
            "Epoch [85/200], Batch [300/750], Loss: 0.3135\n",
            "Epoch [85/200], Batch [400/750], Loss: 0.3334\n",
            "Epoch [85/200], Batch [500/750], Loss: 0.1003\n",
            "Epoch [85/200], Batch [600/750], Loss: 0.4019\n",
            "Epoch [85/200], Batch [700/750], Loss: 0.3102\n",
            "Epoch [85/200] Total train Cost: 209.6769879758358\n",
            "---------------------------------------------\n",
            "Epoch [86/200], Batch [100/750], Loss: 0.2440\n",
            "Epoch [86/200], Batch [200/750], Loss: 0.2851\n",
            "Epoch [86/200], Batch [300/750], Loss: 0.3557\n",
            "Epoch [86/200], Batch [400/750], Loss: 0.2701\n",
            "Epoch [86/200], Batch [500/750], Loss: 0.1252\n",
            "Epoch [86/200], Batch [600/750], Loss: 0.3615\n",
            "Epoch [86/200], Batch [700/750], Loss: 0.3375\n",
            "Epoch [86/200] Total train Cost: 208.8945665806532\n",
            "---------------------------------------------\n",
            "Epoch [87/200], Batch [100/750], Loss: 0.2188\n",
            "Epoch [87/200], Batch [200/750], Loss: 0.1630\n",
            "Epoch [87/200], Batch [300/750], Loss: 0.2459\n",
            "Epoch [87/200], Batch [400/750], Loss: 0.1475\n",
            "Epoch [87/200], Batch [500/750], Loss: 0.2125\n",
            "Epoch [87/200], Batch [600/750], Loss: 0.3449\n",
            "Epoch [87/200], Batch [700/750], Loss: 0.2732\n",
            "Epoch [87/200] Total train Cost: 208.09877207130194\n",
            "---------------------------------------------\n",
            "Epoch [88/200], Batch [100/750], Loss: 0.3104\n",
            "Epoch [88/200], Batch [200/750], Loss: 0.3202\n",
            "Epoch [88/200], Batch [300/750], Loss: 0.4667\n",
            "Epoch [88/200], Batch [400/750], Loss: 0.2546\n",
            "Epoch [88/200], Batch [500/750], Loss: 0.3038\n",
            "Epoch [88/200], Batch [600/750], Loss: 0.2521\n",
            "Epoch [88/200], Batch [700/750], Loss: 0.2815\n",
            "Epoch [88/200] Total train Cost: 207.30177537351847\n",
            "---------------------------------------------\n",
            "Epoch [89/200], Batch [100/750], Loss: 0.1783\n",
            "Epoch [89/200], Batch [200/750], Loss: 0.1447\n",
            "Epoch [89/200], Batch [300/750], Loss: 0.2962\n",
            "Epoch [89/200], Batch [400/750], Loss: 0.1896\n",
            "Epoch [89/200], Batch [500/750], Loss: 0.2722\n",
            "Epoch [89/200], Batch [600/750], Loss: 0.1902\n",
            "Epoch [89/200], Batch [700/750], Loss: 0.3073\n",
            "Epoch [89/200] Total train Cost: 206.53107450902462\n",
            "---------------------------------------------\n",
            "Epoch [90/200], Batch [100/750], Loss: 0.1822\n",
            "Epoch [90/200], Batch [200/750], Loss: 0.3110\n",
            "Epoch [90/200], Batch [300/750], Loss: 0.2225\n",
            "Epoch [90/200], Batch [400/750], Loss: 0.2309\n",
            "Epoch [90/200], Batch [500/750], Loss: 0.2699\n",
            "Epoch [90/200], Batch [600/750], Loss: 0.4669\n",
            "Epoch [90/200], Batch [700/750], Loss: 0.3708\n",
            "Epoch [90/200] Total train Cost: 205.78161965310574\n",
            "---------------------------------------------\n",
            "Epoch [91/200], Batch [100/750], Loss: 0.3068\n",
            "Epoch [91/200], Batch [200/750], Loss: 0.3258\n",
            "Epoch [91/200], Batch [300/750], Loss: 0.1952\n",
            "Epoch [91/200], Batch [400/750], Loss: 0.3403\n",
            "Epoch [91/200], Batch [500/750], Loss: 0.3085\n",
            "Epoch [91/200], Batch [600/750], Loss: 0.2826\n",
            "Epoch [91/200], Batch [700/750], Loss: 0.2916\n",
            "Epoch [91/200] Total train Cost: 205.01409428194165\n",
            "---------------------------------------------\n",
            "Epoch [92/200], Batch [100/750], Loss: 0.2555\n",
            "Epoch [92/200], Batch [200/750], Loss: 0.2343\n",
            "Epoch [92/200], Batch [300/750], Loss: 0.1955\n",
            "Epoch [92/200], Batch [400/750], Loss: 0.2653\n",
            "Epoch [92/200], Batch [500/750], Loss: 0.1545\n",
            "Epoch [92/200], Batch [600/750], Loss: 0.2726\n",
            "Epoch [92/200], Batch [700/750], Loss: 0.1486\n",
            "Epoch [92/200] Total train Cost: 204.23217509314418\n",
            "---------------------------------------------\n",
            "Epoch [93/200], Batch [100/750], Loss: 0.2004\n",
            "Epoch [93/200], Batch [200/750], Loss: 0.2655\n",
            "Epoch [93/200], Batch [300/750], Loss: 0.3091\n",
            "Epoch [93/200], Batch [400/750], Loss: 0.2073\n",
            "Epoch [93/200], Batch [500/750], Loss: 0.2900\n",
            "Epoch [93/200], Batch [600/750], Loss: 0.3044\n",
            "Epoch [93/200], Batch [700/750], Loss: 0.2369\n",
            "Epoch [93/200] Total train Cost: 203.51746411249042\n",
            "---------------------------------------------\n",
            "Epoch [94/200], Batch [100/750], Loss: 0.2043\n",
            "Epoch [94/200], Batch [200/750], Loss: 0.2685\n",
            "Epoch [94/200], Batch [300/750], Loss: 0.3064\n",
            "Epoch [94/200], Batch [400/750], Loss: 0.2302\n",
            "Epoch [94/200], Batch [500/750], Loss: 0.3040\n",
            "Epoch [94/200], Batch [600/750], Loss: 0.3778\n",
            "Epoch [94/200], Batch [700/750], Loss: 0.3340\n",
            "Epoch [94/200] Total train Cost: 202.7688553929329\n",
            "---------------------------------------------\n",
            "Epoch [95/200], Batch [100/750], Loss: 0.3284\n",
            "Epoch [95/200], Batch [200/750], Loss: 0.1431\n",
            "Epoch [95/200], Batch [300/750], Loss: 0.1843\n",
            "Epoch [95/200], Batch [400/750], Loss: 0.5549\n",
            "Epoch [95/200], Batch [500/750], Loss: 0.2205\n",
            "Epoch [95/200], Batch [600/750], Loss: 0.2191\n",
            "Epoch [95/200], Batch [700/750], Loss: 0.3006\n",
            "Epoch [95/200] Total train Cost: 202.04126688838005\n",
            "---------------------------------------------\n",
            "Epoch [96/200], Batch [100/750], Loss: 0.1603\n",
            "Epoch [96/200], Batch [200/750], Loss: 0.3560\n",
            "Epoch [96/200], Batch [300/750], Loss: 0.2568\n",
            "Epoch [96/200], Batch [400/750], Loss: 0.1898\n",
            "Epoch [96/200], Batch [500/750], Loss: 0.1964\n",
            "Epoch [96/200], Batch [600/750], Loss: 0.1624\n",
            "Epoch [96/200], Batch [700/750], Loss: 0.3889\n",
            "Epoch [96/200] Total train Cost: 201.30032017081976\n",
            "---------------------------------------------\n",
            "Epoch [97/200], Batch [100/750], Loss: 0.2476\n",
            "Epoch [97/200], Batch [200/750], Loss: 0.2372\n",
            "Epoch [97/200], Batch [300/750], Loss: 0.3442\n",
            "Epoch [97/200], Batch [400/750], Loss: 0.3509\n",
            "Epoch [97/200], Batch [500/750], Loss: 0.2009\n",
            "Epoch [97/200], Batch [600/750], Loss: 0.2769\n",
            "Epoch [97/200], Batch [700/750], Loss: 0.3442\n",
            "Epoch [97/200] Total train Cost: 200.61103027313948\n",
            "---------------------------------------------\n",
            "Epoch [98/200], Batch [100/750], Loss: 0.3291\n",
            "Epoch [98/200], Batch [200/750], Loss: 0.2597\n",
            "Epoch [98/200], Batch [300/750], Loss: 0.2244\n",
            "Epoch [98/200], Batch [400/750], Loss: 0.2862\n",
            "Epoch [98/200], Batch [500/750], Loss: 0.2615\n",
            "Epoch [98/200], Batch [600/750], Loss: 0.3282\n",
            "Epoch [98/200], Batch [700/750], Loss: 0.4585\n",
            "Epoch [98/200] Total train Cost: 199.89878007024527\n",
            "---------------------------------------------\n",
            "Epoch [99/200], Batch [100/750], Loss: 0.2351\n",
            "Epoch [99/200], Batch [200/750], Loss: 0.2490\n",
            "Epoch [99/200], Batch [300/750], Loss: 0.4889\n",
            "Epoch [99/200], Batch [400/750], Loss: 0.1329\n",
            "Epoch [99/200], Batch [500/750], Loss: 0.2892\n",
            "Epoch [99/200], Batch [600/750], Loss: 0.2905\n",
            "Epoch [99/200], Batch [700/750], Loss: 0.1621\n",
            "Epoch [99/200] Total train Cost: 199.1686900779605\n",
            "---------------------------------------------\n",
            "Epoch [100/200], Batch [100/750], Loss: 0.2721\n",
            "Epoch [100/200], Batch [200/750], Loss: 0.1501\n",
            "Epoch [100/200], Batch [300/750], Loss: 0.1632\n",
            "Epoch [100/200], Batch [400/750], Loss: 0.3001\n",
            "Epoch [100/200], Batch [500/750], Loss: 0.2950\n",
            "Epoch [100/200], Batch [600/750], Loss: 0.2410\n",
            "Epoch [100/200], Batch [700/750], Loss: 0.2080\n",
            "Epoch [100/200] Total train Cost: 198.49147422611713\n",
            "---------------------------------------------\n",
            "Epoch [101/200], Batch [100/750], Loss: 0.3209\n",
            "Epoch [101/200], Batch [200/750], Loss: 0.1942\n",
            "Epoch [101/200], Batch [300/750], Loss: 0.2614\n",
            "Epoch [101/200], Batch [400/750], Loss: 0.2111\n",
            "Epoch [101/200], Batch [500/750], Loss: 0.3146\n",
            "Epoch [101/200], Batch [600/750], Loss: 0.2132\n",
            "Epoch [101/200], Batch [700/750], Loss: 0.4400\n",
            "Epoch [101/200] Total train Cost: 197.78068282455206\n",
            "---------------------------------------------\n",
            "Epoch [102/200], Batch [100/750], Loss: 0.1591\n",
            "Epoch [102/200], Batch [200/750], Loss: 0.2180\n",
            "Epoch [102/200], Batch [300/750], Loss: 0.3023\n",
            "Epoch [102/200], Batch [400/750], Loss: 0.2802\n",
            "Epoch [102/200], Batch [500/750], Loss: 0.2958\n",
            "Epoch [102/200], Batch [600/750], Loss: 0.2709\n",
            "Epoch [102/200], Batch [700/750], Loss: 0.2364\n",
            "Epoch [102/200] Total train Cost: 197.10529708117247\n",
            "---------------------------------------------\n",
            "Epoch [103/200], Batch [100/750], Loss: 0.3577\n",
            "Epoch [103/200], Batch [200/750], Loss: 0.2711\n",
            "Epoch [103/200], Batch [300/750], Loss: 0.2677\n",
            "Epoch [103/200], Batch [400/750], Loss: 0.2801\n",
            "Epoch [103/200], Batch [500/750], Loss: 0.2171\n",
            "Epoch [103/200], Batch [600/750], Loss: 0.1494\n",
            "Epoch [103/200], Batch [700/750], Loss: 0.2104\n",
            "Epoch [103/200] Total train Cost: 196.3906793296337\n",
            "---------------------------------------------\n",
            "Epoch [104/200], Batch [100/750], Loss: 0.1725\n",
            "Epoch [104/200], Batch [200/750], Loss: 0.1962\n",
            "Epoch [104/200], Batch [300/750], Loss: 0.4518\n",
            "Epoch [104/200], Batch [400/750], Loss: 0.3722\n",
            "Epoch [104/200], Batch [500/750], Loss: 0.2557\n",
            "Epoch [104/200], Batch [600/750], Loss: 0.1943\n",
            "Epoch [104/200], Batch [700/750], Loss: 0.2596\n",
            "Epoch [104/200] Total train Cost: 195.7426154613495\n",
            "---------------------------------------------\n",
            "Epoch [105/200], Batch [100/750], Loss: 0.2089\n",
            "Epoch [105/200], Batch [200/750], Loss: 0.4745\n",
            "Epoch [105/200], Batch [300/750], Loss: 0.2338\n",
            "Epoch [105/200], Batch [400/750], Loss: 0.4369\n",
            "Epoch [105/200], Batch [500/750], Loss: 0.2864\n",
            "Epoch [105/200], Batch [600/750], Loss: 0.0908\n",
            "Epoch [105/200], Batch [700/750], Loss: 0.2186\n",
            "Epoch [105/200] Total train Cost: 195.0674403384328\n",
            "---------------------------------------------\n",
            "Epoch [106/200], Batch [100/750], Loss: 0.1774\n",
            "Epoch [106/200], Batch [200/750], Loss: 0.2688\n",
            "Epoch [106/200], Batch [300/750], Loss: 0.1181\n",
            "Epoch [106/200], Batch [400/750], Loss: 0.2851\n",
            "Epoch [106/200], Batch [500/750], Loss: 0.2877\n",
            "Epoch [106/200], Batch [600/750], Loss: 0.5101\n",
            "Epoch [106/200], Batch [700/750], Loss: 0.2632\n",
            "Epoch [106/200] Total train Cost: 194.40553244575858\n",
            "---------------------------------------------\n",
            "Epoch [107/200], Batch [100/750], Loss: 0.1863\n",
            "Epoch [107/200], Batch [200/750], Loss: 0.2367\n",
            "Epoch [107/200], Batch [300/750], Loss: 0.2536\n",
            "Epoch [107/200], Batch [400/750], Loss: 0.2584\n",
            "Epoch [107/200], Batch [500/750], Loss: 0.2248\n",
            "Epoch [107/200], Batch [600/750], Loss: 0.3403\n",
            "Epoch [107/200], Batch [700/750], Loss: 0.4135\n",
            "Epoch [107/200] Total train Cost: 193.74226689338684\n",
            "---------------------------------------------\n",
            "Epoch [108/200], Batch [100/750], Loss: 0.4156\n",
            "Epoch [108/200], Batch [200/750], Loss: 0.3057\n",
            "Epoch [108/200], Batch [300/750], Loss: 0.2788\n",
            "Epoch [108/200], Batch [400/750], Loss: 0.3475\n",
            "Epoch [108/200], Batch [500/750], Loss: 0.3635\n",
            "Epoch [108/200], Batch [600/750], Loss: 0.2950\n",
            "Epoch [108/200], Batch [700/750], Loss: 0.3440\n",
            "Epoch [108/200] Total train Cost: 193.06245248764753\n",
            "---------------------------------------------\n",
            "Epoch [109/200], Batch [100/750], Loss: 0.3369\n",
            "Epoch [109/200], Batch [200/750], Loss: 0.3883\n",
            "Epoch [109/200], Batch [300/750], Loss: 0.3496\n",
            "Epoch [109/200], Batch [400/750], Loss: 0.0895\n",
            "Epoch [109/200], Batch [500/750], Loss: 0.2731\n",
            "Epoch [109/200], Batch [600/750], Loss: 0.1818\n",
            "Epoch [109/200], Batch [700/750], Loss: 0.1799\n",
            "Epoch [109/200] Total train Cost: 192.40691310167313\n",
            "---------------------------------------------\n",
            "Epoch [110/200], Batch [100/750], Loss: 0.3618\n",
            "Epoch [110/200], Batch [200/750], Loss: 0.3836\n",
            "Epoch [110/200], Batch [300/750], Loss: 0.3773\n",
            "Epoch [110/200], Batch [400/750], Loss: 0.2746\n",
            "Epoch [110/200], Batch [500/750], Loss: 0.1689\n",
            "Epoch [110/200], Batch [600/750], Loss: 0.2308\n",
            "Epoch [110/200], Batch [700/750], Loss: 0.3602\n",
            "Epoch [110/200] Total train Cost: 191.79187824577093\n",
            "---------------------------------------------\n",
            "Epoch [111/200], Batch [100/750], Loss: 0.2517\n",
            "Epoch [111/200], Batch [200/750], Loss: 0.2512\n",
            "Epoch [111/200], Batch [300/750], Loss: 0.2204\n",
            "Epoch [111/200], Batch [400/750], Loss: 0.2300\n",
            "Epoch [111/200], Batch [500/750], Loss: 0.3403\n",
            "Epoch [111/200], Batch [600/750], Loss: 0.1410\n",
            "Epoch [111/200], Batch [700/750], Loss: 0.0974\n",
            "Epoch [111/200] Total train Cost: 191.12106931954622\n",
            "---------------------------------------------\n",
            "Epoch [112/200], Batch [100/750], Loss: 0.2598\n",
            "Epoch [112/200], Batch [200/750], Loss: 0.5626\n",
            "Epoch [112/200], Batch [300/750], Loss: 0.4404\n",
            "Epoch [112/200], Batch [400/750], Loss: 0.2851\n",
            "Epoch [112/200], Batch [500/750], Loss: 0.3658\n",
            "Epoch [112/200], Batch [600/750], Loss: 0.2212\n",
            "Epoch [112/200], Batch [700/750], Loss: 0.2877\n",
            "Epoch [112/200] Total train Cost: 190.505434140563\n",
            "---------------------------------------------\n",
            "Epoch [113/200], Batch [100/750], Loss: 0.3101\n",
            "Epoch [113/200], Batch [200/750], Loss: 0.2439\n",
            "Epoch [113/200], Batch [300/750], Loss: 0.2892\n",
            "Epoch [113/200], Batch [400/750], Loss: 0.4674\n",
            "Epoch [113/200], Batch [500/750], Loss: 0.1794\n",
            "Epoch [113/200], Batch [600/750], Loss: 0.2746\n",
            "Epoch [113/200], Batch [700/750], Loss: 0.1670\n",
            "Epoch [113/200] Total train Cost: 189.8541349619627\n",
            "---------------------------------------------\n",
            "Epoch [114/200], Batch [100/750], Loss: 0.1444\n",
            "Epoch [114/200], Batch [200/750], Loss: 0.2231\n",
            "Epoch [114/200], Batch [300/750], Loss: 0.3147\n",
            "Epoch [114/200], Batch [400/750], Loss: 0.3799\n",
            "Epoch [114/200], Batch [500/750], Loss: 0.3088\n",
            "Epoch [114/200], Batch [600/750], Loss: 0.3944\n",
            "Epoch [114/200], Batch [700/750], Loss: 0.3296\n",
            "Epoch [114/200] Total train Cost: 189.22810016572475\n",
            "---------------------------------------------\n",
            "Epoch [115/200], Batch [100/750], Loss: 0.2765\n",
            "Epoch [115/200], Batch [200/750], Loss: 0.2280\n",
            "Epoch [115/200], Batch [300/750], Loss: 0.2706\n",
            "Epoch [115/200], Batch [400/750], Loss: 0.2963\n",
            "Epoch [115/200], Batch [500/750], Loss: 0.1560\n",
            "Epoch [115/200], Batch [600/750], Loss: 0.2970\n",
            "Epoch [115/200], Batch [700/750], Loss: 0.2799\n",
            "Epoch [115/200] Total train Cost: 188.5986995063722\n",
            "---------------------------------------------\n",
            "Epoch [116/200], Batch [100/750], Loss: 0.2705\n",
            "Epoch [116/200], Batch [200/750], Loss: 0.2093\n",
            "Epoch [116/200], Batch [300/750], Loss: 0.1896\n",
            "Epoch [116/200], Batch [400/750], Loss: 0.2812\n",
            "Epoch [116/200], Batch [500/750], Loss: 0.2213\n",
            "Epoch [116/200], Batch [600/750], Loss: 0.4306\n",
            "Epoch [116/200], Batch [700/750], Loss: 0.3387\n",
            "Epoch [116/200] Total train Cost: 187.9938159584999\n",
            "---------------------------------------------\n",
            "Epoch [117/200], Batch [100/750], Loss: 0.3339\n",
            "Epoch [117/200], Batch [200/750], Loss: 0.1858\n",
            "Epoch [117/200], Batch [300/750], Loss: 0.1045\n",
            "Epoch [117/200], Batch [400/750], Loss: 0.2233\n",
            "Epoch [117/200], Batch [500/750], Loss: 0.2682\n",
            "Epoch [117/200], Batch [600/750], Loss: 0.3624\n",
            "Epoch [117/200], Batch [700/750], Loss: 0.1489\n",
            "Epoch [117/200] Total train Cost: 187.36270834878087\n",
            "---------------------------------------------\n",
            "Epoch [118/200], Batch [100/750], Loss: 0.3133\n",
            "Epoch [118/200], Batch [200/750], Loss: 0.1609\n",
            "Epoch [118/200], Batch [300/750], Loss: 0.1998\n",
            "Epoch [118/200], Batch [400/750], Loss: 0.2835\n",
            "Epoch [118/200], Batch [500/750], Loss: 0.1179\n",
            "Epoch [118/200], Batch [600/750], Loss: 0.2341\n",
            "Epoch [118/200], Batch [700/750], Loss: 0.2115\n",
            "Epoch [118/200] Total train Cost: 186.73179809004068\n",
            "---------------------------------------------\n",
            "Epoch [119/200], Batch [100/750], Loss: 0.2487\n",
            "Epoch [119/200], Batch [200/750], Loss: 0.2296\n",
            "Epoch [119/200], Batch [300/750], Loss: 0.2137\n",
            "Epoch [119/200], Batch [400/750], Loss: 0.2609\n",
            "Epoch [119/200], Batch [500/750], Loss: 0.1643\n",
            "Epoch [119/200], Batch [600/750], Loss: 0.2171\n",
            "Epoch [119/200], Batch [700/750], Loss: 0.1214\n",
            "Epoch [119/200] Total train Cost: 186.15927327424288\n",
            "---------------------------------------------\n",
            "Epoch [120/200], Batch [100/750], Loss: 0.3291\n",
            "Epoch [120/200], Batch [200/750], Loss: 0.3194\n",
            "Epoch [120/200], Batch [300/750], Loss: 0.2609\n",
            "Epoch [120/200], Batch [400/750], Loss: 0.1687\n",
            "Epoch [120/200], Batch [500/750], Loss: 0.1913\n",
            "Epoch [120/200], Batch [600/750], Loss: 0.2122\n",
            "Epoch [120/200], Batch [700/750], Loss: 0.1483\n",
            "Epoch [120/200] Total train Cost: 185.524998575449\n",
            "---------------------------------------------\n",
            "Epoch [121/200], Batch [100/750], Loss: 0.1253\n",
            "Epoch [121/200], Batch [200/750], Loss: 0.4019\n",
            "Epoch [121/200], Batch [300/750], Loss: 0.5237\n",
            "Epoch [121/200], Batch [400/750], Loss: 0.3606\n",
            "Epoch [121/200], Batch [500/750], Loss: 0.1734\n",
            "Epoch [121/200], Batch [600/750], Loss: 0.1504\n",
            "Epoch [121/200], Batch [700/750], Loss: 0.2639\n",
            "Epoch [121/200] Total train Cost: 184.93752697110176\n",
            "---------------------------------------------\n",
            "Epoch [122/200], Batch [100/750], Loss: 0.3137\n",
            "Epoch [122/200], Batch [200/750], Loss: 0.2479\n",
            "Epoch [122/200], Batch [300/750], Loss: 0.1305\n",
            "Epoch [122/200], Batch [400/750], Loss: 0.1772\n",
            "Epoch [122/200], Batch [500/750], Loss: 0.2432\n",
            "Epoch [122/200], Batch [600/750], Loss: 0.2736\n",
            "Epoch [122/200], Batch [700/750], Loss: 0.2945\n",
            "Epoch [122/200] Total train Cost: 184.32903731241822\n",
            "---------------------------------------------\n",
            "Epoch [123/200], Batch [100/750], Loss: 0.3505\n",
            "Epoch [123/200], Batch [200/750], Loss: 0.1424\n",
            "Epoch [123/200], Batch [300/750], Loss: 0.2557\n",
            "Epoch [123/200], Batch [400/750], Loss: 0.2477\n",
            "Epoch [123/200], Batch [500/750], Loss: 0.1891\n",
            "Epoch [123/200], Batch [600/750], Loss: 0.3192\n",
            "Epoch [123/200], Batch [700/750], Loss: 0.3143\n",
            "Epoch [123/200] Total train Cost: 183.74315462261438\n",
            "---------------------------------------------\n",
            "Epoch [124/200], Batch [100/750], Loss: 0.2487\n",
            "Epoch [124/200], Batch [200/750], Loss: 0.2338\n",
            "Epoch [124/200], Batch [300/750], Loss: 0.2126\n",
            "Epoch [124/200], Batch [400/750], Loss: 0.2453\n",
            "Epoch [124/200], Batch [500/750], Loss: 0.2534\n",
            "Epoch [124/200], Batch [600/750], Loss: 0.1620\n",
            "Epoch [124/200], Batch [700/750], Loss: 0.1697\n",
            "Epoch [124/200] Total train Cost: 183.1577647253871\n",
            "---------------------------------------------\n",
            "Epoch [125/200], Batch [100/750], Loss: 0.2476\n",
            "Epoch [125/200], Batch [200/750], Loss: 0.3346\n",
            "Epoch [125/200], Batch [300/750], Loss: 0.1240\n",
            "Epoch [125/200], Batch [400/750], Loss: 0.1712\n",
            "Epoch [125/200], Batch [500/750], Loss: 0.1468\n",
            "Epoch [125/200], Batch [600/750], Loss: 0.2266\n",
            "Epoch [125/200], Batch [700/750], Loss: 0.1862\n",
            "Epoch [125/200] Total train Cost: 182.55583325773478\n",
            "---------------------------------------------\n",
            "Epoch [126/200], Batch [100/750], Loss: 0.1573\n",
            "Epoch [126/200], Batch [200/750], Loss: 0.3507\n",
            "Epoch [126/200], Batch [300/750], Loss: 0.3105\n",
            "Epoch [126/200], Batch [400/750], Loss: 0.1105\n",
            "Epoch [126/200], Batch [500/750], Loss: 0.3807\n",
            "Epoch [126/200], Batch [600/750], Loss: 0.2416\n",
            "Epoch [126/200], Batch [700/750], Loss: 0.1671\n",
            "Epoch [126/200] Total train Cost: 181.9906876310706\n",
            "---------------------------------------------\n",
            "Epoch [127/200], Batch [100/750], Loss: 0.1280\n",
            "Epoch [127/200], Batch [200/750], Loss: 0.1864\n",
            "Epoch [127/200], Batch [300/750], Loss: 0.2199\n",
            "Epoch [127/200], Batch [400/750], Loss: 0.2097\n",
            "Epoch [127/200], Batch [500/750], Loss: 0.1881\n",
            "Epoch [127/200], Batch [600/750], Loss: 0.2616\n",
            "Epoch [127/200], Batch [700/750], Loss: 0.2198\n",
            "Epoch [127/200] Total train Cost: 181.39019317924976\n",
            "---------------------------------------------\n",
            "Epoch [128/200], Batch [100/750], Loss: 0.1788\n",
            "Epoch [128/200], Batch [200/750], Loss: 0.3355\n",
            "Epoch [128/200], Batch [300/750], Loss: 0.1506\n",
            "Epoch [128/200], Batch [400/750], Loss: 0.2478\n",
            "Epoch [128/200], Batch [500/750], Loss: 0.1609\n",
            "Epoch [128/200], Batch [600/750], Loss: 0.1568\n",
            "Epoch [128/200], Batch [700/750], Loss: 0.2288\n",
            "Epoch [128/200] Total train Cost: 180.83568969368935\n",
            "---------------------------------------------\n",
            "Epoch [129/200], Batch [100/750], Loss: 0.3611\n",
            "Epoch [129/200], Batch [200/750], Loss: 0.2707\n",
            "Epoch [129/200], Batch [300/750], Loss: 0.2896\n",
            "Epoch [129/200], Batch [400/750], Loss: 0.2326\n",
            "Epoch [129/200], Batch [500/750], Loss: 0.3323\n",
            "Epoch [129/200], Batch [600/750], Loss: 0.1694\n",
            "Epoch [129/200], Batch [700/750], Loss: 0.1850\n",
            "Epoch [129/200] Total train Cost: 180.24791795387864\n",
            "---------------------------------------------\n",
            "Epoch [130/200], Batch [100/750], Loss: 0.2048\n",
            "Epoch [130/200], Batch [200/750], Loss: 0.1550\n",
            "Epoch [130/200], Batch [300/750], Loss: 0.3211\n",
            "Epoch [130/200], Batch [400/750], Loss: 0.2505\n",
            "Epoch [130/200], Batch [500/750], Loss: 0.1247\n",
            "Epoch [130/200], Batch [600/750], Loss: 0.1543\n",
            "Epoch [130/200], Batch [700/750], Loss: 0.1123\n",
            "Epoch [130/200] Total train Cost: 179.69500606507063\n",
            "---------------------------------------------\n",
            "Epoch [131/200], Batch [100/750], Loss: 0.1401\n",
            "Epoch [131/200], Batch [200/750], Loss: 0.2110\n",
            "Epoch [131/200], Batch [300/750], Loss: 0.2707\n",
            "Epoch [131/200], Batch [400/750], Loss: 0.3093\n",
            "Epoch [131/200], Batch [500/750], Loss: 0.2539\n",
            "Epoch [131/200], Batch [600/750], Loss: 0.1056\n",
            "Epoch [131/200], Batch [700/750], Loss: 0.3013\n",
            "Epoch [131/200] Total train Cost: 179.10332766920328\n",
            "---------------------------------------------\n",
            "Epoch [132/200], Batch [100/750], Loss: 0.2447\n",
            "Epoch [132/200], Batch [200/750], Loss: 0.3158\n",
            "Epoch [132/200], Batch [300/750], Loss: 0.1957\n",
            "Epoch [132/200], Batch [400/750], Loss: 0.4031\n",
            "Epoch [132/200], Batch [500/750], Loss: 0.2267\n",
            "Epoch [132/200], Batch [600/750], Loss: 0.3598\n",
            "Epoch [132/200], Batch [700/750], Loss: 0.2201\n",
            "Epoch [132/200] Total train Cost: 178.56389168649912\n",
            "---------------------------------------------\n",
            "Epoch [133/200], Batch [100/750], Loss: 0.2501\n",
            "Epoch [133/200], Batch [200/750], Loss: 0.2306\n",
            "Epoch [133/200], Batch [300/750], Loss: 0.1898\n",
            "Epoch [133/200], Batch [400/750], Loss: 0.3269\n",
            "Epoch [133/200], Batch [500/750], Loss: 0.1870\n",
            "Epoch [133/200], Batch [600/750], Loss: 0.0941\n",
            "Epoch [133/200], Batch [700/750], Loss: 0.2136\n",
            "Epoch [133/200] Total train Cost: 177.98637231439352\n",
            "---------------------------------------------\n",
            "Epoch [134/200], Batch [100/750], Loss: 0.2250\n",
            "Epoch [134/200], Batch [200/750], Loss: 0.4617\n",
            "Epoch [134/200], Batch [300/750], Loss: 0.1665\n",
            "Epoch [134/200], Batch [400/750], Loss: 0.3365\n",
            "Epoch [134/200], Batch [500/750], Loss: 0.3851\n",
            "Epoch [134/200], Batch [600/750], Loss: 0.1565\n",
            "Epoch [134/200], Batch [700/750], Loss: 0.2764\n",
            "Epoch [134/200] Total train Cost: 177.43570233881474\n",
            "---------------------------------------------\n",
            "Epoch [135/200], Batch [100/750], Loss: 0.1681\n",
            "Epoch [135/200], Batch [200/750], Loss: 0.1400\n",
            "Epoch [135/200], Batch [300/750], Loss: 0.3504\n",
            "Epoch [135/200], Batch [400/750], Loss: 0.1474\n",
            "Epoch [135/200], Batch [500/750], Loss: 0.1187\n",
            "Epoch [135/200], Batch [600/750], Loss: 0.3154\n",
            "Epoch [135/200], Batch [700/750], Loss: 0.1424\n",
            "Epoch [135/200] Total train Cost: 176.89011679962277\n",
            "---------------------------------------------\n",
            "Epoch [136/200], Batch [100/750], Loss: 0.2854\n",
            "Epoch [136/200], Batch [200/750], Loss: 0.1833\n",
            "Epoch [136/200], Batch [300/750], Loss: 0.3302\n",
            "Epoch [136/200], Batch [400/750], Loss: 0.2131\n",
            "Epoch [136/200], Batch [500/750], Loss: 0.1337\n",
            "Epoch [136/200], Batch [600/750], Loss: 0.4884\n",
            "Epoch [136/200], Batch [700/750], Loss: 0.1778\n",
            "Epoch [136/200] Total train Cost: 176.34611247852445\n",
            "---------------------------------------------\n",
            "Epoch [137/200], Batch [100/750], Loss: 0.3387\n",
            "Epoch [137/200], Batch [200/750], Loss: 0.3791\n",
            "Epoch [137/200], Batch [300/750], Loss: 0.1693\n",
            "Epoch [137/200], Batch [400/750], Loss: 0.2180\n",
            "Epoch [137/200], Batch [500/750], Loss: 0.3307\n",
            "Epoch [137/200], Batch [600/750], Loss: 0.1550\n",
            "Epoch [137/200], Batch [700/750], Loss: 0.2770\n",
            "Epoch [137/200] Total train Cost: 175.79484988376498\n",
            "---------------------------------------------\n",
            "Epoch [138/200], Batch [100/750], Loss: 0.2431\n",
            "Epoch [138/200], Batch [200/750], Loss: 0.2406\n",
            "Epoch [138/200], Batch [300/750], Loss: 0.2990\n",
            "Epoch [138/200], Batch [400/750], Loss: 0.2185\n",
            "Epoch [138/200], Batch [500/750], Loss: 0.1480\n",
            "Epoch [138/200], Batch [600/750], Loss: 0.2388\n",
            "Epoch [138/200], Batch [700/750], Loss: 0.3454\n",
            "Epoch [138/200] Total train Cost: 175.25834030285478\n",
            "---------------------------------------------\n",
            "Epoch [139/200], Batch [100/750], Loss: 0.3550\n",
            "Epoch [139/200], Batch [200/750], Loss: 0.1129\n",
            "Epoch [139/200], Batch [300/750], Loss: 0.2141\n",
            "Epoch [139/200], Batch [400/750], Loss: 0.1575\n",
            "Epoch [139/200], Batch [500/750], Loss: 0.2376\n",
            "Epoch [139/200], Batch [600/750], Loss: 0.1227\n",
            "Epoch [139/200], Batch [700/750], Loss: 0.2025\n",
            "Epoch [139/200] Total train Cost: 174.7243372388184\n",
            "---------------------------------------------\n",
            "Epoch [140/200], Batch [100/750], Loss: 0.1868\n",
            "Epoch [140/200], Batch [200/750], Loss: 0.3971\n",
            "Epoch [140/200], Batch [300/750], Loss: 0.2102\n",
            "Epoch [140/200], Batch [400/750], Loss: 0.3679\n",
            "Epoch [140/200], Batch [500/750], Loss: 0.1747\n",
            "Epoch [140/200], Batch [600/750], Loss: 0.1940\n",
            "Epoch [140/200], Batch [700/750], Loss: 0.2591\n",
            "Epoch [140/200] Total train Cost: 174.17273638769984\n",
            "---------------------------------------------\n",
            "Epoch [141/200], Batch [100/750], Loss: 0.2751\n",
            "Epoch [141/200], Batch [200/750], Loss: 0.2974\n",
            "Epoch [141/200], Batch [300/750], Loss: 0.1545\n",
            "Epoch [141/200], Batch [400/750], Loss: 0.0889\n",
            "Epoch [141/200], Batch [500/750], Loss: 0.2912\n",
            "Epoch [141/200], Batch [600/750], Loss: 0.3833\n",
            "Epoch [141/200], Batch [700/750], Loss: 0.1887\n",
            "Epoch [141/200] Total train Cost: 173.64551055058837\n",
            "---------------------------------------------\n",
            "Epoch [142/200], Batch [100/750], Loss: 0.2125\n",
            "Epoch [142/200], Batch [200/750], Loss: 0.1761\n",
            "Epoch [142/200], Batch [300/750], Loss: 0.1119\n",
            "Epoch [142/200], Batch [400/750], Loss: 0.3352\n",
            "Epoch [142/200], Batch [500/750], Loss: 0.2320\n",
            "Epoch [142/200], Batch [600/750], Loss: 0.1697\n",
            "Epoch [142/200], Batch [700/750], Loss: 0.2112\n",
            "Epoch [142/200] Total train Cost: 173.12996815517545\n",
            "---------------------------------------------\n",
            "Epoch [143/200], Batch [100/750], Loss: 0.2251\n",
            "Epoch [143/200], Batch [200/750], Loss: 0.2655\n",
            "Epoch [143/200], Batch [300/750], Loss: 0.0932\n",
            "Epoch [143/200], Batch [400/750], Loss: 0.1137\n",
            "Epoch [143/200], Batch [500/750], Loss: 0.1732\n",
            "Epoch [143/200], Batch [600/750], Loss: 0.1832\n",
            "Epoch [143/200], Batch [700/750], Loss: 0.1229\n",
            "Epoch [143/200] Total train Cost: 172.60917145758867\n",
            "---------------------------------------------\n",
            "Epoch [144/200], Batch [100/750], Loss: 0.2550\n",
            "Epoch [144/200], Batch [200/750], Loss: 0.1808\n",
            "Epoch [144/200], Batch [300/750], Loss: 0.3737\n",
            "Epoch [144/200], Batch [400/750], Loss: 0.2097\n",
            "Epoch [144/200], Batch [500/750], Loss: 0.2444\n",
            "Epoch [144/200], Batch [600/750], Loss: 0.1078\n",
            "Epoch [144/200], Batch [700/750], Loss: 0.4671\n",
            "Epoch [144/200] Total train Cost: 172.08052882924676\n",
            "---------------------------------------------\n",
            "Epoch [145/200], Batch [100/750], Loss: 0.1781\n",
            "Epoch [145/200], Batch [200/750], Loss: 0.1180\n",
            "Epoch [145/200], Batch [300/750], Loss: 0.3140\n",
            "Epoch [145/200], Batch [400/750], Loss: 0.3961\n",
            "Epoch [145/200], Batch [500/750], Loss: 0.2853\n",
            "Epoch [145/200], Batch [600/750], Loss: 0.3361\n",
            "Epoch [145/200], Batch [700/750], Loss: 0.2347\n",
            "Epoch [145/200] Total train Cost: 171.55632190033793\n",
            "---------------------------------------------\n",
            "Epoch [146/200], Batch [100/750], Loss: 0.3841\n",
            "Epoch [146/200], Batch [200/750], Loss: 0.1374\n",
            "Epoch [146/200], Batch [300/750], Loss: 0.1954\n",
            "Epoch [146/200], Batch [400/750], Loss: 0.3569\n",
            "Epoch [146/200], Batch [500/750], Loss: 0.2634\n",
            "Epoch [146/200], Batch [600/750], Loss: 0.1044\n",
            "Epoch [146/200], Batch [700/750], Loss: 0.2788\n",
            "Epoch [146/200] Total train Cost: 171.05785679072142\n",
            "---------------------------------------------\n",
            "Epoch [147/200], Batch [100/750], Loss: 0.3272\n",
            "Epoch [147/200], Batch [200/750], Loss: 0.3694\n",
            "Epoch [147/200], Batch [300/750], Loss: 0.1640\n",
            "Epoch [147/200], Batch [400/750], Loss: 0.3292\n",
            "Epoch [147/200], Batch [500/750], Loss: 0.1521\n",
            "Epoch [147/200], Batch [600/750], Loss: 0.3826\n",
            "Epoch [147/200], Batch [700/750], Loss: 0.1698\n",
            "Epoch [147/200] Total train Cost: 170.5288711488247\n",
            "---------------------------------------------\n",
            "Epoch [148/200], Batch [100/750], Loss: 0.2822\n",
            "Epoch [148/200], Batch [200/750], Loss: 0.1489\n",
            "Epoch [148/200], Batch [300/750], Loss: 0.2488\n",
            "Epoch [148/200], Batch [400/750], Loss: 0.1806\n",
            "Epoch [148/200], Batch [500/750], Loss: 0.2372\n",
            "Epoch [148/200], Batch [600/750], Loss: 0.2214\n",
            "Epoch [148/200], Batch [700/750], Loss: 0.4025\n",
            "Epoch [148/200] Total train Cost: 169.9914829134941\n",
            "---------------------------------------------\n",
            "Epoch [149/200], Batch [100/750], Loss: 0.3882\n",
            "Epoch [149/200], Batch [200/750], Loss: 0.0988\n",
            "Epoch [149/200], Batch [300/750], Loss: 0.2684\n",
            "Epoch [149/200], Batch [400/750], Loss: 0.1594\n",
            "Epoch [149/200], Batch [500/750], Loss: 0.2604\n",
            "Epoch [149/200], Batch [600/750], Loss: 0.2507\n",
            "Epoch [149/200], Batch [700/750], Loss: 0.3951\n",
            "Epoch [149/200] Total train Cost: 169.50575483590364\n",
            "---------------------------------------------\n",
            "Epoch [150/200], Batch [100/750], Loss: 0.1547\n",
            "Epoch [150/200], Batch [200/750], Loss: 0.4395\n",
            "Epoch [150/200], Batch [300/750], Loss: 0.3689\n",
            "Epoch [150/200], Batch [400/750], Loss: 0.3211\n",
            "Epoch [150/200], Batch [500/750], Loss: 0.2074\n",
            "Epoch [150/200], Batch [600/750], Loss: 0.2796\n",
            "Epoch [150/200], Batch [700/750], Loss: 0.2127\n",
            "Epoch [150/200] Total train Cost: 169.0229711011052\n",
            "---------------------------------------------\n",
            "Epoch [151/200], Batch [100/750], Loss: 0.2294\n",
            "Epoch [151/200], Batch [200/750], Loss: 0.1486\n",
            "Epoch [151/200], Batch [300/750], Loss: 0.2798\n",
            "Epoch [151/200], Batch [400/750], Loss: 0.2087\n",
            "Epoch [151/200], Batch [500/750], Loss: 0.1958\n",
            "Epoch [151/200], Batch [600/750], Loss: 0.2346\n",
            "Epoch [151/200], Batch [700/750], Loss: 0.3530\n",
            "Epoch [151/200] Total train Cost: 168.50488364696503\n",
            "---------------------------------------------\n",
            "Epoch [152/200], Batch [100/750], Loss: 0.3051\n",
            "Epoch [152/200], Batch [200/750], Loss: 0.3800\n",
            "Epoch [152/200], Batch [300/750], Loss: 0.2422\n",
            "Epoch [152/200], Batch [400/750], Loss: 0.1027\n",
            "Epoch [152/200], Batch [500/750], Loss: 0.1916\n",
            "Epoch [152/200], Batch [600/750], Loss: 0.1751\n",
            "Epoch [152/200], Batch [700/750], Loss: 0.2626\n",
            "Epoch [152/200] Total train Cost: 168.00887801870704\n",
            "---------------------------------------------\n",
            "Epoch [153/200], Batch [100/750], Loss: 0.1876\n",
            "Epoch [153/200], Batch [200/750], Loss: 0.1664\n",
            "Epoch [153/200], Batch [300/750], Loss: 0.1827\n",
            "Epoch [153/200], Batch [400/750], Loss: 0.1811\n",
            "Epoch [153/200], Batch [500/750], Loss: 0.2417\n",
            "Epoch [153/200], Batch [600/750], Loss: 0.2300\n",
            "Epoch [153/200], Batch [700/750], Loss: 0.2189\n",
            "Epoch [153/200] Total train Cost: 167.46618962287903\n",
            "---------------------------------------------\n",
            "Epoch [154/200], Batch [100/750], Loss: 0.2964\n",
            "Epoch [154/200], Batch [200/750], Loss: 0.2231\n",
            "Epoch [154/200], Batch [300/750], Loss: 0.2267\n",
            "Epoch [154/200], Batch [400/750], Loss: 0.2927\n",
            "Epoch [154/200], Batch [500/750], Loss: 0.1118\n",
            "Epoch [154/200], Batch [600/750], Loss: 0.3277\n",
            "Epoch [154/200], Batch [700/750], Loss: 0.3086\n",
            "Epoch [154/200] Total train Cost: 167.04139986634254\n",
            "---------------------------------------------\n",
            "Epoch [155/200], Batch [100/750], Loss: 0.2156\n",
            "Epoch [155/200], Batch [200/750], Loss: 0.1553\n",
            "Epoch [155/200], Batch [300/750], Loss: 0.2354\n",
            "Epoch [155/200], Batch [400/750], Loss: 0.3090\n",
            "Epoch [155/200], Batch [500/750], Loss: 0.0993\n",
            "Epoch [155/200], Batch [600/750], Loss: 0.2446\n",
            "Epoch [155/200], Batch [700/750], Loss: 0.2769\n",
            "Epoch [155/200] Total train Cost: 166.54229487106204\n",
            "---------------------------------------------\n",
            "Epoch [156/200], Batch [100/750], Loss: 0.1583\n",
            "Epoch [156/200], Batch [200/750], Loss: 0.3312\n",
            "Epoch [156/200], Batch [300/750], Loss: 0.1340\n",
            "Epoch [156/200], Batch [400/750], Loss: 0.1359\n",
            "Epoch [156/200], Batch [500/750], Loss: 0.2038\n",
            "Epoch [156/200], Batch [600/750], Loss: 0.2350\n",
            "Epoch [156/200], Batch [700/750], Loss: 0.1193\n",
            "Epoch [156/200] Total train Cost: 166.02662286534905\n",
            "---------------------------------------------\n",
            "Epoch [157/200], Batch [100/750], Loss: 0.1319\n",
            "Epoch [157/200], Batch [200/750], Loss: 0.0571\n",
            "Epoch [157/200], Batch [300/750], Loss: 0.2577\n",
            "Epoch [157/200], Batch [400/750], Loss: 0.1195\n",
            "Epoch [157/200], Batch [500/750], Loss: 0.1190\n",
            "Epoch [157/200], Batch [600/750], Loss: 0.2273\n",
            "Epoch [157/200], Batch [700/750], Loss: 0.5702\n",
            "Epoch [157/200] Total train Cost: 165.55941381677985\n",
            "---------------------------------------------\n",
            "Epoch [158/200], Batch [100/750], Loss: 0.2834\n",
            "Epoch [158/200], Batch [200/750], Loss: 0.2486\n",
            "Epoch [158/200], Batch [300/750], Loss: 0.2873\n",
            "Epoch [158/200], Batch [400/750], Loss: 0.3443\n",
            "Epoch [158/200], Batch [500/750], Loss: 0.1022\n",
            "Epoch [158/200], Batch [600/750], Loss: 0.3360\n",
            "Epoch [158/200], Batch [700/750], Loss: 0.0849\n",
            "Epoch [158/200] Total train Cost: 165.07294964045286\n",
            "---------------------------------------------\n",
            "Epoch [159/200], Batch [100/750], Loss: 0.1722\n",
            "Epoch [159/200], Batch [200/750], Loss: 0.2289\n",
            "Epoch [159/200], Batch [300/750], Loss: 0.2678\n",
            "Epoch [159/200], Batch [400/750], Loss: 0.1554\n",
            "Epoch [159/200], Batch [500/750], Loss: 0.2558\n",
            "Epoch [159/200], Batch [600/750], Loss: 0.1359\n",
            "Epoch [159/200], Batch [700/750], Loss: 0.4275\n",
            "Epoch [159/200] Total train Cost: 164.58746080845594\n",
            "---------------------------------------------\n",
            "Epoch [160/200], Batch [100/750], Loss: 0.1039\n",
            "Epoch [160/200], Batch [200/750], Loss: 0.2346\n",
            "Epoch [160/200], Batch [300/750], Loss: 0.2226\n",
            "Epoch [160/200], Batch [400/750], Loss: 0.2035\n",
            "Epoch [160/200], Batch [500/750], Loss: 0.3277\n",
            "Epoch [160/200], Batch [600/750], Loss: 0.3723\n",
            "Epoch [160/200], Batch [700/750], Loss: 0.2075\n",
            "Epoch [160/200] Total train Cost: 164.1287970468402\n",
            "---------------------------------------------\n",
            "Epoch [161/200], Batch [100/750], Loss: 0.1631\n",
            "Epoch [161/200], Batch [200/750], Loss: 0.1659\n",
            "Epoch [161/200], Batch [300/750], Loss: 0.2865\n",
            "Epoch [161/200], Batch [400/750], Loss: 0.0873\n",
            "Epoch [161/200], Batch [500/750], Loss: 0.1036\n",
            "Epoch [161/200], Batch [600/750], Loss: 0.1580\n",
            "Epoch [161/200], Batch [700/750], Loss: 0.2785\n",
            "Epoch [161/200] Total train Cost: 163.63513224199414\n",
            "---------------------------------------------\n",
            "Epoch [162/200], Batch [100/750], Loss: 0.1385\n",
            "Epoch [162/200], Batch [200/750], Loss: 0.2477\n",
            "Epoch [162/200], Batch [300/750], Loss: 0.2052\n",
            "Epoch [162/200], Batch [400/750], Loss: 0.4042\n",
            "Epoch [162/200], Batch [500/750], Loss: 0.2110\n",
            "Epoch [162/200], Batch [600/750], Loss: 0.1050\n",
            "Epoch [162/200], Batch [700/750], Loss: 0.2582\n",
            "Epoch [162/200] Total train Cost: 163.1462989449501\n",
            "---------------------------------------------\n",
            "Epoch [163/200], Batch [100/750], Loss: 0.1384\n",
            "Epoch [163/200], Batch [200/750], Loss: 0.1824\n",
            "Epoch [163/200], Batch [300/750], Loss: 0.1367\n",
            "Epoch [163/200], Batch [400/750], Loss: 0.1306\n",
            "Epoch [163/200], Batch [500/750], Loss: 0.2900\n",
            "Epoch [163/200], Batch [600/750], Loss: 0.3009\n",
            "Epoch [163/200], Batch [700/750], Loss: 0.2283\n",
            "Epoch [163/200] Total train Cost: 162.6819856762886\n",
            "---------------------------------------------\n",
            "Epoch [164/200], Batch [100/750], Loss: 0.3345\n",
            "Epoch [164/200], Batch [200/750], Loss: 0.2734\n",
            "Epoch [164/200], Batch [300/750], Loss: 0.1472\n",
            "Epoch [164/200], Batch [400/750], Loss: 0.3503\n",
            "Epoch [164/200], Batch [500/750], Loss: 0.2616\n",
            "Epoch [164/200], Batch [600/750], Loss: 0.2887\n",
            "Epoch [164/200], Batch [700/750], Loss: 0.2166\n",
            "Epoch [164/200] Total train Cost: 162.22271965444088\n",
            "---------------------------------------------\n",
            "Epoch [165/200], Batch [100/750], Loss: 0.1225\n",
            "Epoch [165/200], Batch [200/750], Loss: 0.2978\n",
            "Epoch [165/200], Batch [300/750], Loss: 0.2282\n",
            "Epoch [165/200], Batch [400/750], Loss: 0.0924\n",
            "Epoch [165/200], Batch [500/750], Loss: 0.1419\n",
            "Epoch [165/200], Batch [600/750], Loss: 0.2026\n",
            "Epoch [165/200], Batch [700/750], Loss: 0.1895\n",
            "Epoch [165/200] Total train Cost: 161.74239008128643\n",
            "---------------------------------------------\n",
            "Epoch [166/200], Batch [100/750], Loss: 0.0720\n",
            "Epoch [166/200], Batch [200/750], Loss: 0.2389\n",
            "Epoch [166/200], Batch [300/750], Loss: 0.4469\n",
            "Epoch [166/200], Batch [400/750], Loss: 0.2942\n",
            "Epoch [166/200], Batch [500/750], Loss: 0.1267\n",
            "Epoch [166/200], Batch [600/750], Loss: 0.1181\n",
            "Epoch [166/200], Batch [700/750], Loss: 0.2632\n",
            "Epoch [166/200] Total train Cost: 161.29361817985773\n",
            "---------------------------------------------\n",
            "Epoch [167/200], Batch [100/750], Loss: 0.3464\n",
            "Epoch [167/200], Batch [200/750], Loss: 0.1083\n",
            "Epoch [167/200], Batch [300/750], Loss: 0.1569\n",
            "Epoch [167/200], Batch [400/750], Loss: 0.1325\n",
            "Epoch [167/200], Batch [500/750], Loss: 0.2149\n",
            "Epoch [167/200], Batch [600/750], Loss: 0.1098\n",
            "Epoch [167/200], Batch [700/750], Loss: 0.1927\n",
            "Epoch [167/200] Total train Cost: 160.82927884534\n",
            "---------------------------------------------\n",
            "Epoch [168/200], Batch [100/750], Loss: 0.1725\n",
            "Epoch [168/200], Batch [200/750], Loss: 0.2165\n",
            "Epoch [168/200], Batch [300/750], Loss: 0.3207\n",
            "Epoch [168/200], Batch [400/750], Loss: 0.1692\n",
            "Epoch [168/200], Batch [500/750], Loss: 0.2837\n",
            "Epoch [168/200], Batch [600/750], Loss: 0.3351\n",
            "Epoch [168/200], Batch [700/750], Loss: 0.1481\n",
            "Epoch [168/200] Total train Cost: 160.3704448863864\n",
            "---------------------------------------------\n",
            "Epoch [169/200], Batch [100/750], Loss: 0.1828\n",
            "Epoch [169/200], Batch [200/750], Loss: 0.3164\n",
            "Epoch [169/200], Batch [300/750], Loss: 0.1417\n",
            "Epoch [169/200], Batch [400/750], Loss: 0.2739\n",
            "Epoch [169/200], Batch [500/750], Loss: 0.3370\n",
            "Epoch [169/200], Batch [600/750], Loss: 0.2951\n",
            "Epoch [169/200], Batch [700/750], Loss: 0.1991\n",
            "Epoch [169/200] Total train Cost: 159.89699478447437\n",
            "---------------------------------------------\n",
            "Epoch [170/200], Batch [100/750], Loss: 0.1896\n",
            "Epoch [170/200], Batch [200/750], Loss: 0.1492\n",
            "Epoch [170/200], Batch [300/750], Loss: 0.2002\n",
            "Epoch [170/200], Batch [400/750], Loss: 0.3049\n",
            "Epoch [170/200], Batch [500/750], Loss: 0.2030\n",
            "Epoch [170/200], Batch [600/750], Loss: 0.1766\n",
            "Epoch [170/200], Batch [700/750], Loss: 0.2233\n",
            "Epoch [170/200] Total train Cost: 159.4524189159274\n",
            "---------------------------------------------\n",
            "Epoch [171/200], Batch [100/750], Loss: 0.1399\n",
            "Epoch [171/200], Batch [200/750], Loss: 0.3492\n",
            "Epoch [171/200], Batch [300/750], Loss: 0.3240\n",
            "Epoch [171/200], Batch [400/750], Loss: 0.1830\n",
            "Epoch [171/200], Batch [500/750], Loss: 0.1204\n",
            "Epoch [171/200], Batch [600/750], Loss: 0.3423\n",
            "Epoch [171/200], Batch [700/750], Loss: 0.2089\n",
            "Epoch [171/200] Total train Cost: 158.99617974460125\n",
            "---------------------------------------------\n",
            "Epoch [172/200], Batch [100/750], Loss: 0.2486\n",
            "Epoch [172/200], Batch [200/750], Loss: 0.1960\n",
            "Epoch [172/200], Batch [300/750], Loss: 0.2638\n",
            "Epoch [172/200], Batch [400/750], Loss: 0.1873\n",
            "Epoch [172/200], Batch [500/750], Loss: 0.2598\n",
            "Epoch [172/200], Batch [600/750], Loss: 0.1289\n",
            "Epoch [172/200], Batch [700/750], Loss: 0.4098\n",
            "Epoch [172/200] Total train Cost: 158.54970367625356\n",
            "---------------------------------------------\n",
            "Epoch [173/200], Batch [100/750], Loss: 0.1527\n",
            "Epoch [173/200], Batch [200/750], Loss: 0.0926\n",
            "Epoch [173/200], Batch [300/750], Loss: 0.1485\n",
            "Epoch [173/200], Batch [400/750], Loss: 0.1306\n",
            "Epoch [173/200], Batch [500/750], Loss: 0.2510\n",
            "Epoch [173/200], Batch [600/750], Loss: 0.1385\n",
            "Epoch [173/200], Batch [700/750], Loss: 0.1643\n",
            "Epoch [173/200] Total train Cost: 158.09866396337748\n",
            "---------------------------------------------\n",
            "Epoch [174/200], Batch [100/750], Loss: 0.1110\n",
            "Epoch [174/200], Batch [200/750], Loss: 0.1505\n",
            "Epoch [174/200], Batch [300/750], Loss: 0.3039\n",
            "Epoch [174/200], Batch [400/750], Loss: 0.1326\n",
            "Epoch [174/200], Batch [500/750], Loss: 0.2232\n",
            "Epoch [174/200], Batch [600/750], Loss: 0.1576\n",
            "Epoch [174/200], Batch [700/750], Loss: 0.1980\n",
            "Epoch [174/200] Total train Cost: 157.65286238491535\n",
            "---------------------------------------------\n",
            "Epoch [175/200], Batch [100/750], Loss: 0.0702\n",
            "Epoch [175/200], Batch [200/750], Loss: 0.1655\n",
            "Epoch [175/200], Batch [300/750], Loss: 0.3695\n",
            "Epoch [175/200], Batch [400/750], Loss: 0.1762\n",
            "Epoch [175/200], Batch [500/750], Loss: 0.1796\n",
            "Epoch [175/200], Batch [600/750], Loss: 0.1001\n",
            "Epoch [175/200], Batch [700/750], Loss: 0.3494\n",
            "Epoch [175/200] Total train Cost: 157.21282923594117\n",
            "---------------------------------------------\n",
            "Epoch [176/200], Batch [100/750], Loss: 0.2370\n",
            "Epoch [176/200], Batch [200/750], Loss: 0.1104\n",
            "Epoch [176/200], Batch [300/750], Loss: 0.2148\n",
            "Epoch [176/200], Batch [400/750], Loss: 0.1560\n",
            "Epoch [176/200], Batch [500/750], Loss: 0.1814\n",
            "Epoch [176/200], Batch [600/750], Loss: 0.1370\n",
            "Epoch [176/200], Batch [700/750], Loss: 0.0865\n",
            "Epoch [176/200] Total train Cost: 156.7558394111693\n",
            "---------------------------------------------\n",
            "Epoch [177/200], Batch [100/750], Loss: 0.2437\n",
            "Epoch [177/200], Batch [200/750], Loss: 0.1170\n",
            "Epoch [177/200], Batch [300/750], Loss: 0.2639\n",
            "Epoch [177/200], Batch [400/750], Loss: 0.3122\n",
            "Epoch [177/200], Batch [500/750], Loss: 0.2431\n",
            "Epoch [177/200], Batch [600/750], Loss: 0.0950\n",
            "Epoch [177/200], Batch [700/750], Loss: 0.1159\n",
            "Epoch [177/200] Total train Cost: 156.30668555945158\n",
            "---------------------------------------------\n",
            "Epoch [178/200], Batch [100/750], Loss: 0.1252\n",
            "Epoch [178/200], Batch [200/750], Loss: 0.2754\n",
            "Epoch [178/200], Batch [300/750], Loss: 0.0924\n",
            "Epoch [178/200], Batch [400/750], Loss: 0.2920\n",
            "Epoch [178/200], Batch [500/750], Loss: 0.1483\n",
            "Epoch [178/200], Batch [600/750], Loss: 0.1711\n",
            "Epoch [178/200], Batch [700/750], Loss: 0.1050\n",
            "Epoch [178/200] Total train Cost: 155.858992241323\n",
            "---------------------------------------------\n",
            "Epoch [179/200], Batch [100/750], Loss: 0.2504\n",
            "Epoch [179/200], Batch [200/750], Loss: 0.1443\n",
            "Epoch [179/200], Batch [300/750], Loss: 0.1216\n",
            "Epoch [179/200], Batch [400/750], Loss: 0.1582\n",
            "Epoch [179/200], Batch [500/750], Loss: 0.1110\n",
            "Epoch [179/200], Batch [600/750], Loss: 0.1292\n",
            "Epoch [179/200], Batch [700/750], Loss: 0.2627\n",
            "Epoch [179/200] Total train Cost: 155.4527828283608\n",
            "---------------------------------------------\n",
            "Epoch [180/200], Batch [100/750], Loss: 0.1623\n",
            "Epoch [180/200], Batch [200/750], Loss: 0.3446\n",
            "Epoch [180/200], Batch [300/750], Loss: 0.1418\n",
            "Epoch [180/200], Batch [400/750], Loss: 0.1145\n",
            "Epoch [180/200], Batch [500/750], Loss: 0.2056\n",
            "Epoch [180/200], Batch [600/750], Loss: 0.1475\n",
            "Epoch [180/200], Batch [700/750], Loss: 0.1168\n",
            "Epoch [180/200] Total train Cost: 155.0005168132484\n",
            "---------------------------------------------\n",
            "Epoch [181/200], Batch [100/750], Loss: 0.0970\n",
            "Epoch [181/200], Batch [200/750], Loss: 0.2810\n",
            "Epoch [181/200], Batch [300/750], Loss: 0.1966\n",
            "Epoch [181/200], Batch [400/750], Loss: 0.2623\n",
            "Epoch [181/200], Batch [500/750], Loss: 0.2143\n",
            "Epoch [181/200], Batch [600/750], Loss: 0.1492\n",
            "Epoch [181/200], Batch [700/750], Loss: 0.1079\n",
            "Epoch [181/200] Total train Cost: 154.57630576193333\n",
            "---------------------------------------------\n",
            "Epoch [182/200], Batch [100/750], Loss: 0.1291\n",
            "Epoch [182/200], Batch [200/750], Loss: 0.2739\n",
            "Epoch [182/200], Batch [300/750], Loss: 0.1336\n",
            "Epoch [182/200], Batch [400/750], Loss: 0.1136\n",
            "Epoch [182/200], Batch [500/750], Loss: 0.2127\n",
            "Epoch [182/200], Batch [600/750], Loss: 0.2115\n",
            "Epoch [182/200], Batch [700/750], Loss: 0.1390\n",
            "Epoch [182/200] Total train Cost: 154.1453763321042\n",
            "---------------------------------------------\n",
            "Epoch [183/200], Batch [100/750], Loss: 0.2097\n",
            "Epoch [183/200], Batch [200/750], Loss: 0.2867\n",
            "Epoch [183/200], Batch [300/750], Loss: 0.1604\n",
            "Epoch [183/200], Batch [400/750], Loss: 0.2213\n",
            "Epoch [183/200], Batch [500/750], Loss: 0.1328\n",
            "Epoch [183/200], Batch [600/750], Loss: 0.2746\n",
            "Epoch [183/200], Batch [700/750], Loss: 0.1827\n",
            "Epoch [183/200] Total train Cost: 153.70617033913732\n",
            "---------------------------------------------\n",
            "Epoch [184/200], Batch [100/750], Loss: 0.2405\n",
            "Epoch [184/200], Batch [200/750], Loss: 0.2043\n",
            "Epoch [184/200], Batch [300/750], Loss: 0.3029\n",
            "Epoch [184/200], Batch [400/750], Loss: 0.2391\n",
            "Epoch [184/200], Batch [500/750], Loss: 0.1960\n",
            "Epoch [184/200], Batch [600/750], Loss: 0.2018\n",
            "Epoch [184/200], Batch [700/750], Loss: 0.1765\n",
            "Epoch [184/200] Total train Cost: 153.286790125072\n",
            "---------------------------------------------\n",
            "Epoch [185/200], Batch [100/750], Loss: 0.1519\n",
            "Epoch [185/200], Batch [200/750], Loss: 0.1344\n",
            "Epoch [185/200], Batch [300/750], Loss: 0.0784\n",
            "Epoch [185/200], Batch [400/750], Loss: 0.2683\n",
            "Epoch [185/200], Batch [500/750], Loss: 0.1157\n",
            "Epoch [185/200], Batch [600/750], Loss: 0.2532\n",
            "Epoch [185/200], Batch [700/750], Loss: 0.3027\n",
            "Epoch [185/200] Total train Cost: 152.86620074883103\n",
            "---------------------------------------------\n",
            "Epoch [186/200], Batch [100/750], Loss: 0.3553\n",
            "Epoch [186/200], Batch [200/750], Loss: 0.1974\n",
            "Epoch [186/200], Batch [300/750], Loss: 0.1264\n",
            "Epoch [186/200], Batch [400/750], Loss: 0.2976\n",
            "Epoch [186/200], Batch [500/750], Loss: 0.1666\n",
            "Epoch [186/200], Batch [600/750], Loss: 0.2381\n",
            "Epoch [186/200], Batch [700/750], Loss: 0.1936\n",
            "Epoch [186/200] Total train Cost: 152.4381790421903\n",
            "---------------------------------------------\n",
            "Epoch [187/200], Batch [100/750], Loss: 0.3842\n",
            "Epoch [187/200], Batch [200/750], Loss: 0.2419\n",
            "Epoch [187/200], Batch [300/750], Loss: 0.3511\n",
            "Epoch [187/200], Batch [400/750], Loss: 0.1388\n",
            "Epoch [187/200], Batch [500/750], Loss: 0.1783\n",
            "Epoch [187/200], Batch [600/750], Loss: 0.2839\n",
            "Epoch [187/200], Batch [700/750], Loss: 0.1601\n",
            "Epoch [187/200] Total train Cost: 152.0069022886455\n",
            "---------------------------------------------\n",
            "Epoch [188/200], Batch [100/750], Loss: 0.2431\n",
            "Epoch [188/200], Batch [200/750], Loss: 0.0906\n",
            "Epoch [188/200], Batch [300/750], Loss: 0.2800\n",
            "Epoch [188/200], Batch [400/750], Loss: 0.2952\n",
            "Epoch [188/200], Batch [500/750], Loss: 0.1366\n",
            "Epoch [188/200], Batch [600/750], Loss: 0.1584\n",
            "Epoch [188/200], Batch [700/750], Loss: 0.0918\n",
            "Epoch [188/200] Total train Cost: 151.60171361267567\n",
            "---------------------------------------------\n",
            "Epoch [189/200], Batch [100/750], Loss: 0.1875\n",
            "Epoch [189/200], Batch [200/750], Loss: 0.3458\n",
            "Epoch [189/200], Batch [300/750], Loss: 0.2022\n",
            "Epoch [189/200], Batch [400/750], Loss: 0.1804\n",
            "Epoch [189/200], Batch [500/750], Loss: 0.2087\n",
            "Epoch [189/200], Batch [600/750], Loss: 0.1940\n",
            "Epoch [189/200], Batch [700/750], Loss: 0.1168\n",
            "Epoch [189/200] Total train Cost: 151.17127177119255\n",
            "---------------------------------------------\n",
            "Epoch [190/200], Batch [100/750], Loss: 0.1427\n",
            "Epoch [190/200], Batch [200/750], Loss: 0.2067\n",
            "Epoch [190/200], Batch [300/750], Loss: 0.1715\n",
            "Epoch [190/200], Batch [400/750], Loss: 0.2602\n",
            "Epoch [190/200], Batch [500/750], Loss: 0.0532\n",
            "Epoch [190/200], Batch [600/750], Loss: 0.2296\n",
            "Epoch [190/200], Batch [700/750], Loss: 0.2705\n",
            "Epoch [190/200] Total train Cost: 150.75802670791745\n",
            "---------------------------------------------\n",
            "Epoch [191/200], Batch [100/750], Loss: 0.1310\n",
            "Epoch [191/200], Batch [200/750], Loss: 0.2362\n",
            "Epoch [191/200], Batch [300/750], Loss: 0.1546\n",
            "Epoch [191/200], Batch [400/750], Loss: 0.1755\n",
            "Epoch [191/200], Batch [500/750], Loss: 0.2696\n",
            "Epoch [191/200], Batch [600/750], Loss: 0.2754\n",
            "Epoch [191/200], Batch [700/750], Loss: 0.2118\n",
            "Epoch [191/200] Total train Cost: 150.34260499477386\n",
            "---------------------------------------------\n",
            "Epoch [192/200], Batch [100/750], Loss: 0.1018\n",
            "Epoch [192/200], Batch [200/750], Loss: 0.2386\n",
            "Epoch [192/200], Batch [300/750], Loss: 0.2507\n",
            "Epoch [192/200], Batch [400/750], Loss: 0.2017\n",
            "Epoch [192/200], Batch [500/750], Loss: 0.1526\n",
            "Epoch [192/200], Batch [600/750], Loss: 0.2124\n",
            "Epoch [192/200], Batch [700/750], Loss: 0.1580\n",
            "Epoch [192/200] Total train Cost: 149.94298907369375\n",
            "---------------------------------------------\n",
            "Epoch [193/200], Batch [100/750], Loss: 0.1835\n",
            "Epoch [193/200], Batch [200/750], Loss: 0.2049\n",
            "Epoch [193/200], Batch [300/750], Loss: 0.1643\n",
            "Epoch [193/200], Batch [400/750], Loss: 0.1635\n",
            "Epoch [193/200], Batch [500/750], Loss: 0.3636\n",
            "Epoch [193/200], Batch [600/750], Loss: 0.1801\n",
            "Epoch [193/200], Batch [700/750], Loss: 0.1310\n",
            "Epoch [193/200] Total train Cost: 149.53156424313784\n",
            "---------------------------------------------\n",
            "Epoch [194/200], Batch [100/750], Loss: 0.2968\n",
            "Epoch [194/200], Batch [200/750], Loss: 0.4148\n",
            "Epoch [194/200], Batch [300/750], Loss: 0.2994\n",
            "Epoch [194/200], Batch [400/750], Loss: 0.0924\n",
            "Epoch [194/200], Batch [500/750], Loss: 0.2822\n",
            "Epoch [194/200], Batch [600/750], Loss: 0.0650\n",
            "Epoch [194/200], Batch [700/750], Loss: 0.1626\n",
            "Epoch [194/200] Total train Cost: 149.11483117938042\n",
            "---------------------------------------------\n",
            "Epoch [195/200], Batch [100/750], Loss: 0.1956\n",
            "Epoch [195/200], Batch [200/750], Loss: 0.1501\n",
            "Epoch [195/200], Batch [300/750], Loss: 0.1815\n",
            "Epoch [195/200], Batch [400/750], Loss: 0.1051\n",
            "Epoch [195/200], Batch [500/750], Loss: 0.1087\n",
            "Epoch [195/200], Batch [600/750], Loss: 0.1180\n",
            "Epoch [195/200], Batch [700/750], Loss: 0.0966\n",
            "Epoch [195/200] Total train Cost: 148.71507388725877\n",
            "---------------------------------------------\n",
            "Epoch [196/200], Batch [100/750], Loss: 0.2197\n",
            "Epoch [196/200], Batch [200/750], Loss: 0.1770\n",
            "Epoch [196/200], Batch [300/750], Loss: 0.2298\n",
            "Epoch [196/200], Batch [400/750], Loss: 0.3709\n",
            "Epoch [196/200], Batch [500/750], Loss: 0.1864\n",
            "Epoch [196/200], Batch [600/750], Loss: 0.1012\n",
            "Epoch [196/200], Batch [700/750], Loss: 0.3177\n",
            "Epoch [196/200] Total train Cost: 148.2982635423541\n",
            "---------------------------------------------\n",
            "Epoch [197/200], Batch [100/750], Loss: 0.2481\n",
            "Epoch [197/200], Batch [200/750], Loss: 0.1560\n",
            "Epoch [197/200], Batch [300/750], Loss: 0.1045\n",
            "Epoch [197/200], Batch [400/750], Loss: 0.2046\n",
            "Epoch [197/200], Batch [500/750], Loss: 0.2072\n",
            "Epoch [197/200], Batch [600/750], Loss: 0.1787\n",
            "Epoch [197/200], Batch [700/750], Loss: 0.2472\n",
            "Epoch [197/200] Total train Cost: 147.90296298265457\n",
            "---------------------------------------------\n",
            "Epoch [198/200], Batch [100/750], Loss: 0.2380\n",
            "Epoch [198/200], Batch [200/750], Loss: 0.1657\n",
            "Epoch [198/200], Batch [300/750], Loss: 0.2602\n",
            "Epoch [198/200], Batch [400/750], Loss: 0.1487\n",
            "Epoch [198/200], Batch [500/750], Loss: 0.1587\n",
            "Epoch [198/200], Batch [600/750], Loss: 0.2727\n",
            "Epoch [198/200], Batch [700/750], Loss: 0.1282\n",
            "Epoch [198/200] Total train Cost: 147.5070256702602\n",
            "---------------------------------------------\n",
            "Epoch [199/200], Batch [100/750], Loss: 0.4515\n",
            "Epoch [199/200], Batch [200/750], Loss: 0.2991\n",
            "Epoch [199/200], Batch [300/750], Loss: 0.1402\n",
            "Epoch [199/200], Batch [400/750], Loss: 0.1065\n",
            "Epoch [199/200], Batch [500/750], Loss: 0.2482\n",
            "Epoch [199/200], Batch [600/750], Loss: 0.4568\n",
            "Epoch [199/200], Batch [700/750], Loss: 0.1721\n",
            "Epoch [199/200] Total train Cost: 147.1104353070259\n",
            "---------------------------------------------\n",
            "Epoch [200/200], Batch [100/750], Loss: 0.1207\n",
            "Epoch [200/200], Batch [200/750], Loss: 0.1582\n",
            "Epoch [200/200], Batch [300/750], Loss: 0.2417\n",
            "Epoch [200/200], Batch [400/750], Loss: 0.3274\n",
            "Epoch [200/200], Batch [500/750], Loss: 0.1616\n",
            "Epoch [200/200], Batch [600/750], Loss: 0.3394\n",
            "Epoch [200/200], Batch [700/750], Loss: 0.1853\n",
            "Epoch [200/200] Total train Cost: 146.7101434506476\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = MNIST_Neural_Network(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_batches = len(train_loader)\n",
        "\n",
        "batch_loss_list = []\n",
        "epoch_loss_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    current_loss = 0.\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_loss_list.append(loss.item())\n",
        "        current_loss += loss.item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{n_total_batches}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    epoch_loss_list.append(current_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] Total train Cost: {current_loss}')\n",
        "    print(\"-\" * 45)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "ZbbbHZQSlMhY",
        "outputId": "bd45daf0-b4d3-4083-8787-1e2663aa3800"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Epoch Loss')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "ax[0].plot(range(len(batch_loss_list)), (batch_loss_list), label='Batch Loss')\n",
        "ax[0].set_xlabel('Iterations')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_title('Batch Loss')\n",
        "\n",
        "ax[1].plot(range(len(epoch_loss_list)), (epoch_loss_list), label='Epoch Loss')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_title('Epoch Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXcIeFezx1Ew"
      },
      "source": [
        "learning_rate = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwy9SCOwx3G5",
        "outputId": "864ec062-fd00-44ef-9872-9df5792d2886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/200], Batch [100/750], Loss: 2.3105\n",
            "Epoch [1/200], Batch [200/750], Loss: 2.2986\n",
            "Epoch [1/200], Batch [300/750], Loss: 2.2859\n",
            "Epoch [1/200], Batch [400/750], Loss: 2.3065\n",
            "Epoch [1/200], Batch [500/750], Loss: 2.2982\n",
            "Epoch [1/200], Batch [600/750], Loss: 2.3112\n",
            "Epoch [1/200], Batch [700/750], Loss: 2.2836\n",
            "Epoch [1/200] Total train Cost: 1724.6787598133087\n",
            "---------------------------------------------\n",
            "Epoch [2/200], Batch [100/750], Loss: 2.2946\n",
            "Epoch [2/200], Batch [200/750], Loss: 2.2948\n",
            "Epoch [2/200], Batch [300/750], Loss: 2.2767\n",
            "Epoch [2/200], Batch [400/750], Loss: 2.2889\n",
            "Epoch [2/200], Batch [500/750], Loss: 2.2675\n",
            "Epoch [2/200], Batch [600/750], Loss: 2.2582\n",
            "Epoch [2/200], Batch [700/750], Loss: 2.2694\n",
            "Epoch [2/200] Total train Cost: 1711.416208267212\n",
            "---------------------------------------------\n",
            "Epoch [3/200], Batch [100/750], Loss: 2.2894\n",
            "Epoch [3/200], Batch [200/750], Loss: 2.2682\n",
            "Epoch [3/200], Batch [300/750], Loss: 2.2662\n",
            "Epoch [3/200], Batch [400/750], Loss: 2.2761\n",
            "Epoch [3/200], Batch [500/750], Loss: 2.2615\n",
            "Epoch [3/200], Batch [600/750], Loss: 2.2706\n",
            "Epoch [3/200], Batch [700/750], Loss: 2.2531\n",
            "Epoch [3/200] Total train Cost: 1698.2977714538574\n",
            "---------------------------------------------\n",
            "Epoch [4/200], Batch [100/750], Loss: 2.2616\n",
            "Epoch [4/200], Batch [200/750], Loss: 2.2562\n",
            "Epoch [4/200], Batch [300/750], Loss: 2.2374\n",
            "Epoch [4/200], Batch [400/750], Loss: 2.2374\n",
            "Epoch [4/200], Batch [500/750], Loss: 2.2558\n",
            "Epoch [4/200], Batch [600/750], Loss: 2.2517\n",
            "Epoch [4/200], Batch [700/750], Loss: 2.2394\n",
            "Epoch [4/200] Total train Cost: 1685.244402885437\n",
            "---------------------------------------------\n",
            "Epoch [5/200], Batch [100/750], Loss: 2.2380\n",
            "Epoch [5/200], Batch [200/750], Loss: 2.2352\n",
            "Epoch [5/200], Batch [300/750], Loss: 2.2383\n",
            "Epoch [5/200], Batch [400/750], Loss: 2.2266\n",
            "Epoch [5/200], Batch [500/750], Loss: 2.2115\n",
            "Epoch [5/200], Batch [600/750], Loss: 2.2307\n",
            "Epoch [5/200], Batch [700/750], Loss: 2.2192\n",
            "Epoch [5/200] Total train Cost: 1672.1880807876587\n",
            "---------------------------------------------\n",
            "Epoch [6/200], Batch [100/750], Loss: 2.2232\n",
            "Epoch [6/200], Batch [200/750], Loss: 2.2232\n",
            "Epoch [6/200], Batch [300/750], Loss: 2.2028\n",
            "Epoch [6/200], Batch [400/750], Loss: 2.2124\n",
            "Epoch [6/200], Batch [500/750], Loss: 2.2082\n",
            "Epoch [6/200], Batch [600/750], Loss: 2.2179\n",
            "Epoch [6/200], Batch [700/750], Loss: 2.2023\n",
            "Epoch [6/200] Total train Cost: 1659.063782453537\n",
            "---------------------------------------------\n",
            "Epoch [7/200], Batch [100/750], Loss: 2.1967\n",
            "Epoch [7/200], Batch [200/750], Loss: 2.2082\n",
            "Epoch [7/200], Batch [300/750], Loss: 2.1874\n",
            "Epoch [7/200], Batch [400/750], Loss: 2.1794\n",
            "Epoch [7/200], Batch [500/750], Loss: 2.1769\n",
            "Epoch [7/200], Batch [600/750], Loss: 2.1804\n",
            "Epoch [7/200], Batch [700/750], Loss: 2.2011\n",
            "Epoch [7/200] Total train Cost: 1645.8159136772156\n",
            "---------------------------------------------\n",
            "Epoch [8/200], Batch [100/750], Loss: 2.1756\n",
            "Epoch [8/200], Batch [200/750], Loss: 2.1877\n",
            "Epoch [8/200], Batch [300/750], Loss: 2.1688\n",
            "Epoch [8/200], Batch [400/750], Loss: 2.1815\n",
            "Epoch [8/200], Batch [500/750], Loss: 2.1794\n",
            "Epoch [8/200], Batch [600/750], Loss: 2.1549\n",
            "Epoch [8/200], Batch [700/750], Loss: 2.1782\n",
            "Epoch [8/200] Total train Cost: 1632.394073009491\n",
            "---------------------------------------------\n",
            "Epoch [9/200], Batch [100/750], Loss: 2.1619\n",
            "Epoch [9/200], Batch [200/750], Loss: 2.1456\n",
            "Epoch [9/200], Batch [300/750], Loss: 2.1358\n",
            "Epoch [9/200], Batch [400/750], Loss: 2.1560\n",
            "Epoch [9/200], Batch [500/750], Loss: 2.1198\n",
            "Epoch [9/200], Batch [600/750], Loss: 2.1565\n",
            "Epoch [9/200], Batch [700/750], Loss: 2.1767\n",
            "Epoch [9/200] Total train Cost: 1618.754943370819\n",
            "---------------------------------------------\n",
            "Epoch [10/200], Batch [100/750], Loss: 2.1619\n",
            "Epoch [10/200], Batch [200/750], Loss: 2.1470\n",
            "Epoch [10/200], Batch [300/750], Loss: 2.1453\n",
            "Epoch [10/200], Batch [400/750], Loss: 2.1674\n",
            "Epoch [10/200], Batch [500/750], Loss: 2.1428\n",
            "Epoch [10/200], Batch [600/750], Loss: 2.1644\n",
            "Epoch [10/200], Batch [700/750], Loss: 2.1530\n",
            "Epoch [10/200] Total train Cost: 1604.859168767929\n",
            "---------------------------------------------\n",
            "Epoch [11/200], Batch [100/750], Loss: 2.1088\n",
            "Epoch [11/200], Batch [200/750], Loss: 2.1382\n",
            "Epoch [11/200], Batch [300/750], Loss: 2.1651\n",
            "Epoch [11/200], Batch [400/750], Loss: 2.1198\n",
            "Epoch [11/200], Batch [500/750], Loss: 2.1684\n",
            "Epoch [11/200], Batch [600/750], Loss: 2.1318\n",
            "Epoch [11/200], Batch [700/750], Loss: 2.1346\n",
            "Epoch [11/200] Total train Cost: 1590.6674709320068\n",
            "---------------------------------------------\n",
            "Epoch [12/200], Batch [100/750], Loss: 2.1079\n",
            "Epoch [12/200], Batch [200/750], Loss: 2.1168\n",
            "Epoch [12/200], Batch [300/750], Loss: 2.0981\n",
            "Epoch [12/200], Batch [400/750], Loss: 2.1080\n",
            "Epoch [12/200], Batch [500/750], Loss: 2.0887\n",
            "Epoch [12/200], Batch [600/750], Loss: 2.0972\n",
            "Epoch [12/200], Batch [700/750], Loss: 2.0848\n",
            "Epoch [12/200] Total train Cost: 1576.1505737304688\n",
            "---------------------------------------------\n",
            "Epoch [13/200], Batch [100/750], Loss: 2.0756\n",
            "Epoch [13/200], Batch [200/750], Loss: 2.0774\n",
            "Epoch [13/200], Batch [300/750], Loss: 2.0930\n",
            "Epoch [13/200], Batch [400/750], Loss: 2.0675\n",
            "Epoch [13/200], Batch [500/750], Loss: 2.1311\n",
            "Epoch [13/200], Batch [600/750], Loss: 2.0585\n",
            "Epoch [13/200], Batch [700/750], Loss: 2.0877\n",
            "Epoch [13/200] Total train Cost: 1561.2855114936829\n",
            "---------------------------------------------\n",
            "Epoch [14/200], Batch [100/750], Loss: 2.0844\n",
            "Epoch [14/200], Batch [200/750], Loss: 2.0884\n",
            "Epoch [14/200], Batch [300/750], Loss: 2.0277\n",
            "Epoch [14/200], Batch [400/750], Loss: 2.0449\n",
            "Epoch [14/200], Batch [500/750], Loss: 2.0666\n",
            "Epoch [14/200], Batch [600/750], Loss: 2.0548\n",
            "Epoch [14/200], Batch [700/750], Loss: 2.0125\n",
            "Epoch [14/200] Total train Cost: 1546.0536378622055\n",
            "---------------------------------------------\n",
            "Epoch [15/200], Batch [100/750], Loss: 2.0238\n",
            "Epoch [15/200], Batch [200/750], Loss: 2.0917\n",
            "Epoch [15/200], Batch [300/750], Loss: 2.0593\n",
            "Epoch [15/200], Batch [400/750], Loss: 2.0597\n",
            "Epoch [15/200], Batch [500/750], Loss: 2.0118\n",
            "Epoch [15/200], Batch [600/750], Loss: 2.0145\n",
            "Epoch [15/200], Batch [700/750], Loss: 2.0327\n",
            "Epoch [15/200] Total train Cost: 1530.4431365728378\n",
            "---------------------------------------------\n",
            "Epoch [16/200], Batch [100/750], Loss: 1.9709\n",
            "Epoch [16/200], Batch [200/750], Loss: 1.9872\n",
            "Epoch [16/200], Batch [300/750], Loss: 2.0048\n",
            "Epoch [16/200], Batch [400/750], Loss: 2.0348\n",
            "Epoch [16/200], Batch [500/750], Loss: 2.0024\n",
            "Epoch [16/200], Batch [600/750], Loss: 2.0517\n",
            "Epoch [16/200], Batch [700/750], Loss: 2.0126\n",
            "Epoch [16/200] Total train Cost: 1514.4424344301224\n",
            "---------------------------------------------\n",
            "Epoch [17/200], Batch [100/750], Loss: 2.0402\n",
            "Epoch [17/200], Batch [200/750], Loss: 1.9850\n",
            "Epoch [17/200], Batch [300/750], Loss: 1.9942\n",
            "Epoch [17/200], Batch [400/750], Loss: 1.9581\n",
            "Epoch [17/200], Batch [500/750], Loss: 2.0021\n",
            "Epoch [17/200], Batch [600/750], Loss: 1.9557\n",
            "Epoch [17/200], Batch [700/750], Loss: 1.9743\n",
            "Epoch [17/200] Total train Cost: 1498.045212507248\n",
            "---------------------------------------------\n",
            "Epoch [18/200], Batch [100/750], Loss: 1.9940\n",
            "Epoch [18/200], Batch [200/750], Loss: 2.0117\n",
            "Epoch [18/200], Batch [300/750], Loss: 2.0199\n",
            "Epoch [18/200], Batch [400/750], Loss: 1.9147\n",
            "Epoch [18/200], Batch [500/750], Loss: 1.9928\n",
            "Epoch [18/200], Batch [600/750], Loss: 1.9644\n",
            "Epoch [18/200], Batch [700/750], Loss: 1.9932\n",
            "Epoch [18/200] Total train Cost: 1481.253185391426\n",
            "---------------------------------------------\n",
            "Epoch [19/200], Batch [100/750], Loss: 1.9655\n",
            "Epoch [19/200], Batch [200/750], Loss: 1.9354\n",
            "Epoch [19/200], Batch [300/750], Loss: 1.9638\n",
            "Epoch [19/200], Batch [400/750], Loss: 2.0162\n",
            "Epoch [19/200], Batch [500/750], Loss: 1.9516\n",
            "Epoch [19/200], Batch [600/750], Loss: 2.0023\n",
            "Epoch [19/200], Batch [700/750], Loss: 1.9682\n",
            "Epoch [19/200] Total train Cost: 1464.0682780742645\n",
            "---------------------------------------------\n",
            "Epoch [20/200], Batch [100/750], Loss: 1.9377\n",
            "Epoch [20/200], Batch [200/750], Loss: 1.9227\n",
            "Epoch [20/200], Batch [300/750], Loss: 1.9154\n",
            "Epoch [20/200], Batch [400/750], Loss: 1.8870\n",
            "Epoch [20/200], Batch [500/750], Loss: 1.8992\n",
            "Epoch [20/200], Batch [600/750], Loss: 1.9428\n",
            "Epoch [20/200], Batch [700/750], Loss: 1.9244\n",
            "Epoch [20/200] Total train Cost: 1446.5018837451935\n",
            "---------------------------------------------\n",
            "Epoch [21/200], Batch [100/750], Loss: 1.9666\n",
            "Epoch [21/200], Batch [200/750], Loss: 1.8882\n",
            "Epoch [21/200], Batch [300/750], Loss: 1.8978\n",
            "Epoch [21/200], Batch [400/750], Loss: 1.9022\n",
            "Epoch [21/200], Batch [500/750], Loss: 1.8883\n",
            "Epoch [21/200], Batch [600/750], Loss: 1.8696\n",
            "Epoch [21/200], Batch [700/750], Loss: 1.9157\n",
            "Epoch [21/200] Total train Cost: 1428.5697221755981\n",
            "---------------------------------------------\n",
            "Epoch [22/200], Batch [100/750], Loss: 1.8403\n",
            "Epoch [22/200], Batch [200/750], Loss: 1.9428\n",
            "Epoch [22/200], Batch [300/750], Loss: 1.8204\n",
            "Epoch [22/200], Batch [400/750], Loss: 1.8739\n",
            "Epoch [22/200], Batch [500/750], Loss: 1.8457\n",
            "Epoch [22/200], Batch [600/750], Loss: 1.8943\n",
            "Epoch [22/200], Batch [700/750], Loss: 1.8653\n",
            "Epoch [22/200] Total train Cost: 1410.290048122406\n",
            "---------------------------------------------\n",
            "Epoch [23/200], Batch [100/750], Loss: 1.8151\n",
            "Epoch [23/200], Batch [200/750], Loss: 1.8497\n",
            "Epoch [23/200], Batch [300/750], Loss: 1.8581\n",
            "Epoch [23/200], Batch [400/750], Loss: 1.8874\n",
            "Epoch [23/200], Batch [500/750], Loss: 1.8435\n",
            "Epoch [23/200], Batch [600/750], Loss: 1.8415\n",
            "Epoch [23/200], Batch [700/750], Loss: 1.8653\n",
            "Epoch [23/200] Total train Cost: 1391.686992406845\n",
            "---------------------------------------------\n",
            "Epoch [24/200], Batch [100/750], Loss: 1.8742\n",
            "Epoch [24/200], Batch [200/750], Loss: 1.7983\n",
            "Epoch [24/200], Batch [300/750], Loss: 1.7984\n",
            "Epoch [24/200], Batch [400/750], Loss: 1.8426\n",
            "Epoch [24/200], Batch [500/750], Loss: 1.8403\n",
            "Epoch [24/200], Batch [600/750], Loss: 1.7710\n",
            "Epoch [24/200], Batch [700/750], Loss: 1.8352\n",
            "Epoch [24/200] Total train Cost: 1372.7871570587158\n",
            "---------------------------------------------\n",
            "Epoch [25/200], Batch [100/750], Loss: 1.8527\n",
            "Epoch [25/200], Batch [200/750], Loss: 1.8819\n",
            "Epoch [25/200], Batch [300/750], Loss: 1.7563\n",
            "Epoch [25/200], Batch [400/750], Loss: 1.7222\n",
            "Epoch [25/200], Batch [500/750], Loss: 1.7587\n",
            "Epoch [25/200], Batch [600/750], Loss: 1.8174\n",
            "Epoch [25/200], Batch [700/750], Loss: 1.8011\n",
            "Epoch [25/200] Total train Cost: 1353.619907259941\n",
            "---------------------------------------------\n",
            "Epoch [26/200], Batch [100/750], Loss: 1.7734\n",
            "Epoch [26/200], Batch [200/750], Loss: 1.7515\n",
            "Epoch [26/200], Batch [300/750], Loss: 1.7781\n",
            "Epoch [26/200], Batch [400/750], Loss: 1.7568\n",
            "Epoch [26/200], Batch [500/750], Loss: 1.8121\n",
            "Epoch [26/200], Batch [600/750], Loss: 1.7213\n",
            "Epoch [26/200], Batch [700/750], Loss: 1.7118\n",
            "Epoch [26/200] Total train Cost: 1334.2183060646057\n",
            "---------------------------------------------\n",
            "Epoch [27/200], Batch [100/750], Loss: 1.7787\n",
            "Epoch [27/200], Batch [200/750], Loss: 1.7242\n",
            "Epoch [27/200], Batch [300/750], Loss: 1.6996\n",
            "Epoch [27/200], Batch [400/750], Loss: 1.7830\n",
            "Epoch [27/200], Batch [500/750], Loss: 1.7336\n",
            "Epoch [27/200], Batch [600/750], Loss: 1.7336\n",
            "Epoch [27/200], Batch [700/750], Loss: 1.6600\n",
            "Epoch [27/200] Total train Cost: 1314.6198719739914\n",
            "---------------------------------------------\n",
            "Epoch [28/200], Batch [100/750], Loss: 1.6913\n",
            "Epoch [28/200], Batch [200/750], Loss: 1.7248\n",
            "Epoch [28/200], Batch [300/750], Loss: 1.7299\n",
            "Epoch [28/200], Batch [400/750], Loss: 1.7078\n",
            "Epoch [28/200], Batch [500/750], Loss: 1.6664\n",
            "Epoch [28/200], Batch [600/750], Loss: 1.7531\n",
            "Epoch [28/200], Batch [700/750], Loss: 1.7645\n",
            "Epoch [28/200] Total train Cost: 1294.8609966039658\n",
            "---------------------------------------------\n",
            "Epoch [29/200], Batch [100/750], Loss: 1.6751\n",
            "Epoch [29/200], Batch [200/750], Loss: 1.7056\n",
            "Epoch [29/200], Batch [300/750], Loss: 1.7003\n",
            "Epoch [29/200], Batch [400/750], Loss: 1.6289\n",
            "Epoch [29/200], Batch [500/750], Loss: 1.7083\n",
            "Epoch [29/200], Batch [600/750], Loss: 1.6791\n",
            "Epoch [29/200], Batch [700/750], Loss: 1.6766\n",
            "Epoch [29/200] Total train Cost: 1274.9810960292816\n",
            "---------------------------------------------\n",
            "Epoch [30/200], Batch [100/750], Loss: 1.6911\n",
            "Epoch [30/200], Batch [200/750], Loss: 1.6047\n",
            "Epoch [30/200], Batch [300/750], Loss: 1.6677\n",
            "Epoch [30/200], Batch [400/750], Loss: 1.7253\n",
            "Epoch [30/200], Batch [500/750], Loss: 1.5846\n",
            "Epoch [30/200], Batch [600/750], Loss: 1.6482\n",
            "Epoch [30/200], Batch [700/750], Loss: 1.6226\n",
            "Epoch [30/200] Total train Cost: 1255.0171720981598\n",
            "---------------------------------------------\n",
            "Epoch [31/200], Batch [100/750], Loss: 1.7452\n",
            "Epoch [31/200], Batch [200/750], Loss: 1.6070\n",
            "Epoch [31/200], Batch [300/750], Loss: 1.6370\n",
            "Epoch [31/200], Batch [400/750], Loss: 1.6009\n",
            "Epoch [31/200], Batch [500/750], Loss: 1.6901\n",
            "Epoch [31/200], Batch [600/750], Loss: 1.5615\n",
            "Epoch [31/200], Batch [700/750], Loss: 1.5990\n",
            "Epoch [31/200] Total train Cost: 1235.012216091156\n",
            "---------------------------------------------\n",
            "Epoch [32/200], Batch [100/750], Loss: 1.6363\n",
            "Epoch [32/200], Batch [200/750], Loss: 1.6401\n",
            "Epoch [32/200], Batch [300/750], Loss: 1.6311\n",
            "Epoch [32/200], Batch [400/750], Loss: 1.6918\n",
            "Epoch [32/200], Batch [500/750], Loss: 1.6650\n",
            "Epoch [32/200], Batch [600/750], Loss: 1.6496\n",
            "Epoch [32/200], Batch [700/750], Loss: 1.5829\n",
            "Epoch [32/200] Total train Cost: 1215.0088312625885\n",
            "---------------------------------------------\n",
            "Epoch [33/200], Batch [100/750], Loss: 1.6438\n",
            "Epoch [33/200], Batch [200/750], Loss: 1.5917\n",
            "Epoch [33/200], Batch [300/750], Loss: 1.5464\n",
            "Epoch [33/200], Batch [400/750], Loss: 1.5892\n",
            "Epoch [33/200], Batch [500/750], Loss: 1.5891\n",
            "Epoch [33/200], Batch [600/750], Loss: 1.5578\n",
            "Epoch [33/200], Batch [700/750], Loss: 1.6353\n",
            "Epoch [33/200] Total train Cost: 1195.0451984405518\n",
            "---------------------------------------------\n",
            "Epoch [34/200], Batch [100/750], Loss: 1.5619\n",
            "Epoch [34/200], Batch [200/750], Loss: 1.5407\n",
            "Epoch [34/200], Batch [300/750], Loss: 1.5748\n",
            "Epoch [34/200], Batch [400/750], Loss: 1.5693\n",
            "Epoch [34/200], Batch [500/750], Loss: 1.4225\n",
            "Epoch [34/200], Batch [600/750], Loss: 1.5338\n",
            "Epoch [34/200], Batch [700/750], Loss: 1.5375\n",
            "Epoch [34/200] Total train Cost: 1175.1608419418335\n",
            "---------------------------------------------\n",
            "Epoch [35/200], Batch [100/750], Loss: 1.5224\n",
            "Epoch [35/200], Batch [200/750], Loss: 1.5258\n",
            "Epoch [35/200], Batch [300/750], Loss: 1.5355\n",
            "Epoch [35/200], Batch [400/750], Loss: 1.4691\n",
            "Epoch [35/200], Batch [500/750], Loss: 1.5866\n",
            "Epoch [35/200], Batch [600/750], Loss: 1.5574\n",
            "Epoch [35/200], Batch [700/750], Loss: 1.5465\n",
            "Epoch [35/200] Total train Cost: 1155.3944284915924\n",
            "---------------------------------------------\n",
            "Epoch [36/200], Batch [100/750], Loss: 1.4794\n",
            "Epoch [36/200], Batch [200/750], Loss: 1.5295\n",
            "Epoch [36/200], Batch [300/750], Loss: 1.5026\n",
            "Epoch [36/200], Batch [400/750], Loss: 1.4708\n",
            "Epoch [36/200], Batch [500/750], Loss: 1.4303\n",
            "Epoch [36/200], Batch [600/750], Loss: 1.6172\n",
            "Epoch [36/200], Batch [700/750], Loss: 1.4589\n",
            "Epoch [36/200] Total train Cost: 1135.7833865880966\n",
            "---------------------------------------------\n",
            "Epoch [37/200], Batch [100/750], Loss: 1.5115\n",
            "Epoch [37/200], Batch [200/750], Loss: 1.5533\n",
            "Epoch [37/200], Batch [300/750], Loss: 1.4309\n",
            "Epoch [37/200], Batch [400/750], Loss: 1.5287\n",
            "Epoch [37/200], Batch [500/750], Loss: 1.4776\n",
            "Epoch [37/200], Batch [600/750], Loss: 1.4921\n",
            "Epoch [37/200], Batch [700/750], Loss: 1.4327\n",
            "Epoch [37/200] Total train Cost: 1116.3628064393997\n",
            "---------------------------------------------\n",
            "Epoch [38/200], Batch [100/750], Loss: 1.4414\n",
            "Epoch [38/200], Batch [200/750], Loss: 1.5697\n",
            "Epoch [38/200], Batch [300/750], Loss: 1.4390\n",
            "Epoch [38/200], Batch [400/750], Loss: 1.4288\n",
            "Epoch [38/200], Batch [500/750], Loss: 1.4267\n",
            "Epoch [38/200], Batch [600/750], Loss: 1.4424\n",
            "Epoch [38/200], Batch [700/750], Loss: 1.5095\n",
            "Epoch [38/200] Total train Cost: 1097.1679824590683\n",
            "---------------------------------------------\n",
            "Epoch [39/200], Batch [100/750], Loss: 1.4397\n",
            "Epoch [39/200], Batch [200/750], Loss: 1.3925\n",
            "Epoch [39/200], Batch [300/750], Loss: 1.4600\n",
            "Epoch [39/200], Batch [400/750], Loss: 1.4101\n",
            "Epoch [39/200], Batch [500/750], Loss: 1.5281\n",
            "Epoch [39/200], Batch [600/750], Loss: 1.4678\n",
            "Epoch [39/200], Batch [700/750], Loss: 1.3799\n",
            "Epoch [39/200] Total train Cost: 1078.2255012989044\n",
            "---------------------------------------------\n",
            "Epoch [40/200], Batch [100/750], Loss: 1.3435\n",
            "Epoch [40/200], Batch [200/750], Loss: 1.3976\n",
            "Epoch [40/200], Batch [300/750], Loss: 1.4751\n",
            "Epoch [40/200], Batch [400/750], Loss: 1.4750\n",
            "Epoch [40/200], Batch [500/750], Loss: 1.3194\n",
            "Epoch [40/200], Batch [600/750], Loss: 1.4870\n",
            "Epoch [40/200], Batch [700/750], Loss: 1.4880\n",
            "Epoch [40/200] Total train Cost: 1059.565923690796\n",
            "---------------------------------------------\n",
            "Epoch [41/200], Batch [100/750], Loss: 1.3591\n",
            "Epoch [41/200], Batch [200/750], Loss: 1.4657\n",
            "Epoch [41/200], Batch [300/750], Loss: 1.4275\n",
            "Epoch [41/200], Batch [400/750], Loss: 1.3718\n",
            "Epoch [41/200], Batch [500/750], Loss: 1.3634\n",
            "Epoch [41/200], Batch [600/750], Loss: 1.3782\n",
            "Epoch [41/200], Batch [700/750], Loss: 1.4415\n",
            "Epoch [41/200] Total train Cost: 1041.2139910459518\n",
            "---------------------------------------------\n",
            "Epoch [42/200], Batch [100/750], Loss: 1.3641\n",
            "Epoch [42/200], Batch [200/750], Loss: 1.3258\n",
            "Epoch [42/200], Batch [300/750], Loss: 1.4519\n",
            "Epoch [42/200], Batch [400/750], Loss: 1.5014\n",
            "Epoch [42/200], Batch [500/750], Loss: 1.3060\n",
            "Epoch [42/200], Batch [600/750], Loss: 1.3424\n",
            "Epoch [42/200], Batch [700/750], Loss: 1.3982\n",
            "Epoch [42/200] Total train Cost: 1023.1893064975739\n",
            "---------------------------------------------\n",
            "Epoch [43/200], Batch [100/750], Loss: 1.4200\n",
            "Epoch [43/200], Batch [200/750], Loss: 1.3819\n",
            "Epoch [43/200], Batch [300/750], Loss: 1.3172\n",
            "Epoch [43/200], Batch [400/750], Loss: 1.3591\n",
            "Epoch [43/200], Batch [500/750], Loss: 1.3220\n",
            "Epoch [43/200], Batch [600/750], Loss: 1.3605\n",
            "Epoch [43/200], Batch [700/750], Loss: 1.3947\n",
            "Epoch [43/200] Total train Cost: 1005.5140879154205\n",
            "---------------------------------------------\n",
            "Epoch [44/200], Batch [100/750], Loss: 1.3889\n",
            "Epoch [44/200], Batch [200/750], Loss: 1.3346\n",
            "Epoch [44/200], Batch [300/750], Loss: 1.3406\n",
            "Epoch [44/200], Batch [400/750], Loss: 1.1866\n",
            "Epoch [44/200], Batch [500/750], Loss: 1.2863\n",
            "Epoch [44/200], Batch [600/750], Loss: 1.3957\n",
            "Epoch [44/200], Batch [700/750], Loss: 1.3368\n",
            "Epoch [44/200] Total train Cost: 988.2026753425598\n",
            "---------------------------------------------\n",
            "Epoch [45/200], Batch [100/750], Loss: 1.2534\n",
            "Epoch [45/200], Batch [200/750], Loss: 1.2489\n",
            "Epoch [45/200], Batch [300/750], Loss: 1.3349\n",
            "Epoch [45/200], Batch [400/750], Loss: 1.2791\n",
            "Epoch [45/200], Batch [500/750], Loss: 1.2876\n",
            "Epoch [45/200], Batch [600/750], Loss: 1.3390\n",
            "Epoch [45/200], Batch [700/750], Loss: 1.3381\n",
            "Epoch [45/200] Total train Cost: 971.2680015563965\n",
            "---------------------------------------------\n",
            "Epoch [46/200], Batch [100/750], Loss: 1.2358\n",
            "Epoch [46/200], Batch [200/750], Loss: 1.3601\n",
            "Epoch [46/200], Batch [300/750], Loss: 1.4069\n",
            "Epoch [46/200], Batch [400/750], Loss: 1.2384\n",
            "Epoch [46/200], Batch [500/750], Loss: 1.3054\n",
            "Epoch [46/200], Batch [600/750], Loss: 1.2490\n",
            "Epoch [46/200], Batch [700/750], Loss: 1.1920\n",
            "Epoch [46/200] Total train Cost: 954.720609664917\n",
            "---------------------------------------------\n",
            "Epoch [47/200], Batch [100/750], Loss: 1.2846\n",
            "Epoch [47/200], Batch [200/750], Loss: 1.2724\n",
            "Epoch [47/200], Batch [300/750], Loss: 1.1844\n",
            "Epoch [47/200], Batch [400/750], Loss: 1.3184\n",
            "Epoch [47/200], Batch [500/750], Loss: 1.2528\n",
            "Epoch [47/200], Batch [600/750], Loss: 1.1296\n",
            "Epoch [47/200], Batch [700/750], Loss: 1.1907\n",
            "Epoch [47/200] Total train Cost: 938.5710960626602\n",
            "---------------------------------------------\n",
            "Epoch [48/200], Batch [100/750], Loss: 1.3448\n",
            "Epoch [48/200], Batch [200/750], Loss: 1.2479\n",
            "Epoch [48/200], Batch [300/750], Loss: 1.2839\n",
            "Epoch [48/200], Batch [400/750], Loss: 1.2312\n",
            "Epoch [48/200], Batch [500/750], Loss: 1.1714\n",
            "Epoch [48/200], Batch [600/750], Loss: 1.2504\n",
            "Epoch [48/200], Batch [700/750], Loss: 1.0693\n",
            "Epoch [48/200] Total train Cost: 922.8229727745056\n",
            "---------------------------------------------\n",
            "Epoch [49/200], Batch [100/750], Loss: 1.2215\n",
            "Epoch [49/200], Batch [200/750], Loss: 1.1403\n",
            "Epoch [49/200], Batch [300/750], Loss: 1.0966\n",
            "Epoch [49/200], Batch [400/750], Loss: 1.1795\n",
            "Epoch [49/200], Batch [500/750], Loss: 1.1679\n",
            "Epoch [49/200], Batch [600/750], Loss: 1.2446\n",
            "Epoch [49/200], Batch [700/750], Loss: 1.2345\n",
            "Epoch [49/200] Total train Cost: 907.4811162948608\n",
            "---------------------------------------------\n",
            "Epoch [50/200], Batch [100/750], Loss: 1.2596\n",
            "Epoch [50/200], Batch [200/750], Loss: 1.1840\n",
            "Epoch [50/200], Batch [300/750], Loss: 1.1511\n",
            "Epoch [50/200], Batch [400/750], Loss: 1.2878\n",
            "Epoch [50/200], Batch [500/750], Loss: 1.1407\n",
            "Epoch [50/200], Batch [600/750], Loss: 1.2007\n",
            "Epoch [50/200], Batch [700/750], Loss: 1.2197\n",
            "Epoch [50/200] Total train Cost: 892.5463747382164\n",
            "---------------------------------------------\n",
            "Epoch [51/200], Batch [100/750], Loss: 1.0805\n",
            "Epoch [51/200], Batch [200/750], Loss: 1.1562\n",
            "Epoch [51/200], Batch [300/750], Loss: 1.1154\n",
            "Epoch [51/200], Batch [400/750], Loss: 1.1514\n",
            "Epoch [51/200], Batch [500/750], Loss: 1.1167\n",
            "Epoch [51/200], Batch [600/750], Loss: 1.1616\n",
            "Epoch [51/200], Batch [700/750], Loss: 1.1397\n",
            "Epoch [51/200] Total train Cost: 878.0180228352547\n",
            "---------------------------------------------\n",
            "Epoch [52/200], Batch [100/750], Loss: 1.1370\n",
            "Epoch [52/200], Batch [200/750], Loss: 1.1046\n",
            "Epoch [52/200], Batch [300/750], Loss: 1.1331\n",
            "Epoch [52/200], Batch [400/750], Loss: 1.1932\n",
            "Epoch [52/200], Batch [500/750], Loss: 1.2183\n",
            "Epoch [52/200], Batch [600/750], Loss: 1.1425\n",
            "Epoch [52/200], Batch [700/750], Loss: 1.0682\n",
            "Epoch [52/200] Total train Cost: 863.8948879241943\n",
            "---------------------------------------------\n",
            "Epoch [53/200], Batch [100/750], Loss: 1.1247\n",
            "Epoch [53/200], Batch [200/750], Loss: 1.1897\n",
            "Epoch [53/200], Batch [300/750], Loss: 1.0716\n",
            "Epoch [53/200], Batch [400/750], Loss: 1.1580\n",
            "Epoch [53/200], Batch [500/750], Loss: 1.0456\n",
            "Epoch [53/200], Batch [600/750], Loss: 1.1876\n",
            "Epoch [53/200], Batch [700/750], Loss: 1.2511\n",
            "Epoch [53/200] Total train Cost: 850.1715884208679\n",
            "---------------------------------------------\n",
            "Epoch [54/200], Batch [100/750], Loss: 1.0867\n",
            "Epoch [54/200], Batch [200/750], Loss: 1.0491\n",
            "Epoch [54/200], Batch [300/750], Loss: 1.1886\n",
            "Epoch [54/200], Batch [400/750], Loss: 1.0460\n",
            "Epoch [54/200], Batch [500/750], Loss: 1.1082\n",
            "Epoch [54/200], Batch [600/750], Loss: 1.2207\n",
            "Epoch [54/200], Batch [700/750], Loss: 1.0438\n",
            "Epoch [54/200] Total train Cost: 836.8446414470673\n",
            "---------------------------------------------\n",
            "Epoch [55/200], Batch [100/750], Loss: 0.9720\n",
            "Epoch [55/200], Batch [200/750], Loss: 1.0017\n",
            "Epoch [55/200], Batch [300/750], Loss: 1.1431\n",
            "Epoch [55/200], Batch [400/750], Loss: 1.0938\n",
            "Epoch [55/200], Batch [500/750], Loss: 1.0722\n",
            "Epoch [55/200], Batch [600/750], Loss: 1.1639\n",
            "Epoch [55/200], Batch [700/750], Loss: 1.1124\n",
            "Epoch [55/200] Total train Cost: 823.9071878790855\n",
            "---------------------------------------------\n",
            "Epoch [56/200], Batch [100/750], Loss: 1.1712\n",
            "Epoch [56/200], Batch [200/750], Loss: 1.2572\n",
            "Epoch [56/200], Batch [300/750], Loss: 1.0735\n",
            "Epoch [56/200], Batch [400/750], Loss: 1.0087\n",
            "Epoch [56/200], Batch [500/750], Loss: 1.1795\n",
            "Epoch [56/200], Batch [600/750], Loss: 1.0471\n",
            "Epoch [56/200], Batch [700/750], Loss: 1.0954\n",
            "Epoch [56/200] Total train Cost: 811.3525183796883\n",
            "---------------------------------------------\n",
            "Epoch [57/200], Batch [100/750], Loss: 1.0196\n",
            "Epoch [57/200], Batch [200/750], Loss: 1.0009\n",
            "Epoch [57/200], Batch [300/750], Loss: 1.1514\n",
            "Epoch [57/200], Batch [400/750], Loss: 0.9520\n",
            "Epoch [57/200], Batch [500/750], Loss: 1.0587\n",
            "Epoch [57/200], Batch [600/750], Loss: 1.0456\n",
            "Epoch [57/200], Batch [700/750], Loss: 1.1284\n",
            "Epoch [57/200] Total train Cost: 799.1723635196686\n",
            "---------------------------------------------\n",
            "Epoch [58/200], Batch [100/750], Loss: 0.9563\n",
            "Epoch [58/200], Batch [200/750], Loss: 1.0119\n",
            "Epoch [58/200], Batch [300/750], Loss: 1.0791\n",
            "Epoch [58/200], Batch [400/750], Loss: 0.9796\n",
            "Epoch [58/200], Batch [500/750], Loss: 1.1399\n",
            "Epoch [58/200], Batch [600/750], Loss: 0.9463\n",
            "Epoch [58/200], Batch [700/750], Loss: 1.0496\n",
            "Epoch [58/200] Total train Cost: 787.3607239723206\n",
            "---------------------------------------------\n",
            "Epoch [59/200], Batch [100/750], Loss: 1.1255\n",
            "Epoch [59/200], Batch [200/750], Loss: 1.0331\n",
            "Epoch [59/200], Batch [300/750], Loss: 0.8960\n",
            "Epoch [59/200], Batch [400/750], Loss: 1.0414\n",
            "Epoch [59/200], Batch [500/750], Loss: 1.0588\n",
            "Epoch [59/200], Batch [600/750], Loss: 0.8738\n",
            "Epoch [59/200], Batch [700/750], Loss: 0.9778\n",
            "Epoch [59/200] Total train Cost: 775.9039599895477\n",
            "---------------------------------------------\n",
            "Epoch [60/200], Batch [100/750], Loss: 1.0232\n",
            "Epoch [60/200], Batch [200/750], Loss: 0.9786\n",
            "Epoch [60/200], Batch [300/750], Loss: 1.0105\n",
            "Epoch [60/200], Batch [400/750], Loss: 1.1479\n",
            "Epoch [60/200], Batch [500/750], Loss: 1.1761\n",
            "Epoch [60/200], Batch [600/750], Loss: 0.9999\n",
            "Epoch [60/200], Batch [700/750], Loss: 1.0267\n",
            "Epoch [60/200] Total train Cost: 764.797010242939\n",
            "---------------------------------------------\n",
            "Epoch [61/200], Batch [100/750], Loss: 0.9741\n",
            "Epoch [61/200], Batch [200/750], Loss: 1.0616\n",
            "Epoch [61/200], Batch [300/750], Loss: 0.9985\n",
            "Epoch [61/200], Batch [400/750], Loss: 0.9878\n",
            "Epoch [61/200], Batch [500/750], Loss: 1.0550\n",
            "Epoch [61/200], Batch [600/750], Loss: 0.9449\n",
            "Epoch [61/200], Batch [700/750], Loss: 1.1212\n",
            "Epoch [61/200] Total train Cost: 754.028850197792\n",
            "---------------------------------------------\n",
            "Epoch [62/200], Batch [100/750], Loss: 1.0450\n",
            "Epoch [62/200], Batch [200/750], Loss: 1.0184\n",
            "Epoch [62/200], Batch [300/750], Loss: 0.9094\n",
            "Epoch [62/200], Batch [400/750], Loss: 0.9453\n",
            "Epoch [62/200], Batch [500/750], Loss: 1.0615\n",
            "Epoch [62/200], Batch [600/750], Loss: 1.0230\n",
            "Epoch [62/200], Batch [700/750], Loss: 0.9868\n",
            "Epoch [62/200] Total train Cost: 743.5898247361183\n",
            "---------------------------------------------\n",
            "Epoch [63/200], Batch [100/750], Loss: 1.0447\n",
            "Epoch [63/200], Batch [200/750], Loss: 1.0089\n",
            "Epoch [63/200], Batch [300/750], Loss: 1.0782\n",
            "Epoch [63/200], Batch [400/750], Loss: 0.9802\n",
            "Epoch [63/200], Batch [500/750], Loss: 0.9244\n",
            "Epoch [63/200], Batch [600/750], Loss: 1.0349\n",
            "Epoch [63/200], Batch [700/750], Loss: 1.0074\n",
            "Epoch [63/200] Total train Cost: 733.470418214798\n",
            "---------------------------------------------\n",
            "Epoch [64/200], Batch [100/750], Loss: 1.0299\n",
            "Epoch [64/200], Batch [200/750], Loss: 0.9439\n",
            "Epoch [64/200], Batch [300/750], Loss: 0.9782\n",
            "Epoch [64/200], Batch [400/750], Loss: 0.8833\n",
            "Epoch [64/200], Batch [500/750], Loss: 0.9338\n",
            "Epoch [64/200], Batch [600/750], Loss: 0.9276\n",
            "Epoch [64/200], Batch [700/750], Loss: 0.9504\n",
            "Epoch [64/200] Total train Cost: 723.6615672111511\n",
            "---------------------------------------------\n",
            "Epoch [65/200], Batch [100/750], Loss: 1.0071\n",
            "Epoch [65/200], Batch [200/750], Loss: 0.9441\n",
            "Epoch [65/200], Batch [300/750], Loss: 0.9115\n",
            "Epoch [65/200], Batch [400/750], Loss: 0.9924\n",
            "Epoch [65/200], Batch [500/750], Loss: 0.9527\n",
            "Epoch [65/200], Batch [600/750], Loss: 0.9610\n",
            "Epoch [65/200], Batch [700/750], Loss: 0.8660\n",
            "Epoch [65/200] Total train Cost: 714.1499333977699\n",
            "---------------------------------------------\n",
            "Epoch [66/200], Batch [100/750], Loss: 0.9966\n",
            "Epoch [66/200], Batch [200/750], Loss: 0.9021\n",
            "Epoch [66/200], Batch [300/750], Loss: 1.0290\n",
            "Epoch [66/200], Batch [400/750], Loss: 0.9261\n",
            "Epoch [66/200], Batch [500/750], Loss: 0.9618\n",
            "Epoch [66/200], Batch [600/750], Loss: 0.8654\n",
            "Epoch [66/200], Batch [700/750], Loss: 0.8537\n",
            "Epoch [66/200] Total train Cost: 704.9290208220482\n",
            "---------------------------------------------\n",
            "Epoch [67/200], Batch [100/750], Loss: 0.8828\n",
            "Epoch [67/200], Batch [200/750], Loss: 0.7874\n",
            "Epoch [67/200], Batch [300/750], Loss: 0.8979\n",
            "Epoch [67/200], Batch [400/750], Loss: 0.9552\n",
            "Epoch [67/200], Batch [500/750], Loss: 0.9746\n",
            "Epoch [67/200], Batch [600/750], Loss: 0.9148\n",
            "Epoch [67/200], Batch [700/750], Loss: 0.8867\n",
            "Epoch [67/200] Total train Cost: 695.9879756569862\n",
            "---------------------------------------------\n",
            "Epoch [68/200], Batch [100/750], Loss: 0.8204\n",
            "Epoch [68/200], Batch [200/750], Loss: 0.9157\n",
            "Epoch [68/200], Batch [300/750], Loss: 1.0484\n",
            "Epoch [68/200], Batch [400/750], Loss: 0.9733\n",
            "Epoch [68/200], Batch [500/750], Loss: 1.0357\n",
            "Epoch [68/200], Batch [600/750], Loss: 0.9940\n",
            "Epoch [68/200], Batch [700/750], Loss: 0.9785\n",
            "Epoch [68/200] Total train Cost: 687.3167839050293\n",
            "---------------------------------------------\n",
            "Epoch [69/200], Batch [100/750], Loss: 0.8875\n",
            "Epoch [69/200], Batch [200/750], Loss: 0.8580\n",
            "Epoch [69/200], Batch [300/750], Loss: 0.9664\n",
            "Epoch [69/200], Batch [400/750], Loss: 0.7813\n",
            "Epoch [69/200], Batch [500/750], Loss: 0.9171\n",
            "Epoch [69/200], Batch [600/750], Loss: 0.9678\n",
            "Epoch [69/200], Batch [700/750], Loss: 0.9801\n",
            "Epoch [69/200] Total train Cost: 678.9080197811127\n",
            "---------------------------------------------\n",
            "Epoch [70/200], Batch [100/750], Loss: 1.0174\n",
            "Epoch [70/200], Batch [200/750], Loss: 0.9074\n",
            "Epoch [70/200], Batch [300/750], Loss: 0.8588\n",
            "Epoch [70/200], Batch [400/750], Loss: 0.7846\n",
            "Epoch [70/200], Batch [500/750], Loss: 1.0376\n",
            "Epoch [70/200], Batch [600/750], Loss: 0.8388\n",
            "Epoch [70/200], Batch [700/750], Loss: 0.9507\n",
            "Epoch [70/200] Total train Cost: 670.7506330013275\n",
            "---------------------------------------------\n",
            "Epoch [71/200], Batch [100/750], Loss: 0.8381\n",
            "Epoch [71/200], Batch [200/750], Loss: 0.7664\n",
            "Epoch [71/200], Batch [300/750], Loss: 0.9815\n",
            "Epoch [71/200], Batch [400/750], Loss: 0.7586\n",
            "Epoch [71/200], Batch [500/750], Loss: 0.8457\n",
            "Epoch [71/200], Batch [600/750], Loss: 0.7846\n",
            "Epoch [71/200], Batch [700/750], Loss: 0.9888\n",
            "Epoch [71/200] Total train Cost: 662.8357590436935\n",
            "---------------------------------------------\n",
            "Epoch [72/200], Batch [100/750], Loss: 0.8514\n",
            "Epoch [72/200], Batch [200/750], Loss: 0.9261\n",
            "Epoch [72/200], Batch [300/750], Loss: 0.8330\n",
            "Epoch [72/200], Batch [400/750], Loss: 0.8345\n",
            "Epoch [72/200], Batch [500/750], Loss: 0.8222\n",
            "Epoch [72/200], Batch [600/750], Loss: 0.8699\n",
            "Epoch [72/200], Batch [700/750], Loss: 0.8940\n",
            "Epoch [72/200] Total train Cost: 655.1553682088852\n",
            "---------------------------------------------\n",
            "Epoch [73/200], Batch [100/750], Loss: 0.9953\n",
            "Epoch [73/200], Batch [200/750], Loss: 0.7698\n",
            "Epoch [73/200], Batch [300/750], Loss: 0.9354\n",
            "Epoch [73/200], Batch [400/750], Loss: 0.8435\n",
            "Epoch [73/200], Batch [500/750], Loss: 0.7351\n",
            "Epoch [73/200], Batch [600/750], Loss: 0.9728\n",
            "Epoch [73/200], Batch [700/750], Loss: 0.9521\n",
            "Epoch [73/200] Total train Cost: 647.7014417052269\n",
            "---------------------------------------------\n",
            "Epoch [74/200], Batch [100/750], Loss: 0.9025\n",
            "Epoch [74/200], Batch [200/750], Loss: 0.8196\n",
            "Epoch [74/200], Batch [300/750], Loss: 0.9166\n",
            "Epoch [74/200], Batch [400/750], Loss: 0.9732\n",
            "Epoch [74/200], Batch [500/750], Loss: 0.7766\n",
            "Epoch [74/200], Batch [600/750], Loss: 0.7574\n",
            "Epoch [74/200], Batch [700/750], Loss: 0.8195\n",
            "Epoch [74/200] Total train Cost: 640.4656916260719\n",
            "---------------------------------------------\n",
            "Epoch [75/200], Batch [100/750], Loss: 0.9434\n",
            "Epoch [75/200], Batch [200/750], Loss: 0.7571\n",
            "Epoch [75/200], Batch [300/750], Loss: 0.9450\n",
            "Epoch [75/200], Batch [400/750], Loss: 0.8216\n",
            "Epoch [75/200], Batch [500/750], Loss: 0.8259\n",
            "Epoch [75/200], Batch [600/750], Loss: 0.8970\n",
            "Epoch [75/200], Batch [700/750], Loss: 0.9112\n",
            "Epoch [75/200] Total train Cost: 633.4377405047417\n",
            "---------------------------------------------\n",
            "Epoch [76/200], Batch [100/750], Loss: 0.7593\n",
            "Epoch [76/200], Batch [200/750], Loss: 0.8561\n",
            "Epoch [76/200], Batch [300/750], Loss: 0.8895\n",
            "Epoch [76/200], Batch [400/750], Loss: 0.8329\n",
            "Epoch [76/200], Batch [500/750], Loss: 0.9005\n",
            "Epoch [76/200], Batch [600/750], Loss: 0.9713\n",
            "Epoch [76/200], Batch [700/750], Loss: 0.8204\n",
            "Epoch [76/200] Total train Cost: 626.6134833693504\n",
            "---------------------------------------------\n",
            "Epoch [77/200], Batch [100/750], Loss: 0.7189\n",
            "Epoch [77/200], Batch [200/750], Loss: 0.8324\n",
            "Epoch [77/200], Batch [300/750], Loss: 0.7665\n",
            "Epoch [77/200], Batch [400/750], Loss: 0.7125\n",
            "Epoch [77/200], Batch [500/750], Loss: 0.7505\n",
            "Epoch [77/200], Batch [600/750], Loss: 0.7571\n",
            "Epoch [77/200], Batch [700/750], Loss: 0.7747\n",
            "Epoch [77/200] Total train Cost: 619.9842205643654\n",
            "---------------------------------------------\n",
            "Epoch [78/200], Batch [100/750], Loss: 0.7099\n",
            "Epoch [78/200], Batch [200/750], Loss: 0.9110\n",
            "Epoch [78/200], Batch [300/750], Loss: 0.7180\n",
            "Epoch [78/200], Batch [400/750], Loss: 0.8528\n",
            "Epoch [78/200], Batch [500/750], Loss: 0.7589\n",
            "Epoch [78/200], Batch [600/750], Loss: 0.7986\n",
            "Epoch [78/200], Batch [700/750], Loss: 0.8555\n",
            "Epoch [78/200] Total train Cost: 613.5431917309761\n",
            "---------------------------------------------\n",
            "Epoch [79/200], Batch [100/750], Loss: 0.6115\n",
            "Epoch [79/200], Batch [200/750], Loss: 0.8415\n",
            "Epoch [79/200], Batch [300/750], Loss: 0.6830\n",
            "Epoch [79/200], Batch [400/750], Loss: 0.6614\n",
            "Epoch [79/200], Batch [500/750], Loss: 0.7803\n",
            "Epoch [79/200], Batch [600/750], Loss: 0.8872\n",
            "Epoch [79/200], Batch [700/750], Loss: 0.7099\n",
            "Epoch [79/200] Total train Cost: 607.2810876965523\n",
            "---------------------------------------------\n",
            "Epoch [80/200], Batch [100/750], Loss: 0.8419\n",
            "Epoch [80/200], Batch [200/750], Loss: 0.8246\n",
            "Epoch [80/200], Batch [300/750], Loss: 0.7490\n",
            "Epoch [80/200], Batch [400/750], Loss: 0.8722\n",
            "Epoch [80/200], Batch [500/750], Loss: 0.8172\n",
            "Epoch [80/200], Batch [600/750], Loss: 0.8089\n",
            "Epoch [80/200], Batch [700/750], Loss: 0.7759\n",
            "Epoch [80/200] Total train Cost: 601.1937775015831\n",
            "---------------------------------------------\n",
            "Epoch [81/200], Batch [100/750], Loss: 0.9077\n",
            "Epoch [81/200], Batch [200/750], Loss: 0.7493\n",
            "Epoch [81/200], Batch [300/750], Loss: 0.7852\n",
            "Epoch [81/200], Batch [400/750], Loss: 0.7971\n",
            "Epoch [81/200], Batch [500/750], Loss: 0.7628\n",
            "Epoch [81/200], Batch [600/750], Loss: 0.8243\n",
            "Epoch [81/200], Batch [700/750], Loss: 0.8663\n",
            "Epoch [81/200] Total train Cost: 595.2761990427971\n",
            "---------------------------------------------\n",
            "Epoch [82/200], Batch [100/750], Loss: 0.6558\n",
            "Epoch [82/200], Batch [200/750], Loss: 0.7533\n",
            "Epoch [82/200], Batch [300/750], Loss: 0.7633\n",
            "Epoch [82/200], Batch [400/750], Loss: 0.9581\n",
            "Epoch [82/200], Batch [500/750], Loss: 0.7212\n",
            "Epoch [82/200], Batch [600/750], Loss: 0.7661\n",
            "Epoch [82/200], Batch [700/750], Loss: 0.7447\n",
            "Epoch [82/200] Total train Cost: 589.518405854702\n",
            "---------------------------------------------\n",
            "Epoch [83/200], Batch [100/750], Loss: 0.7862\n",
            "Epoch [83/200], Batch [200/750], Loss: 0.6688\n",
            "Epoch [83/200], Batch [300/750], Loss: 0.6800\n",
            "Epoch [83/200], Batch [400/750], Loss: 0.8275\n",
            "Epoch [83/200], Batch [500/750], Loss: 0.8696\n",
            "Epoch [83/200], Batch [600/750], Loss: 0.8264\n",
            "Epoch [83/200], Batch [700/750], Loss: 0.8131\n",
            "Epoch [83/200] Total train Cost: 583.916594684124\n",
            "---------------------------------------------\n",
            "Epoch [84/200], Batch [100/750], Loss: 0.7399\n",
            "Epoch [84/200], Batch [200/750], Loss: 0.7499\n",
            "Epoch [84/200], Batch [300/750], Loss: 0.7805\n",
            "Epoch [84/200], Batch [400/750], Loss: 0.7243\n",
            "Epoch [84/200], Batch [500/750], Loss: 0.7403\n",
            "Epoch [84/200], Batch [600/750], Loss: 0.7093\n",
            "Epoch [84/200], Batch [700/750], Loss: 0.7901\n",
            "Epoch [84/200] Total train Cost: 578.4655023813248\n",
            "---------------------------------------------\n",
            "Epoch [85/200], Batch [100/750], Loss: 0.8070\n",
            "Epoch [85/200], Batch [200/750], Loss: 0.7427\n",
            "Epoch [85/200], Batch [300/750], Loss: 0.8280\n",
            "Epoch [85/200], Batch [400/750], Loss: 0.5584\n",
            "Epoch [85/200], Batch [500/750], Loss: 0.7657\n",
            "Epoch [85/200], Batch [600/750], Loss: 0.8063\n",
            "Epoch [85/200], Batch [700/750], Loss: 0.8787\n",
            "Epoch [85/200] Total train Cost: 573.158972799778\n",
            "---------------------------------------------\n",
            "Epoch [86/200], Batch [100/750], Loss: 0.9823\n",
            "Epoch [86/200], Batch [200/750], Loss: 0.7966\n",
            "Epoch [86/200], Batch [300/750], Loss: 0.7603\n",
            "Epoch [86/200], Batch [400/750], Loss: 0.7661\n",
            "Epoch [86/200], Batch [500/750], Loss: 0.8797\n",
            "Epoch [86/200], Batch [600/750], Loss: 0.7498\n",
            "Epoch [86/200], Batch [700/750], Loss: 0.7961\n",
            "Epoch [86/200] Total train Cost: 567.992273569107\n",
            "---------------------------------------------\n",
            "Epoch [87/200], Batch [100/750], Loss: 0.7892\n",
            "Epoch [87/200], Batch [200/750], Loss: 0.6824\n",
            "Epoch [87/200], Batch [300/750], Loss: 0.6046\n",
            "Epoch [87/200], Batch [400/750], Loss: 0.8072\n",
            "Epoch [87/200], Batch [500/750], Loss: 0.7538\n",
            "Epoch [87/200], Batch [600/750], Loss: 0.7993\n",
            "Epoch [87/200], Batch [700/750], Loss: 0.8136\n",
            "Epoch [87/200] Total train Cost: 562.959537923336\n",
            "---------------------------------------------\n",
            "Epoch [88/200], Batch [100/750], Loss: 0.8413\n",
            "Epoch [88/200], Batch [200/750], Loss: 0.6831\n",
            "Epoch [88/200], Batch [300/750], Loss: 0.8322\n",
            "Epoch [88/200], Batch [400/750], Loss: 0.7517\n",
            "Epoch [88/200], Batch [500/750], Loss: 0.6919\n",
            "Epoch [88/200], Batch [600/750], Loss: 0.7042\n",
            "Epoch [88/200], Batch [700/750], Loss: 0.6859\n",
            "Epoch [88/200] Total train Cost: 558.0579174160957\n",
            "---------------------------------------------\n",
            "Epoch [89/200], Batch [100/750], Loss: 0.6550\n",
            "Epoch [89/200], Batch [200/750], Loss: 0.6980\n",
            "Epoch [89/200], Batch [300/750], Loss: 0.7139\n",
            "Epoch [89/200], Batch [400/750], Loss: 0.7990\n",
            "Epoch [89/200], Batch [500/750], Loss: 0.6744\n",
            "Epoch [89/200], Batch [600/750], Loss: 0.8072\n",
            "Epoch [89/200], Batch [700/750], Loss: 0.8141\n",
            "Epoch [89/200] Total train Cost: 553.280152618885\n",
            "---------------------------------------------\n",
            "Epoch [90/200], Batch [100/750], Loss: 0.7010\n",
            "Epoch [90/200], Batch [200/750], Loss: 0.8084\n",
            "Epoch [90/200], Batch [300/750], Loss: 0.6183\n",
            "Epoch [90/200], Batch [400/750], Loss: 0.7354\n",
            "Epoch [90/200], Batch [500/750], Loss: 0.7265\n",
            "Epoch [90/200], Batch [600/750], Loss: 0.5641\n",
            "Epoch [90/200], Batch [700/750], Loss: 0.8032\n",
            "Epoch [90/200] Total train Cost: 548.6239633560181\n",
            "---------------------------------------------\n",
            "Epoch [91/200], Batch [100/750], Loss: 0.7965\n",
            "Epoch [91/200], Batch [200/750], Loss: 0.7925\n",
            "Epoch [91/200], Batch [300/750], Loss: 0.6852\n",
            "Epoch [91/200], Batch [400/750], Loss: 0.6834\n",
            "Epoch [91/200], Batch [500/750], Loss: 0.6486\n",
            "Epoch [91/200], Batch [600/750], Loss: 0.7212\n",
            "Epoch [91/200], Batch [700/750], Loss: 0.7585\n",
            "Epoch [91/200] Total train Cost: 544.0845576822758\n",
            "---------------------------------------------\n",
            "Epoch [92/200], Batch [100/750], Loss: 0.6810\n",
            "Epoch [92/200], Batch [200/750], Loss: 0.6540\n",
            "Epoch [92/200], Batch [300/750], Loss: 0.7542\n",
            "Epoch [92/200], Batch [400/750], Loss: 0.6899\n",
            "Epoch [92/200], Batch [500/750], Loss: 0.7150\n",
            "Epoch [92/200], Batch [600/750], Loss: 0.7023\n",
            "Epoch [92/200], Batch [700/750], Loss: 0.7283\n",
            "Epoch [92/200] Total train Cost: 539.6558234095573\n",
            "---------------------------------------------\n",
            "Epoch [93/200], Batch [100/750], Loss: 0.5833\n",
            "Epoch [93/200], Batch [200/750], Loss: 0.7058\n",
            "Epoch [93/200], Batch [300/750], Loss: 0.5953\n",
            "Epoch [93/200], Batch [400/750], Loss: 0.7924\n",
            "Epoch [93/200], Batch [500/750], Loss: 0.6550\n",
            "Epoch [93/200], Batch [600/750], Loss: 0.6046\n",
            "Epoch [93/200], Batch [700/750], Loss: 0.7104\n",
            "Epoch [93/200] Total train Cost: 535.3364587128162\n",
            "---------------------------------------------\n",
            "Epoch [94/200], Batch [100/750], Loss: 0.8205\n",
            "Epoch [94/200], Batch [200/750], Loss: 0.7446\n",
            "Epoch [94/200], Batch [300/750], Loss: 0.7046\n",
            "Epoch [94/200], Batch [400/750], Loss: 0.6684\n",
            "Epoch [94/200], Batch [500/750], Loss: 0.8316\n",
            "Epoch [94/200], Batch [600/750], Loss: 0.6463\n",
            "Epoch [94/200], Batch [700/750], Loss: 0.6632\n",
            "Epoch [94/200] Total train Cost: 531.1224793791771\n",
            "---------------------------------------------\n",
            "Epoch [95/200], Batch [100/750], Loss: 0.6729\n",
            "Epoch [95/200], Batch [200/750], Loss: 0.8084\n",
            "Epoch [95/200], Batch [300/750], Loss: 0.7341\n",
            "Epoch [95/200], Batch [400/750], Loss: 0.7799\n",
            "Epoch [95/200], Batch [500/750], Loss: 0.7252\n",
            "Epoch [95/200], Batch [600/750], Loss: 0.6834\n",
            "Epoch [95/200], Batch [700/750], Loss: 0.7020\n",
            "Epoch [95/200] Total train Cost: 527.0082973241806\n",
            "---------------------------------------------\n",
            "Epoch [96/200], Batch [100/750], Loss: 0.6680\n",
            "Epoch [96/200], Batch [200/750], Loss: 0.8017\n",
            "Epoch [96/200], Batch [300/750], Loss: 0.7838\n",
            "Epoch [96/200], Batch [400/750], Loss: 0.7492\n",
            "Epoch [96/200], Batch [500/750], Loss: 0.6723\n",
            "Epoch [96/200], Batch [600/750], Loss: 0.7267\n",
            "Epoch [96/200], Batch [700/750], Loss: 0.6906\n",
            "Epoch [96/200] Total train Cost: 522.9936829507351\n",
            "---------------------------------------------\n",
            "Epoch [97/200], Batch [100/750], Loss: 0.7281\n",
            "Epoch [97/200], Batch [200/750], Loss: 0.6728\n",
            "Epoch [97/200], Batch [300/750], Loss: 0.6118\n",
            "Epoch [97/200], Batch [400/750], Loss: 0.9382\n",
            "Epoch [97/200], Batch [500/750], Loss: 0.7624\n",
            "Epoch [97/200], Batch [600/750], Loss: 0.6315\n",
            "Epoch [97/200], Batch [700/750], Loss: 0.6675\n",
            "Epoch [97/200] Total train Cost: 519.071900755167\n",
            "---------------------------------------------\n",
            "Epoch [98/200], Batch [100/750], Loss: 0.6930\n",
            "Epoch [98/200], Batch [200/750], Loss: 0.8145\n",
            "Epoch [98/200], Batch [300/750], Loss: 0.6412\n",
            "Epoch [98/200], Batch [400/750], Loss: 0.6438\n",
            "Epoch [98/200], Batch [500/750], Loss: 0.6770\n",
            "Epoch [98/200], Batch [600/750], Loss: 0.6533\n",
            "Epoch [98/200], Batch [700/750], Loss: 0.6331\n",
            "Epoch [98/200] Total train Cost: 515.2429527938366\n",
            "---------------------------------------------\n",
            "Epoch [99/200], Batch [100/750], Loss: 0.6481\n",
            "Epoch [99/200], Batch [200/750], Loss: 0.6236\n",
            "Epoch [99/200], Batch [300/750], Loss: 0.7512\n",
            "Epoch [99/200], Batch [400/750], Loss: 0.6703\n",
            "Epoch [99/200], Batch [500/750], Loss: 0.6789\n",
            "Epoch [99/200], Batch [600/750], Loss: 0.7011\n",
            "Epoch [99/200], Batch [700/750], Loss: 0.6806\n",
            "Epoch [99/200] Total train Cost: 511.50156486034393\n",
            "---------------------------------------------\n",
            "Epoch [100/200], Batch [100/750], Loss: 0.5812\n",
            "Epoch [100/200], Batch [200/750], Loss: 0.6208\n",
            "Epoch [100/200], Batch [300/750], Loss: 0.7997\n",
            "Epoch [100/200], Batch [400/750], Loss: 0.7231\n",
            "Epoch [100/200], Batch [500/750], Loss: 0.6575\n",
            "Epoch [100/200], Batch [600/750], Loss: 0.7891\n",
            "Epoch [100/200], Batch [700/750], Loss: 0.6338\n",
            "Epoch [100/200] Total train Cost: 507.8459534943104\n",
            "---------------------------------------------\n",
            "Epoch [101/200], Batch [100/750], Loss: 0.8512\n",
            "Epoch [101/200], Batch [200/750], Loss: 0.7134\n",
            "Epoch [101/200], Batch [300/750], Loss: 0.6768\n",
            "Epoch [101/200], Batch [400/750], Loss: 0.6912\n",
            "Epoch [101/200], Batch [500/750], Loss: 0.6983\n",
            "Epoch [101/200], Batch [600/750], Loss: 0.7233\n",
            "Epoch [101/200], Batch [700/750], Loss: 0.7256\n",
            "Epoch [101/200] Total train Cost: 504.2731750905514\n",
            "---------------------------------------------\n",
            "Epoch [102/200], Batch [100/750], Loss: 0.5336\n",
            "Epoch [102/200], Batch [200/750], Loss: 0.6094\n",
            "Epoch [102/200], Batch [300/750], Loss: 0.7171\n",
            "Epoch [102/200], Batch [400/750], Loss: 0.7412\n",
            "Epoch [102/200], Batch [500/750], Loss: 0.6676\n",
            "Epoch [102/200], Batch [600/750], Loss: 0.7346\n",
            "Epoch [102/200], Batch [700/750], Loss: 0.6866\n",
            "Epoch [102/200] Total train Cost: 500.7794621884823\n",
            "---------------------------------------------\n",
            "Epoch [103/200], Batch [100/750], Loss: 0.5763\n",
            "Epoch [103/200], Batch [200/750], Loss: 0.6181\n",
            "Epoch [103/200], Batch [300/750], Loss: 0.7542\n",
            "Epoch [103/200], Batch [400/750], Loss: 0.6612\n",
            "Epoch [103/200], Batch [500/750], Loss: 0.5940\n",
            "Epoch [103/200], Batch [600/750], Loss: 0.7397\n",
            "Epoch [103/200], Batch [700/750], Loss: 0.6974\n",
            "Epoch [103/200] Total train Cost: 497.3646246790886\n",
            "---------------------------------------------\n",
            "Epoch [104/200], Batch [100/750], Loss: 0.7363\n",
            "Epoch [104/200], Batch [200/750], Loss: 0.6517\n",
            "Epoch [104/200], Batch [300/750], Loss: 0.6107\n",
            "Epoch [104/200], Batch [400/750], Loss: 0.6277\n",
            "Epoch [104/200], Batch [500/750], Loss: 0.7063\n",
            "Epoch [104/200], Batch [600/750], Loss: 0.6811\n",
            "Epoch [104/200], Batch [700/750], Loss: 0.6313\n",
            "Epoch [104/200] Total train Cost: 494.0237866640091\n",
            "---------------------------------------------\n",
            "Epoch [105/200], Batch [100/750], Loss: 0.6974\n",
            "Epoch [105/200], Batch [200/750], Loss: 0.6788\n",
            "Epoch [105/200], Batch [300/750], Loss: 0.6977\n",
            "Epoch [105/200], Batch [400/750], Loss: 0.7352\n",
            "Epoch [105/200], Batch [500/750], Loss: 0.6926\n",
            "Epoch [105/200], Batch [600/750], Loss: 0.6436\n",
            "Epoch [105/200], Batch [700/750], Loss: 0.6217\n",
            "Epoch [105/200] Total train Cost: 490.7557609677315\n",
            "---------------------------------------------\n",
            "Epoch [106/200], Batch [100/750], Loss: 0.5708\n",
            "Epoch [106/200], Batch [200/750], Loss: 0.6899\n",
            "Epoch [106/200], Batch [300/750], Loss: 0.6751\n",
            "Epoch [106/200], Batch [400/750], Loss: 0.5624\n",
            "Epoch [106/200], Batch [500/750], Loss: 0.7068\n",
            "Epoch [106/200], Batch [600/750], Loss: 0.7414\n",
            "Epoch [106/200], Batch [700/750], Loss: 0.7180\n",
            "Epoch [106/200] Total train Cost: 487.5580608546734\n",
            "---------------------------------------------\n",
            "Epoch [107/200], Batch [100/750], Loss: 0.7116\n",
            "Epoch [107/200], Batch [200/750], Loss: 0.7745\n",
            "Epoch [107/200], Batch [300/750], Loss: 0.7294\n",
            "Epoch [107/200], Batch [400/750], Loss: 0.7154\n",
            "Epoch [107/200], Batch [500/750], Loss: 0.6383\n",
            "Epoch [107/200], Batch [600/750], Loss: 0.7341\n",
            "Epoch [107/200], Batch [700/750], Loss: 0.5295\n",
            "Epoch [107/200] Total train Cost: 484.4282277226448\n",
            "---------------------------------------------\n",
            "Epoch [108/200], Batch [100/750], Loss: 0.6950\n",
            "Epoch [108/200], Batch [200/750], Loss: 0.7995\n",
            "Epoch [108/200], Batch [300/750], Loss: 0.6323\n",
            "Epoch [108/200], Batch [400/750], Loss: 0.6231\n",
            "Epoch [108/200], Batch [500/750], Loss: 0.6975\n",
            "Epoch [108/200], Batch [600/750], Loss: 0.6664\n",
            "Epoch [108/200], Batch [700/750], Loss: 0.6351\n",
            "Epoch [108/200] Total train Cost: 481.3635838627815\n",
            "---------------------------------------------\n",
            "Epoch [109/200], Batch [100/750], Loss: 0.6024\n",
            "Epoch [109/200], Batch [200/750], Loss: 0.7689\n",
            "Epoch [109/200], Batch [300/750], Loss: 0.7052\n",
            "Epoch [109/200], Batch [400/750], Loss: 0.6849\n",
            "Epoch [109/200], Batch [500/750], Loss: 0.6012\n",
            "Epoch [109/200], Batch [600/750], Loss: 0.4855\n",
            "Epoch [109/200], Batch [700/750], Loss: 0.6594\n",
            "Epoch [109/200] Total train Cost: 478.3656357526779\n",
            "---------------------------------------------\n",
            "Epoch [110/200], Batch [100/750], Loss: 0.5720\n",
            "Epoch [110/200], Batch [200/750], Loss: 0.6108\n",
            "Epoch [110/200], Batch [300/750], Loss: 0.6487\n",
            "Epoch [110/200], Batch [400/750], Loss: 0.5418\n",
            "Epoch [110/200], Batch [500/750], Loss: 0.6053\n",
            "Epoch [110/200], Batch [600/750], Loss: 0.8722\n",
            "Epoch [110/200], Batch [700/750], Loss: 0.5846\n",
            "Epoch [110/200] Total train Cost: 475.4273214042187\n",
            "---------------------------------------------\n",
            "Epoch [111/200], Batch [100/750], Loss: 0.5986\n",
            "Epoch [111/200], Batch [200/750], Loss: 0.5971\n",
            "Epoch [111/200], Batch [300/750], Loss: 0.6729\n",
            "Epoch [111/200], Batch [400/750], Loss: 0.6226\n",
            "Epoch [111/200], Batch [500/750], Loss: 0.6457\n",
            "Epoch [111/200], Batch [600/750], Loss: 0.7284\n",
            "Epoch [111/200], Batch [700/750], Loss: 0.7373\n",
            "Epoch [111/200] Total train Cost: 472.55072596669197\n",
            "---------------------------------------------\n",
            "Epoch [112/200], Batch [100/750], Loss: 0.6226\n",
            "Epoch [112/200], Batch [200/750], Loss: 0.5750\n",
            "Epoch [112/200], Batch [300/750], Loss: 0.7528\n",
            "Epoch [112/200], Batch [400/750], Loss: 0.6522\n",
            "Epoch [112/200], Batch [500/750], Loss: 0.5413\n",
            "Epoch [112/200], Batch [600/750], Loss: 0.5982\n",
            "Epoch [112/200], Batch [700/750], Loss: 0.7099\n",
            "Epoch [112/200] Total train Cost: 469.7317377626896\n",
            "---------------------------------------------\n",
            "Epoch [113/200], Batch [100/750], Loss: 0.5262\n",
            "Epoch [113/200], Batch [200/750], Loss: 0.6521\n",
            "Epoch [113/200], Batch [300/750], Loss: 0.6463\n",
            "Epoch [113/200], Batch [400/750], Loss: 0.6715\n",
            "Epoch [113/200], Batch [500/750], Loss: 0.7123\n",
            "Epoch [113/200], Batch [600/750], Loss: 0.5291\n",
            "Epoch [113/200], Batch [700/750], Loss: 0.7338\n",
            "Epoch [113/200] Total train Cost: 466.9699212014675\n",
            "---------------------------------------------\n",
            "Epoch [114/200], Batch [100/750], Loss: 0.6620\n",
            "Epoch [114/200], Batch [200/750], Loss: 0.6964\n",
            "Epoch [114/200], Batch [300/750], Loss: 0.5497\n",
            "Epoch [114/200], Batch [400/750], Loss: 0.5850\n",
            "Epoch [114/200], Batch [500/750], Loss: 0.5155\n",
            "Epoch [114/200], Batch [600/750], Loss: 0.5559\n",
            "Epoch [114/200], Batch [700/750], Loss: 0.5013\n",
            "Epoch [114/200] Total train Cost: 464.26312017440796\n",
            "---------------------------------------------\n",
            "Epoch [115/200], Batch [100/750], Loss: 0.5505\n",
            "Epoch [115/200], Batch [200/750], Loss: 0.6536\n",
            "Epoch [115/200], Batch [300/750], Loss: 0.5791\n",
            "Epoch [115/200], Batch [400/750], Loss: 0.6015\n",
            "Epoch [115/200], Batch [500/750], Loss: 0.7243\n",
            "Epoch [115/200], Batch [600/750], Loss: 0.5820\n",
            "Epoch [115/200], Batch [700/750], Loss: 0.7029\n",
            "Epoch [115/200] Total train Cost: 461.6093470156193\n",
            "---------------------------------------------\n",
            "Epoch [116/200], Batch [100/750], Loss: 0.5919\n",
            "Epoch [116/200], Batch [200/750], Loss: 0.6329\n",
            "Epoch [116/200], Batch [300/750], Loss: 0.6675\n",
            "Epoch [116/200], Batch [400/750], Loss: 0.5407\n",
            "Epoch [116/200], Batch [500/750], Loss: 0.5097\n",
            "Epoch [116/200], Batch [600/750], Loss: 0.5394\n",
            "Epoch [116/200], Batch [700/750], Loss: 0.6713\n",
            "Epoch [116/200] Total train Cost: 459.0076342523098\n",
            "---------------------------------------------\n",
            "Epoch [117/200], Batch [100/750], Loss: 0.5748\n",
            "Epoch [117/200], Batch [200/750], Loss: 0.6646\n",
            "Epoch [117/200], Batch [300/750], Loss: 0.4262\n",
            "Epoch [117/200], Batch [400/750], Loss: 0.6613\n",
            "Epoch [117/200], Batch [500/750], Loss: 0.4537\n",
            "Epoch [117/200], Batch [600/750], Loss: 0.6813\n",
            "Epoch [117/200], Batch [700/750], Loss: 0.6319\n",
            "Epoch [117/200] Total train Cost: 456.4564665257931\n",
            "---------------------------------------------\n",
            "Epoch [118/200], Batch [100/750], Loss: 0.7072\n",
            "Epoch [118/200], Batch [200/750], Loss: 0.5078\n",
            "Epoch [118/200], Batch [300/750], Loss: 0.6812\n",
            "Epoch [118/200], Batch [400/750], Loss: 0.6783\n",
            "Epoch [118/200], Batch [500/750], Loss: 0.7007\n",
            "Epoch [118/200], Batch [600/750], Loss: 0.5887\n",
            "Epoch [118/200], Batch [700/750], Loss: 0.6288\n",
            "Epoch [118/200] Total train Cost: 453.9544190466404\n",
            "---------------------------------------------\n",
            "Epoch [119/200], Batch [100/750], Loss: 0.4930\n",
            "Epoch [119/200], Batch [200/750], Loss: 0.5814\n",
            "Epoch [119/200], Batch [300/750], Loss: 0.7108\n",
            "Epoch [119/200], Batch [400/750], Loss: 0.6516\n",
            "Epoch [119/200], Batch [500/750], Loss: 0.6577\n",
            "Epoch [119/200], Batch [600/750], Loss: 0.6578\n",
            "Epoch [119/200], Batch [700/750], Loss: 0.7225\n",
            "Epoch [119/200] Total train Cost: 451.49938377738\n",
            "---------------------------------------------\n",
            "Epoch [120/200], Batch [100/750], Loss: 0.6414\n",
            "Epoch [120/200], Batch [200/750], Loss: 0.6190\n",
            "Epoch [120/200], Batch [300/750], Loss: 0.5308\n",
            "Epoch [120/200], Batch [400/750], Loss: 0.5364\n",
            "Epoch [120/200], Batch [500/750], Loss: 0.7101\n",
            "Epoch [120/200], Batch [600/750], Loss: 0.5786\n",
            "Epoch [120/200], Batch [700/750], Loss: 0.6223\n",
            "Epoch [120/200] Total train Cost: 449.0909296274185\n",
            "---------------------------------------------\n",
            "Epoch [121/200], Batch [100/750], Loss: 0.5950\n",
            "Epoch [121/200], Batch [200/750], Loss: 0.5357\n",
            "Epoch [121/200], Batch [300/750], Loss: 0.5756\n",
            "Epoch [121/200], Batch [400/750], Loss: 0.5574\n",
            "Epoch [121/200], Batch [500/750], Loss: 0.5635\n",
            "Epoch [121/200], Batch [600/750], Loss: 0.6858\n",
            "Epoch [121/200], Batch [700/750], Loss: 0.6733\n",
            "Epoch [121/200] Total train Cost: 446.72730228304863\n",
            "---------------------------------------------\n",
            "Epoch [122/200], Batch [100/750], Loss: 0.6022\n",
            "Epoch [122/200], Batch [200/750], Loss: 0.5932\n",
            "Epoch [122/200], Batch [300/750], Loss: 0.5689\n",
            "Epoch [122/200], Batch [400/750], Loss: 0.6266\n",
            "Epoch [122/200], Batch [500/750], Loss: 0.5901\n",
            "Epoch [122/200], Batch [600/750], Loss: 0.5602\n",
            "Epoch [122/200], Batch [700/750], Loss: 0.5495\n",
            "Epoch [122/200] Total train Cost: 444.40809935331345\n",
            "---------------------------------------------\n",
            "Epoch [123/200], Batch [100/750], Loss: 0.6236\n",
            "Epoch [123/200], Batch [200/750], Loss: 0.5894\n",
            "Epoch [123/200], Batch [300/750], Loss: 0.5252\n",
            "Epoch [123/200], Batch [400/750], Loss: 0.5900\n",
            "Epoch [123/200], Batch [500/750], Loss: 0.5472\n",
            "Epoch [123/200], Batch [600/750], Loss: 0.5157\n",
            "Epoch [123/200], Batch [700/750], Loss: 0.5444\n",
            "Epoch [123/200] Total train Cost: 442.13123086094856\n",
            "---------------------------------------------\n",
            "Epoch [124/200], Batch [100/750], Loss: 0.6712\n",
            "Epoch [124/200], Batch [200/750], Loss: 0.6733\n",
            "Epoch [124/200], Batch [300/750], Loss: 0.6773\n",
            "Epoch [124/200], Batch [400/750], Loss: 0.5268\n",
            "Epoch [124/200], Batch [500/750], Loss: 0.5117\n",
            "Epoch [124/200], Batch [600/750], Loss: 0.5843\n",
            "Epoch [124/200], Batch [700/750], Loss: 0.5694\n",
            "Epoch [124/200] Total train Cost: 439.895418792963\n",
            "---------------------------------------------\n",
            "Epoch [125/200], Batch [100/750], Loss: 0.4695\n",
            "Epoch [125/200], Batch [200/750], Loss: 0.6841\n",
            "Epoch [125/200], Batch [300/750], Loss: 0.6662\n",
            "Epoch [125/200], Batch [400/750], Loss: 0.6297\n",
            "Epoch [125/200], Batch [500/750], Loss: 0.6067\n",
            "Epoch [125/200], Batch [600/750], Loss: 0.6313\n",
            "Epoch [125/200], Batch [700/750], Loss: 0.6071\n",
            "Epoch [125/200] Total train Cost: 437.7011585831642\n",
            "---------------------------------------------\n",
            "Epoch [126/200], Batch [100/750], Loss: 0.6207\n",
            "Epoch [126/200], Batch [200/750], Loss: 0.4547\n",
            "Epoch [126/200], Batch [300/750], Loss: 0.6002\n",
            "Epoch [126/200], Batch [400/750], Loss: 0.7173\n",
            "Epoch [126/200], Batch [500/750], Loss: 0.5838\n",
            "Epoch [126/200], Batch [600/750], Loss: 0.4851\n",
            "Epoch [126/200], Batch [700/750], Loss: 0.5395\n",
            "Epoch [126/200] Total train Cost: 435.5452687740326\n",
            "---------------------------------------------\n",
            "Epoch [127/200], Batch [100/750], Loss: 0.5839\n",
            "Epoch [127/200], Batch [200/750], Loss: 0.6821\n",
            "Epoch [127/200], Batch [300/750], Loss: 0.6105\n",
            "Epoch [127/200], Batch [400/750], Loss: 0.4907\n",
            "Epoch [127/200], Batch [500/750], Loss: 0.4946\n",
            "Epoch [127/200], Batch [600/750], Loss: 0.6018\n",
            "Epoch [127/200], Batch [700/750], Loss: 0.5278\n",
            "Epoch [127/200] Total train Cost: 433.42708295583725\n",
            "---------------------------------------------\n",
            "Epoch [128/200], Batch [100/750], Loss: 0.5523\n",
            "Epoch [128/200], Batch [200/750], Loss: 0.5825\n",
            "Epoch [128/200], Batch [300/750], Loss: 0.4294\n",
            "Epoch [128/200], Batch [400/750], Loss: 0.4440\n",
            "Epoch [128/200], Batch [500/750], Loss: 0.6122\n",
            "Epoch [128/200], Batch [600/750], Loss: 0.5558\n",
            "Epoch [128/200], Batch [700/750], Loss: 0.4707\n",
            "Epoch [128/200] Total train Cost: 431.34691792726517\n",
            "---------------------------------------------\n",
            "Epoch [129/200], Batch [100/750], Loss: 0.5378\n",
            "Epoch [129/200], Batch [200/750], Loss: 0.6243\n",
            "Epoch [129/200], Batch [300/750], Loss: 0.6258\n",
            "Epoch [129/200], Batch [400/750], Loss: 0.5368\n",
            "Epoch [129/200], Batch [500/750], Loss: 0.6248\n",
            "Epoch [129/200], Batch [600/750], Loss: 0.6207\n",
            "Epoch [129/200], Batch [700/750], Loss: 0.3995\n",
            "Epoch [129/200] Total train Cost: 429.30285450816154\n",
            "---------------------------------------------\n",
            "Epoch [130/200], Batch [100/750], Loss: 0.6431\n",
            "Epoch [130/200], Batch [200/750], Loss: 0.4868\n",
            "Epoch [130/200], Batch [300/750], Loss: 0.5088\n",
            "Epoch [130/200], Batch [400/750], Loss: 0.5681\n",
            "Epoch [130/200], Batch [500/750], Loss: 0.6928\n",
            "Epoch [130/200], Batch [600/750], Loss: 0.5644\n",
            "Epoch [130/200], Batch [700/750], Loss: 0.5523\n",
            "Epoch [130/200] Total train Cost: 427.2931725382805\n",
            "---------------------------------------------\n",
            "Epoch [131/200], Batch [100/750], Loss: 0.5342\n",
            "Epoch [131/200], Batch [200/750], Loss: 0.6561\n",
            "Epoch [131/200], Batch [300/750], Loss: 0.5872\n",
            "Epoch [131/200], Batch [400/750], Loss: 0.5867\n",
            "Epoch [131/200], Batch [500/750], Loss: 0.5012\n",
            "Epoch [131/200], Batch [600/750], Loss: 0.5917\n",
            "Epoch [131/200], Batch [700/750], Loss: 0.4198\n",
            "Epoch [131/200] Total train Cost: 425.31883046031\n",
            "---------------------------------------------\n",
            "Epoch [132/200], Batch [100/750], Loss: 0.5508\n",
            "Epoch [132/200], Batch [200/750], Loss: 0.4911\n",
            "Epoch [132/200], Batch [300/750], Loss: 0.5552\n",
            "Epoch [132/200], Batch [400/750], Loss: 0.7663\n",
            "Epoch [132/200], Batch [500/750], Loss: 0.4831\n",
            "Epoch [132/200], Batch [600/750], Loss: 0.5400\n",
            "Epoch [132/200], Batch [700/750], Loss: 0.4036\n",
            "Epoch [132/200] Total train Cost: 423.37842214107513\n",
            "---------------------------------------------\n",
            "Epoch [133/200], Batch [100/750], Loss: 0.5886\n",
            "Epoch [133/200], Batch [200/750], Loss: 0.4919\n",
            "Epoch [133/200], Batch [300/750], Loss: 0.5874\n",
            "Epoch [133/200], Batch [400/750], Loss: 0.5818\n",
            "Epoch [133/200], Batch [500/750], Loss: 0.5571\n",
            "Epoch [133/200], Batch [600/750], Loss: 0.4351\n",
            "Epoch [133/200], Batch [700/750], Loss: 0.4853\n",
            "Epoch [133/200] Total train Cost: 421.4707259237766\n",
            "---------------------------------------------\n",
            "Epoch [134/200], Batch [100/750], Loss: 0.4797\n",
            "Epoch [134/200], Batch [200/750], Loss: 0.4123\n",
            "Epoch [134/200], Batch [300/750], Loss: 0.5700\n",
            "Epoch [134/200], Batch [400/750], Loss: 0.6231\n",
            "Epoch [134/200], Batch [500/750], Loss: 0.6587\n",
            "Epoch [134/200], Batch [600/750], Loss: 0.5420\n",
            "Epoch [134/200], Batch [700/750], Loss: 0.7185\n",
            "Epoch [134/200] Total train Cost: 419.5943869948387\n",
            "---------------------------------------------\n",
            "Epoch [135/200], Batch [100/750], Loss: 0.5441\n",
            "Epoch [135/200], Batch [200/750], Loss: 0.6725\n",
            "Epoch [135/200], Batch [300/750], Loss: 0.5327\n",
            "Epoch [135/200], Batch [400/750], Loss: 0.5514\n",
            "Epoch [135/200], Batch [500/750], Loss: 0.7157\n",
            "Epoch [135/200], Batch [600/750], Loss: 0.5358\n",
            "Epoch [135/200], Batch [700/750], Loss: 0.6230\n",
            "Epoch [135/200] Total train Cost: 417.7483134865761\n",
            "---------------------------------------------\n",
            "Epoch [136/200], Batch [100/750], Loss: 0.5621\n",
            "Epoch [136/200], Batch [200/750], Loss: 0.6976\n",
            "Epoch [136/200], Batch [300/750], Loss: 0.5505\n",
            "Epoch [136/200], Batch [400/750], Loss: 0.5931\n",
            "Epoch [136/200], Batch [500/750], Loss: 0.5071\n",
            "Epoch [136/200], Batch [600/750], Loss: 0.6098\n",
            "Epoch [136/200], Batch [700/750], Loss: 0.5950\n",
            "Epoch [136/200] Total train Cost: 415.9349964261055\n",
            "---------------------------------------------\n",
            "Epoch [137/200], Batch [100/750], Loss: 0.4345\n",
            "Epoch [137/200], Batch [200/750], Loss: 0.4581\n",
            "Epoch [137/200], Batch [300/750], Loss: 0.5141\n",
            "Epoch [137/200], Batch [400/750], Loss: 0.4357\n",
            "Epoch [137/200], Batch [500/750], Loss: 0.5812\n",
            "Epoch [137/200], Batch [600/750], Loss: 0.5129\n",
            "Epoch [137/200], Batch [700/750], Loss: 0.6587\n",
            "Epoch [137/200] Total train Cost: 414.1502052247524\n",
            "---------------------------------------------\n",
            "Epoch [138/200], Batch [100/750], Loss: 0.4821\n",
            "Epoch [138/200], Batch [200/750], Loss: 0.5958\n",
            "Epoch [138/200], Batch [300/750], Loss: 0.7260\n",
            "Epoch [138/200], Batch [400/750], Loss: 0.4737\n",
            "Epoch [138/200], Batch [500/750], Loss: 0.5973\n",
            "Epoch [138/200], Batch [600/750], Loss: 0.5093\n",
            "Epoch [138/200], Batch [700/750], Loss: 0.6315\n",
            "Epoch [138/200] Total train Cost: 412.3933000564575\n",
            "---------------------------------------------\n",
            "Epoch [139/200], Batch [100/750], Loss: 0.5131\n",
            "Epoch [139/200], Batch [200/750], Loss: 0.4931\n",
            "Epoch [139/200], Batch [300/750], Loss: 0.6944\n",
            "Epoch [139/200], Batch [400/750], Loss: 0.5607\n",
            "Epoch [139/200], Batch [500/750], Loss: 0.5590\n",
            "Epoch [139/200], Batch [600/750], Loss: 0.5420\n",
            "Epoch [139/200], Batch [700/750], Loss: 0.5050\n",
            "Epoch [139/200] Total train Cost: 410.6660511791706\n",
            "---------------------------------------------\n",
            "Epoch [140/200], Batch [100/750], Loss: 0.5402\n",
            "Epoch [140/200], Batch [200/750], Loss: 0.4611\n",
            "Epoch [140/200], Batch [300/750], Loss: 0.6647\n",
            "Epoch [140/200], Batch [400/750], Loss: 0.5240\n",
            "Epoch [140/200], Batch [500/750], Loss: 0.4085\n",
            "Epoch [140/200], Batch [600/750], Loss: 0.5950\n",
            "Epoch [140/200], Batch [700/750], Loss: 0.5898\n",
            "Epoch [140/200] Total train Cost: 408.96606010198593\n",
            "---------------------------------------------\n",
            "Epoch [141/200], Batch [100/750], Loss: 0.4980\n",
            "Epoch [141/200], Batch [200/750], Loss: 0.4267\n",
            "Epoch [141/200], Batch [300/750], Loss: 0.4835\n",
            "Epoch [141/200], Batch [400/750], Loss: 0.5286\n",
            "Epoch [141/200], Batch [500/750], Loss: 0.4733\n",
            "Epoch [141/200], Batch [600/750], Loss: 0.4180\n",
            "Epoch [141/200], Batch [700/750], Loss: 0.6195\n",
            "Epoch [141/200] Total train Cost: 407.2924787700176\n",
            "---------------------------------------------\n",
            "Epoch [142/200], Batch [100/750], Loss: 0.3716\n",
            "Epoch [142/200], Batch [200/750], Loss: 0.6736\n",
            "Epoch [142/200], Batch [300/750], Loss: 0.5065\n",
            "Epoch [142/200], Batch [400/750], Loss: 0.7197\n",
            "Epoch [142/200], Batch [500/750], Loss: 0.4205\n",
            "Epoch [142/200], Batch [600/750], Loss: 0.4971\n",
            "Epoch [142/200], Batch [700/750], Loss: 0.7552\n",
            "Epoch [142/200] Total train Cost: 405.646229326725\n",
            "---------------------------------------------\n",
            "Epoch [143/200], Batch [100/750], Loss: 0.5083\n",
            "Epoch [143/200], Batch [200/750], Loss: 0.4902\n",
            "Epoch [143/200], Batch [300/750], Loss: 0.3743\n",
            "Epoch [143/200], Batch [400/750], Loss: 0.5754\n",
            "Epoch [143/200], Batch [500/750], Loss: 0.6738\n",
            "Epoch [143/200], Batch [600/750], Loss: 0.4341\n",
            "Epoch [143/200], Batch [700/750], Loss: 0.6608\n",
            "Epoch [143/200] Total train Cost: 404.02445662021637\n",
            "---------------------------------------------\n",
            "Epoch [144/200], Batch [100/750], Loss: 0.6208\n",
            "Epoch [144/200], Batch [200/750], Loss: 0.5349\n",
            "Epoch [144/200], Batch [300/750], Loss: 0.4239\n",
            "Epoch [144/200], Batch [400/750], Loss: 0.6122\n",
            "Epoch [144/200], Batch [500/750], Loss: 0.5032\n",
            "Epoch [144/200], Batch [600/750], Loss: 0.5145\n",
            "Epoch [144/200], Batch [700/750], Loss: 0.5169\n",
            "Epoch [144/200] Total train Cost: 402.4291880130768\n",
            "---------------------------------------------\n",
            "Epoch [145/200], Batch [100/750], Loss: 0.6479\n",
            "Epoch [145/200], Batch [200/750], Loss: 0.5210\n",
            "Epoch [145/200], Batch [300/750], Loss: 0.5498\n",
            "Epoch [145/200], Batch [400/750], Loss: 0.6250\n",
            "Epoch [145/200], Batch [500/750], Loss: 0.5323\n",
            "Epoch [145/200], Batch [600/750], Loss: 0.7044\n",
            "Epoch [145/200], Batch [700/750], Loss: 0.6696\n",
            "Epoch [145/200] Total train Cost: 400.85685989260674\n",
            "---------------------------------------------\n",
            "Epoch [146/200], Batch [100/750], Loss: 0.4386\n",
            "Epoch [146/200], Batch [200/750], Loss: 0.5468\n",
            "Epoch [146/200], Batch [300/750], Loss: 0.5380\n",
            "Epoch [146/200], Batch [400/750], Loss: 0.5158\n",
            "Epoch [146/200], Batch [500/750], Loss: 0.7569\n",
            "Epoch [146/200], Batch [600/750], Loss: 0.5258\n",
            "Epoch [146/200], Batch [700/750], Loss: 0.5611\n",
            "Epoch [146/200] Total train Cost: 399.3100470304489\n",
            "---------------------------------------------\n",
            "Epoch [147/200], Batch [100/750], Loss: 0.3725\n",
            "Epoch [147/200], Batch [200/750], Loss: 0.4094\n",
            "Epoch [147/200], Batch [300/750], Loss: 0.6216\n",
            "Epoch [147/200], Batch [400/750], Loss: 0.3730\n",
            "Epoch [147/200], Batch [500/750], Loss: 0.5941\n",
            "Epoch [147/200], Batch [600/750], Loss: 0.6340\n",
            "Epoch [147/200], Batch [700/750], Loss: 0.3892\n",
            "Epoch [147/200] Total train Cost: 397.7849556207657\n",
            "---------------------------------------------\n",
            "Epoch [148/200], Batch [100/750], Loss: 0.4542\n",
            "Epoch [148/200], Batch [200/750], Loss: 0.5216\n",
            "Epoch [148/200], Batch [300/750], Loss: 0.5226\n",
            "Epoch [148/200], Batch [400/750], Loss: 0.4243\n",
            "Epoch [148/200], Batch [500/750], Loss: 0.4023\n",
            "Epoch [148/200], Batch [600/750], Loss: 0.4765\n",
            "Epoch [148/200], Batch [700/750], Loss: 0.5492\n",
            "Epoch [148/200] Total train Cost: 396.2834866940975\n",
            "---------------------------------------------\n",
            "Epoch [149/200], Batch [100/750], Loss: 0.4702\n",
            "Epoch [149/200], Batch [200/750], Loss: 0.5505\n",
            "Epoch [149/200], Batch [300/750], Loss: 0.5185\n",
            "Epoch [149/200], Batch [400/750], Loss: 0.4943\n",
            "Epoch [149/200], Batch [500/750], Loss: 0.5550\n",
            "Epoch [149/200], Batch [600/750], Loss: 0.5128\n",
            "Epoch [149/200], Batch [700/750], Loss: 0.4400\n",
            "Epoch [149/200] Total train Cost: 394.805626899004\n",
            "---------------------------------------------\n",
            "Epoch [150/200], Batch [100/750], Loss: 0.6194\n",
            "Epoch [150/200], Batch [200/750], Loss: 0.3140\n",
            "Epoch [150/200], Batch [300/750], Loss: 0.7646\n",
            "Epoch [150/200], Batch [400/750], Loss: 0.4355\n",
            "Epoch [150/200], Batch [500/750], Loss: 0.6753\n",
            "Epoch [150/200], Batch [600/750], Loss: 0.3498\n",
            "Epoch [150/200], Batch [700/750], Loss: 0.7697\n",
            "Epoch [150/200] Total train Cost: 393.34739151597023\n",
            "---------------------------------------------\n",
            "Epoch [151/200], Batch [100/750], Loss: 0.4702\n",
            "Epoch [151/200], Batch [200/750], Loss: 0.4924\n",
            "Epoch [151/200], Batch [300/750], Loss: 0.4651\n",
            "Epoch [151/200], Batch [400/750], Loss: 0.6031\n",
            "Epoch [151/200], Batch [500/750], Loss: 0.6714\n",
            "Epoch [151/200], Batch [600/750], Loss: 0.7158\n",
            "Epoch [151/200], Batch [700/750], Loss: 0.5621\n",
            "Epoch [151/200] Total train Cost: 391.9130634367466\n",
            "---------------------------------------------\n",
            "Epoch [152/200], Batch [100/750], Loss: 0.6208\n",
            "Epoch [152/200], Batch [200/750], Loss: 0.4093\n",
            "Epoch [152/200], Batch [300/750], Loss: 0.5737\n",
            "Epoch [152/200], Batch [400/750], Loss: 0.4591\n",
            "Epoch [152/200], Batch [500/750], Loss: 0.4476\n",
            "Epoch [152/200], Batch [600/750], Loss: 0.7372\n",
            "Epoch [152/200], Batch [700/750], Loss: 0.6020\n",
            "Epoch [152/200] Total train Cost: 390.4974786043167\n",
            "---------------------------------------------\n",
            "Epoch [153/200], Batch [100/750], Loss: 0.6643\n",
            "Epoch [153/200], Batch [200/750], Loss: 0.6132\n",
            "Epoch [153/200], Batch [300/750], Loss: 0.5059\n",
            "Epoch [153/200], Batch [400/750], Loss: 0.5668\n",
            "Epoch [153/200], Batch [500/750], Loss: 0.4620\n",
            "Epoch [153/200], Batch [600/750], Loss: 0.4872\n",
            "Epoch [153/200], Batch [700/750], Loss: 0.4999\n",
            "Epoch [153/200] Total train Cost: 389.1035425364971\n",
            "---------------------------------------------\n",
            "Epoch [154/200], Batch [100/750], Loss: 0.4733\n",
            "Epoch [154/200], Batch [200/750], Loss: 0.6109\n",
            "Epoch [154/200], Batch [300/750], Loss: 0.5262\n",
            "Epoch [154/200], Batch [400/750], Loss: 0.4175\n",
            "Epoch [154/200], Batch [500/750], Loss: 0.5978\n",
            "Epoch [154/200], Batch [600/750], Loss: 0.4637\n",
            "Epoch [154/200], Batch [700/750], Loss: 0.5713\n",
            "Epoch [154/200] Total train Cost: 387.7290889918804\n",
            "---------------------------------------------\n",
            "Epoch [155/200], Batch [100/750], Loss: 0.5785\n",
            "Epoch [155/200], Batch [200/750], Loss: 0.3980\n",
            "Epoch [155/200], Batch [300/750], Loss: 0.5618\n",
            "Epoch [155/200], Batch [400/750], Loss: 0.6813\n",
            "Epoch [155/200], Batch [500/750], Loss: 0.7586\n",
            "Epoch [155/200], Batch [600/750], Loss: 0.6700\n",
            "Epoch [155/200], Batch [700/750], Loss: 0.7920\n",
            "Epoch [155/200] Total train Cost: 386.37419068813324\n",
            "---------------------------------------------\n",
            "Epoch [156/200], Batch [100/750], Loss: 0.4223\n",
            "Epoch [156/200], Batch [200/750], Loss: 0.5034\n",
            "Epoch [156/200], Batch [300/750], Loss: 0.5747\n",
            "Epoch [156/200], Batch [400/750], Loss: 0.5301\n",
            "Epoch [156/200], Batch [500/750], Loss: 0.5710\n",
            "Epoch [156/200], Batch [600/750], Loss: 0.4556\n",
            "Epoch [156/200], Batch [700/750], Loss: 0.3989\n",
            "Epoch [156/200] Total train Cost: 385.03892144560814\n",
            "---------------------------------------------\n",
            "Epoch [157/200], Batch [100/750], Loss: 0.5252\n",
            "Epoch [157/200], Batch [200/750], Loss: 0.5267\n",
            "Epoch [157/200], Batch [300/750], Loss: 0.5175\n",
            "Epoch [157/200], Batch [400/750], Loss: 0.5313\n",
            "Epoch [157/200], Batch [500/750], Loss: 0.6741\n",
            "Epoch [157/200], Batch [600/750], Loss: 0.5480\n",
            "Epoch [157/200], Batch [700/750], Loss: 0.4665\n",
            "Epoch [157/200] Total train Cost: 383.7222440838814\n",
            "---------------------------------------------\n",
            "Epoch [158/200], Batch [100/750], Loss: 0.4819\n",
            "Epoch [158/200], Batch [200/750], Loss: 0.4847\n",
            "Epoch [158/200], Batch [300/750], Loss: 0.3688\n",
            "Epoch [158/200], Batch [400/750], Loss: 0.6314\n",
            "Epoch [158/200], Batch [500/750], Loss: 0.5173\n",
            "Epoch [158/200], Batch [600/750], Loss: 0.5148\n",
            "Epoch [158/200], Batch [700/750], Loss: 0.5434\n",
            "Epoch [158/200] Total train Cost: 382.4238128513098\n",
            "---------------------------------------------\n",
            "Epoch [159/200], Batch [100/750], Loss: 0.5832\n",
            "Epoch [159/200], Batch [200/750], Loss: 0.5403\n",
            "Epoch [159/200], Batch [300/750], Loss: 0.3502\n",
            "Epoch [159/200], Batch [400/750], Loss: 0.4402\n",
            "Epoch [159/200], Batch [500/750], Loss: 0.5877\n",
            "Epoch [159/200], Batch [600/750], Loss: 0.5284\n",
            "Epoch [159/200], Batch [700/750], Loss: 0.6255\n",
            "Epoch [159/200] Total train Cost: 381.14375898241997\n",
            "---------------------------------------------\n",
            "Epoch [160/200], Batch [100/750], Loss: 0.5663\n",
            "Epoch [160/200], Batch [200/750], Loss: 0.4154\n",
            "Epoch [160/200], Batch [300/750], Loss: 0.3029\n",
            "Epoch [160/200], Batch [400/750], Loss: 0.6204\n",
            "Epoch [160/200], Batch [500/750], Loss: 0.4704\n",
            "Epoch [160/200], Batch [600/750], Loss: 0.3403\n",
            "Epoch [160/200], Batch [700/750], Loss: 0.4480\n",
            "Epoch [160/200] Total train Cost: 379.881671667099\n",
            "---------------------------------------------\n",
            "Epoch [161/200], Batch [100/750], Loss: 0.6570\n",
            "Epoch [161/200], Batch [200/750], Loss: 0.4037\n",
            "Epoch [161/200], Batch [300/750], Loss: 0.5759\n",
            "Epoch [161/200], Batch [400/750], Loss: 0.4477\n",
            "Epoch [161/200], Batch [500/750], Loss: 0.5854\n",
            "Epoch [161/200], Batch [600/750], Loss: 0.4973\n",
            "Epoch [161/200], Batch [700/750], Loss: 0.4551\n",
            "Epoch [161/200] Total train Cost: 378.6368498802185\n",
            "---------------------------------------------\n",
            "Epoch [162/200], Batch [100/750], Loss: 0.3913\n",
            "Epoch [162/200], Batch [200/750], Loss: 0.6501\n",
            "Epoch [162/200], Batch [300/750], Loss: 0.4702\n",
            "Epoch [162/200], Batch [400/750], Loss: 0.4804\n",
            "Epoch [162/200], Batch [500/750], Loss: 0.5536\n",
            "Epoch [162/200], Batch [600/750], Loss: 0.4126\n",
            "Epoch [162/200], Batch [700/750], Loss: 0.6044\n",
            "Epoch [162/200] Total train Cost: 377.4087190628052\n",
            "---------------------------------------------\n",
            "Epoch [163/200], Batch [100/750], Loss: 0.4559\n",
            "Epoch [163/200], Batch [200/750], Loss: 0.4784\n",
            "Epoch [163/200], Batch [300/750], Loss: 0.5038\n",
            "Epoch [163/200], Batch [400/750], Loss: 0.5383\n",
            "Epoch [163/200], Batch [500/750], Loss: 0.4200\n",
            "Epoch [163/200], Batch [600/750], Loss: 0.4422\n",
            "Epoch [163/200], Batch [700/750], Loss: 0.5304\n",
            "Epoch [163/200] Total train Cost: 376.195825278759\n",
            "---------------------------------------------\n",
            "Epoch [164/200], Batch [100/750], Loss: 0.4920\n",
            "Epoch [164/200], Batch [200/750], Loss: 0.5737\n",
            "Epoch [164/200], Batch [300/750], Loss: 0.4681\n",
            "Epoch [164/200], Batch [400/750], Loss: 0.4024\n",
            "Epoch [164/200], Batch [500/750], Loss: 0.4842\n",
            "Epoch [164/200], Batch [600/750], Loss: 0.5662\n",
            "Epoch [164/200], Batch [700/750], Loss: 0.6332\n",
            "Epoch [164/200] Total train Cost: 375.00124111771584\n",
            "---------------------------------------------\n",
            "Epoch [165/200], Batch [100/750], Loss: 0.4736\n",
            "Epoch [165/200], Batch [200/750], Loss: 0.3874\n",
            "Epoch [165/200], Batch [300/750], Loss: 0.5207\n",
            "Epoch [165/200], Batch [400/750], Loss: 0.5591\n",
            "Epoch [165/200], Batch [500/750], Loss: 0.6220\n",
            "Epoch [165/200], Batch [600/750], Loss: 0.5034\n",
            "Epoch [165/200], Batch [700/750], Loss: 0.6140\n",
            "Epoch [165/200] Total train Cost: 373.8217318356037\n",
            "---------------------------------------------\n",
            "Epoch [166/200], Batch [100/750], Loss: 0.5320\n",
            "Epoch [166/200], Batch [200/750], Loss: 0.5306\n",
            "Epoch [166/200], Batch [300/750], Loss: 0.3609\n",
            "Epoch [166/200], Batch [400/750], Loss: 0.4601\n",
            "Epoch [166/200], Batch [500/750], Loss: 0.3927\n",
            "Epoch [166/200], Batch [600/750], Loss: 0.5095\n",
            "Epoch [166/200], Batch [700/750], Loss: 0.3879\n",
            "Epoch [166/200] Total train Cost: 372.6584497988224\n",
            "---------------------------------------------\n",
            "Epoch [167/200], Batch [100/750], Loss: 0.3502\n",
            "Epoch [167/200], Batch [200/750], Loss: 0.5523\n",
            "Epoch [167/200], Batch [300/750], Loss: 0.4457\n",
            "Epoch [167/200], Batch [400/750], Loss: 0.3254\n",
            "Epoch [167/200], Batch [500/750], Loss: 0.6288\n",
            "Epoch [167/200], Batch [600/750], Loss: 0.3712\n",
            "Epoch [167/200], Batch [700/750], Loss: 0.2691\n",
            "Epoch [167/200] Total train Cost: 371.50869293510914\n",
            "---------------------------------------------\n",
            "Epoch [168/200], Batch [100/750], Loss: 0.4710\n",
            "Epoch [168/200], Batch [200/750], Loss: 0.5175\n",
            "Epoch [168/200], Batch [300/750], Loss: 0.4860\n",
            "Epoch [168/200], Batch [400/750], Loss: 0.5876\n",
            "Epoch [168/200], Batch [500/750], Loss: 0.6104\n",
            "Epoch [168/200], Batch [600/750], Loss: 0.3894\n",
            "Epoch [168/200], Batch [700/750], Loss: 0.5949\n",
            "Epoch [168/200] Total train Cost: 370.3753490149975\n",
            "---------------------------------------------\n",
            "Epoch [169/200], Batch [100/750], Loss: 0.4705\n",
            "Epoch [169/200], Batch [200/750], Loss: 0.4857\n",
            "Epoch [169/200], Batch [300/750], Loss: 0.4983\n",
            "Epoch [169/200], Batch [400/750], Loss: 0.4078\n",
            "Epoch [169/200], Batch [500/750], Loss: 0.5528\n",
            "Epoch [169/200], Batch [600/750], Loss: 0.4180\n",
            "Epoch [169/200], Batch [700/750], Loss: 0.6666\n",
            "Epoch [169/200] Total train Cost: 369.25700882077217\n",
            "---------------------------------------------\n",
            "Epoch [170/200], Batch [100/750], Loss: 0.4688\n",
            "Epoch [170/200], Batch [200/750], Loss: 0.5979\n",
            "Epoch [170/200], Batch [300/750], Loss: 0.4764\n",
            "Epoch [170/200], Batch [400/750], Loss: 0.6835\n",
            "Epoch [170/200], Batch [500/750], Loss: 0.4110\n",
            "Epoch [170/200], Batch [600/750], Loss: 0.6659\n",
            "Epoch [170/200], Batch [700/750], Loss: 0.4504\n",
            "Epoch [170/200] Total train Cost: 368.15295642614365\n",
            "---------------------------------------------\n",
            "Epoch [171/200], Batch [100/750], Loss: 0.4067\n",
            "Epoch [171/200], Batch [200/750], Loss: 0.6853\n",
            "Epoch [171/200], Batch [300/750], Loss: 0.4427\n",
            "Epoch [171/200], Batch [400/750], Loss: 0.5196\n",
            "Epoch [171/200], Batch [500/750], Loss: 0.3928\n",
            "Epoch [171/200], Batch [600/750], Loss: 0.4389\n",
            "Epoch [171/200], Batch [700/750], Loss: 0.4816\n",
            "Epoch [171/200] Total train Cost: 367.06163519620895\n",
            "---------------------------------------------\n",
            "Epoch [172/200], Batch [100/750], Loss: 0.4862\n",
            "Epoch [172/200], Batch [200/750], Loss: 0.4633\n",
            "Epoch [172/200], Batch [300/750], Loss: 0.4068\n",
            "Epoch [172/200], Batch [400/750], Loss: 0.4331\n",
            "Epoch [172/200], Batch [500/750], Loss: 0.4125\n",
            "Epoch [172/200], Batch [600/750], Loss: 0.3679\n",
            "Epoch [172/200], Batch [700/750], Loss: 0.5816\n",
            "Epoch [172/200] Total train Cost: 365.98629903793335\n",
            "---------------------------------------------\n",
            "Epoch [173/200], Batch [100/750], Loss: 0.4879\n",
            "Epoch [173/200], Batch [200/750], Loss: 0.3203\n",
            "Epoch [173/200], Batch [300/750], Loss: 0.3738\n",
            "Epoch [173/200], Batch [400/750], Loss: 0.5109\n",
            "Epoch [173/200], Batch [500/750], Loss: 0.4651\n",
            "Epoch [173/200], Batch [600/750], Loss: 0.4374\n",
            "Epoch [173/200], Batch [700/750], Loss: 0.4616\n",
            "Epoch [173/200] Total train Cost: 364.92258858680725\n",
            "---------------------------------------------\n",
            "Epoch [174/200], Batch [100/750], Loss: 0.5327\n",
            "Epoch [174/200], Batch [200/750], Loss: 0.4699\n",
            "Epoch [174/200], Batch [300/750], Loss: 0.4927\n",
            "Epoch [174/200], Batch [400/750], Loss: 0.6032\n",
            "Epoch [174/200], Batch [500/750], Loss: 0.4267\n",
            "Epoch [174/200], Batch [600/750], Loss: 0.5391\n",
            "Epoch [174/200], Batch [700/750], Loss: 0.3959\n",
            "Epoch [174/200] Total train Cost: 363.8733755350113\n",
            "---------------------------------------------\n",
            "Epoch [175/200], Batch [100/750], Loss: 0.4282\n",
            "Epoch [175/200], Batch [200/750], Loss: 0.3854\n",
            "Epoch [175/200], Batch [300/750], Loss: 0.5411\n",
            "Epoch [175/200], Batch [400/750], Loss: 0.4614\n",
            "Epoch [175/200], Batch [500/750], Loss: 0.6927\n",
            "Epoch [175/200], Batch [600/750], Loss: 0.2630\n",
            "Epoch [175/200], Batch [700/750], Loss: 0.5560\n",
            "Epoch [175/200] Total train Cost: 362.83696699142456\n",
            "---------------------------------------------\n",
            "Epoch [176/200], Batch [100/750], Loss: 0.3850\n",
            "Epoch [176/200], Batch [200/750], Loss: 0.4398\n",
            "Epoch [176/200], Batch [300/750], Loss: 0.5473\n",
            "Epoch [176/200], Batch [400/750], Loss: 0.4903\n",
            "Epoch [176/200], Batch [500/750], Loss: 0.5676\n",
            "Epoch [176/200], Batch [600/750], Loss: 0.3384\n",
            "Epoch [176/200], Batch [700/750], Loss: 0.4284\n",
            "Epoch [176/200] Total train Cost: 361.8129369020462\n",
            "---------------------------------------------\n",
            "Epoch [177/200], Batch [100/750], Loss: 0.3389\n",
            "Epoch [177/200], Batch [200/750], Loss: 0.3907\n",
            "Epoch [177/200], Batch [300/750], Loss: 0.4544\n",
            "Epoch [177/200], Batch [400/750], Loss: 0.3963\n",
            "Epoch [177/200], Batch [500/750], Loss: 0.4129\n",
            "Epoch [177/200], Batch [600/750], Loss: 0.6480\n",
            "Epoch [177/200], Batch [700/750], Loss: 0.5069\n",
            "Epoch [177/200] Total train Cost: 360.80202716588974\n",
            "---------------------------------------------\n",
            "Epoch [178/200], Batch [100/750], Loss: 0.7507\n",
            "Epoch [178/200], Batch [200/750], Loss: 0.4253\n",
            "Epoch [178/200], Batch [300/750], Loss: 0.4838\n",
            "Epoch [178/200], Batch [400/750], Loss: 0.5352\n",
            "Epoch [178/200], Batch [500/750], Loss: 0.4539\n",
            "Epoch [178/200], Batch [600/750], Loss: 0.5144\n",
            "Epoch [178/200], Batch [700/750], Loss: 0.6328\n",
            "Epoch [178/200] Total train Cost: 359.8043191432953\n",
            "---------------------------------------------\n",
            "Epoch [179/200], Batch [100/750], Loss: 0.5800\n",
            "Epoch [179/200], Batch [200/750], Loss: 0.4850\n",
            "Epoch [179/200], Batch [300/750], Loss: 0.4583\n",
            "Epoch [179/200], Batch [400/750], Loss: 0.2953\n",
            "Epoch [179/200], Batch [500/750], Loss: 0.3785\n",
            "Epoch [179/200], Batch [600/750], Loss: 0.3719\n",
            "Epoch [179/200], Batch [700/750], Loss: 0.5384\n",
            "Epoch [179/200] Total train Cost: 358.81646896898746\n",
            "---------------------------------------------\n",
            "Epoch [180/200], Batch [100/750], Loss: 0.2828\n",
            "Epoch [180/200], Batch [200/750], Loss: 0.5065\n",
            "Epoch [180/200], Batch [300/750], Loss: 0.5032\n",
            "Epoch [180/200], Batch [400/750], Loss: 0.4453\n",
            "Epoch [180/200], Batch [500/750], Loss: 0.4884\n",
            "Epoch [180/200], Batch [600/750], Loss: 0.3847\n",
            "Epoch [180/200], Batch [700/750], Loss: 0.4922\n",
            "Epoch [180/200] Total train Cost: 357.8430624306202\n",
            "---------------------------------------------\n",
            "Epoch [181/200], Batch [100/750], Loss: 0.4619\n",
            "Epoch [181/200], Batch [200/750], Loss: 0.4346\n",
            "Epoch [181/200], Batch [300/750], Loss: 0.3372\n",
            "Epoch [181/200], Batch [400/750], Loss: 0.4555\n",
            "Epoch [181/200], Batch [500/750], Loss: 0.3909\n",
            "Epoch [181/200], Batch [600/750], Loss: 0.3896\n",
            "Epoch [181/200], Batch [700/750], Loss: 0.3824\n",
            "Epoch [181/200] Total train Cost: 356.8800205886364\n",
            "---------------------------------------------\n",
            "Epoch [182/200], Batch [100/750], Loss: 0.4394\n",
            "Epoch [182/200], Batch [200/750], Loss: 0.5467\n",
            "Epoch [182/200], Batch [300/750], Loss: 0.4645\n",
            "Epoch [182/200], Batch [400/750], Loss: 0.4850\n",
            "Epoch [182/200], Batch [500/750], Loss: 0.5011\n",
            "Epoch [182/200], Batch [600/750], Loss: 0.4672\n",
            "Epoch [182/200], Batch [700/750], Loss: 0.3998\n",
            "Epoch [182/200] Total train Cost: 355.92817471921444\n",
            "---------------------------------------------\n",
            "Epoch [183/200], Batch [100/750], Loss: 0.5469\n",
            "Epoch [183/200], Batch [200/750], Loss: 0.4655\n",
            "Epoch [183/200], Batch [300/750], Loss: 0.5955\n",
            "Epoch [183/200], Batch [400/750], Loss: 0.3696\n",
            "Epoch [183/200], Batch [500/750], Loss: 0.4705\n",
            "Epoch [183/200], Batch [600/750], Loss: 0.4599\n",
            "Epoch [183/200], Batch [700/750], Loss: 0.3667\n",
            "Epoch [183/200] Total train Cost: 354.9882536828518\n",
            "---------------------------------------------\n",
            "Epoch [184/200], Batch [100/750], Loss: 0.7328\n",
            "Epoch [184/200], Batch [200/750], Loss: 0.4428\n",
            "Epoch [184/200], Batch [300/750], Loss: 0.5267\n",
            "Epoch [184/200], Batch [400/750], Loss: 0.4975\n",
            "Epoch [184/200], Batch [500/750], Loss: 0.4846\n",
            "Epoch [184/200], Batch [600/750], Loss: 0.4790\n",
            "Epoch [184/200], Batch [700/750], Loss: 0.3968\n",
            "Epoch [184/200] Total train Cost: 354.0600543022156\n",
            "---------------------------------------------\n",
            "Epoch [185/200], Batch [100/750], Loss: 0.5245\n",
            "Epoch [185/200], Batch [200/750], Loss: 0.4539\n",
            "Epoch [185/200], Batch [300/750], Loss: 0.4453\n",
            "Epoch [185/200], Batch [400/750], Loss: 0.5820\n",
            "Epoch [185/200], Batch [500/750], Loss: 0.4588\n",
            "Epoch [185/200], Batch [600/750], Loss: 0.5553\n",
            "Epoch [185/200], Batch [700/750], Loss: 0.5442\n",
            "Epoch [185/200] Total train Cost: 353.14210042357445\n",
            "---------------------------------------------\n",
            "Epoch [186/200], Batch [100/750], Loss: 0.3629\n",
            "Epoch [186/200], Batch [200/750], Loss: 0.4466\n",
            "Epoch [186/200], Batch [300/750], Loss: 0.4761\n",
            "Epoch [186/200], Batch [400/750], Loss: 0.4027\n",
            "Epoch [186/200], Batch [500/750], Loss: 0.3153\n",
            "Epoch [186/200], Batch [600/750], Loss: 0.5463\n",
            "Epoch [186/200], Batch [700/750], Loss: 0.4509\n",
            "Epoch [186/200] Total train Cost: 352.2344863116741\n",
            "---------------------------------------------\n",
            "Epoch [187/200], Batch [100/750], Loss: 0.6292\n",
            "Epoch [187/200], Batch [200/750], Loss: 0.5137\n",
            "Epoch [187/200], Batch [300/750], Loss: 0.6144\n",
            "Epoch [187/200], Batch [400/750], Loss: 0.6847\n",
            "Epoch [187/200], Batch [500/750], Loss: 0.3840\n",
            "Epoch [187/200], Batch [600/750], Loss: 0.4289\n",
            "Epoch [187/200], Batch [700/750], Loss: 0.3330\n",
            "Epoch [187/200] Total train Cost: 351.3371100127697\n",
            "---------------------------------------------\n",
            "Epoch [188/200], Batch [100/750], Loss: 0.4424\n",
            "Epoch [188/200], Batch [200/750], Loss: 0.3496\n",
            "Epoch [188/200], Batch [300/750], Loss: 0.4224\n",
            "Epoch [188/200], Batch [400/750], Loss: 0.3976\n",
            "Epoch [188/200], Batch [500/750], Loss: 0.7706\n",
            "Epoch [188/200], Batch [600/750], Loss: 0.5859\n",
            "Epoch [188/200], Batch [700/750], Loss: 0.2535\n",
            "Epoch [188/200] Total train Cost: 350.4499945193529\n",
            "---------------------------------------------\n",
            "Epoch [189/200], Batch [100/750], Loss: 0.4143\n",
            "Epoch [189/200], Batch [200/750], Loss: 0.6002\n",
            "Epoch [189/200], Batch [300/750], Loss: 0.4333\n",
            "Epoch [189/200], Batch [400/750], Loss: 0.5707\n",
            "Epoch [189/200], Batch [500/750], Loss: 0.3628\n",
            "Epoch [189/200], Batch [600/750], Loss: 0.4697\n",
            "Epoch [189/200], Batch [700/750], Loss: 0.5376\n",
            "Epoch [189/200] Total train Cost: 349.5746519714594\n",
            "---------------------------------------------\n",
            "Epoch [190/200], Batch [100/750], Loss: 0.4900\n",
            "Epoch [190/200], Batch [200/750], Loss: 0.4114\n",
            "Epoch [190/200], Batch [300/750], Loss: 0.4220\n",
            "Epoch [190/200], Batch [400/750], Loss: 0.3453\n",
            "Epoch [190/200], Batch [500/750], Loss: 0.5931\n",
            "Epoch [190/200], Batch [600/750], Loss: 0.4853\n",
            "Epoch [190/200], Batch [700/750], Loss: 0.4948\n",
            "Epoch [190/200] Total train Cost: 348.7080762386322\n",
            "---------------------------------------------\n",
            "Epoch [191/200], Batch [100/750], Loss: 0.4349\n",
            "Epoch [191/200], Batch [200/750], Loss: 0.3688\n",
            "Epoch [191/200], Batch [300/750], Loss: 0.5583\n",
            "Epoch [191/200], Batch [400/750], Loss: 0.3804\n",
            "Epoch [191/200], Batch [500/750], Loss: 0.5368\n",
            "Epoch [191/200], Batch [600/750], Loss: 0.6164\n",
            "Epoch [191/200], Batch [700/750], Loss: 0.4051\n",
            "Epoch [191/200] Total train Cost: 347.851999104023\n",
            "---------------------------------------------\n",
            "Epoch [192/200], Batch [100/750], Loss: 0.5088\n",
            "Epoch [192/200], Batch [200/750], Loss: 0.4289\n",
            "Epoch [192/200], Batch [300/750], Loss: 0.5497\n",
            "Epoch [192/200], Batch [400/750], Loss: 0.3465\n",
            "Epoch [192/200], Batch [500/750], Loss: 0.4551\n",
            "Epoch [192/200], Batch [600/750], Loss: 0.4582\n",
            "Epoch [192/200], Batch [700/750], Loss: 0.5081\n",
            "Epoch [192/200] Total train Cost: 347.0053197145462\n",
            "---------------------------------------------\n",
            "Epoch [193/200], Batch [100/750], Loss: 0.4329\n",
            "Epoch [193/200], Batch [200/750], Loss: 0.4208\n",
            "Epoch [193/200], Batch [300/750], Loss: 0.6079\n",
            "Epoch [193/200], Batch [400/750], Loss: 0.4674\n",
            "Epoch [193/200], Batch [500/750], Loss: 0.4192\n",
            "Epoch [193/200], Batch [600/750], Loss: 0.5634\n",
            "Epoch [193/200], Batch [700/750], Loss: 0.5122\n",
            "Epoch [193/200] Total train Cost: 346.16703425347805\n",
            "---------------------------------------------\n",
            "Epoch [194/200], Batch [100/750], Loss: 0.4265\n",
            "Epoch [194/200], Batch [200/750], Loss: 0.4972\n",
            "Epoch [194/200], Batch [300/750], Loss: 0.5385\n",
            "Epoch [194/200], Batch [400/750], Loss: 0.5052\n",
            "Epoch [194/200], Batch [500/750], Loss: 0.4921\n",
            "Epoch [194/200], Batch [600/750], Loss: 0.4964\n",
            "Epoch [194/200], Batch [700/750], Loss: 0.5091\n",
            "Epoch [194/200] Total train Cost: 345.33872705698013\n",
            "---------------------------------------------\n",
            "Epoch [195/200], Batch [100/750], Loss: 0.6463\n",
            "Epoch [195/200], Batch [200/750], Loss: 0.5015\n",
            "Epoch [195/200], Batch [300/750], Loss: 0.2944\n",
            "Epoch [195/200], Batch [400/750], Loss: 0.4878\n",
            "Epoch [195/200], Batch [500/750], Loss: 0.4808\n",
            "Epoch [195/200], Batch [600/750], Loss: 0.6047\n",
            "Epoch [195/200], Batch [700/750], Loss: 0.4644\n",
            "Epoch [195/200] Total train Cost: 344.518862336874\n",
            "---------------------------------------------\n",
            "Epoch [196/200], Batch [100/750], Loss: 0.3974\n",
            "Epoch [196/200], Batch [200/750], Loss: 0.5467\n",
            "Epoch [196/200], Batch [300/750], Loss: 0.5633\n",
            "Epoch [196/200], Batch [400/750], Loss: 0.4464\n",
            "Epoch [196/200], Batch [500/750], Loss: 0.5191\n",
            "Epoch [196/200], Batch [600/750], Loss: 0.3771\n",
            "Epoch [196/200], Batch [700/750], Loss: 0.4249\n",
            "Epoch [196/200] Total train Cost: 343.7098543792963\n",
            "---------------------------------------------\n",
            "Epoch [197/200], Batch [100/750], Loss: 0.5333\n",
            "Epoch [197/200], Batch [200/750], Loss: 0.5149\n",
            "Epoch [197/200], Batch [300/750], Loss: 0.4898\n",
            "Epoch [197/200], Batch [400/750], Loss: 0.2866\n",
            "Epoch [197/200], Batch [500/750], Loss: 0.4789\n",
            "Epoch [197/200], Batch [600/750], Loss: 0.4704\n",
            "Epoch [197/200], Batch [700/750], Loss: 0.4607\n",
            "Epoch [197/200] Total train Cost: 342.9092469960451\n",
            "---------------------------------------------\n",
            "Epoch [198/200], Batch [100/750], Loss: 0.4277\n",
            "Epoch [198/200], Batch [200/750], Loss: 0.4988\n",
            "Epoch [198/200], Batch [300/750], Loss: 0.3139\n",
            "Epoch [198/200], Batch [400/750], Loss: 0.5421\n",
            "Epoch [198/200], Batch [500/750], Loss: 0.4507\n",
            "Epoch [198/200], Batch [600/750], Loss: 0.4442\n",
            "Epoch [198/200], Batch [700/750], Loss: 0.5879\n",
            "Epoch [198/200] Total train Cost: 342.1168240606785\n",
            "---------------------------------------------\n",
            "Epoch [199/200], Batch [100/750], Loss: 0.5391\n",
            "Epoch [199/200], Batch [200/750], Loss: 0.3653\n",
            "Epoch [199/200], Batch [300/750], Loss: 0.3918\n",
            "Epoch [199/200], Batch [400/750], Loss: 0.4309\n",
            "Epoch [199/200], Batch [500/750], Loss: 0.6955\n",
            "Epoch [199/200], Batch [600/750], Loss: 0.4115\n",
            "Epoch [199/200], Batch [700/750], Loss: 0.4570\n",
            "Epoch [199/200] Total train Cost: 341.3325727880001\n",
            "---------------------------------------------\n",
            "Epoch [200/200], Batch [100/750], Loss: 0.3282\n",
            "Epoch [200/200], Batch [200/750], Loss: 0.5013\n",
            "Epoch [200/200], Batch [300/750], Loss: 0.5291\n",
            "Epoch [200/200], Batch [400/750], Loss: 0.3537\n",
            "Epoch [200/200], Batch [500/750], Loss: 0.4186\n",
            "Epoch [200/200], Batch [600/750], Loss: 0.4848\n",
            "Epoch [200/200], Batch [700/750], Loss: 0.3208\n",
            "Epoch [200/200] Total train Cost: 340.55699248611927\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.0001\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = MNIST_Neural_Network(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_batches = len(train_loader)\n",
        "\n",
        "batch_loss_list = []\n",
        "epoch_loss_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    current_loss = 0.\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_loss_list.append(loss.item())\n",
        "        current_loss += loss.item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{n_total_batches}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    epoch_loss_list.append(current_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] Total train Cost: {current_loss}')\n",
        "    print(\"-\" * 45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "TIh6fktZ2ONX",
        "outputId": "40263e43-bef3-4baf-a69a-d3c8e438e7e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Epoch Loss')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "ax[0].plot(range(len(batch_loss_list)), (batch_loss_list), label='Batch Loss')\n",
        "ax[0].set_xlabel('Iterations')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_title('Batch Loss')\n",
        "\n",
        "ax[1].plot(range(len(epoch_loss_list)), (epoch_loss_list), label='Epoch Loss')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_title('Epoch Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTNehhODTf2L"
      },
      "source": [
        "learning_rate = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWD1zCAoOsLz",
        "outputId": "06f86264-800d-46a9-a9cc-cda2d6b3c74c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/200], Batch [100/750], Loss: 2.0714\n",
            "Epoch [1/200], Batch [200/750], Loss: 1.7356\n",
            "Epoch [1/200], Batch [300/750], Loss: 1.4463\n",
            "Epoch [1/200], Batch [400/750], Loss: 1.1933\n",
            "Epoch [1/200], Batch [500/750], Loss: 0.7185\n",
            "Epoch [1/200], Batch [600/750], Loss: 0.7918\n",
            "Epoch [1/200], Batch [700/750], Loss: 0.7101\n",
            "Epoch [1/200] Total train Cost: 976.1808027029037\n",
            "---------------------------------------------\n",
            "Epoch [2/200], Batch [100/750], Loss: 0.4790\n",
            "Epoch [2/200], Batch [200/750], Loss: 0.4690\n",
            "Epoch [2/200], Batch [300/750], Loss: 0.5938\n",
            "Epoch [2/200], Batch [400/750], Loss: 0.5688\n",
            "Epoch [2/200], Batch [500/750], Loss: 0.5166\n",
            "Epoch [2/200], Batch [600/750], Loss: 0.3903\n",
            "Epoch [2/200], Batch [700/750], Loss: 0.6229\n",
            "Epoch [2/200] Total train Cost: 402.01770183444023\n",
            "---------------------------------------------\n",
            "Epoch [3/200], Batch [100/750], Loss: 0.2907\n",
            "Epoch [3/200], Batch [200/750], Loss: 0.4174\n",
            "Epoch [3/200], Batch [300/750], Loss: 0.3955\n",
            "Epoch [3/200], Batch [400/750], Loss: 0.3151\n",
            "Epoch [3/200], Batch [500/750], Loss: 0.3567\n",
            "Epoch [3/200], Batch [600/750], Loss: 0.4506\n",
            "Epoch [3/200], Batch [700/750], Loss: 0.2772\n",
            "Epoch [3/200] Total train Cost: 312.37395891547203\n",
            "---------------------------------------------\n",
            "Epoch [4/200], Batch [100/750], Loss: 0.3220\n",
            "Epoch [4/200], Batch [200/750], Loss: 0.2906\n",
            "Epoch [4/200], Batch [300/750], Loss: 0.4201\n",
            "Epoch [4/200], Batch [400/750], Loss: 0.3574\n",
            "Epoch [4/200], Batch [500/750], Loss: 0.5753\n",
            "Epoch [4/200], Batch [600/750], Loss: 0.4006\n",
            "Epoch [4/200], Batch [700/750], Loss: 0.2302\n",
            "Epoch [4/200] Total train Cost: 276.71124117076397\n",
            "---------------------------------------------\n",
            "Epoch [5/200], Batch [100/750], Loss: 0.3122\n",
            "Epoch [5/200], Batch [200/750], Loss: 0.3198\n",
            "Epoch [5/200], Batch [300/750], Loss: 0.2539\n",
            "Epoch [5/200], Batch [400/750], Loss: 0.5009\n",
            "Epoch [5/200], Batch [500/750], Loss: 0.3763\n",
            "Epoch [5/200], Batch [600/750], Loss: 0.2390\n",
            "Epoch [5/200], Batch [700/750], Loss: 0.2634\n",
            "Epoch [5/200] Total train Cost: 255.9099771901965\n",
            "---------------------------------------------\n",
            "Epoch [6/200], Batch [100/750], Loss: 0.1833\n",
            "Epoch [6/200], Batch [200/750], Loss: 0.2627\n",
            "Epoch [6/200], Batch [300/750], Loss: 0.2377\n",
            "Epoch [6/200], Batch [400/750], Loss: 0.3570\n",
            "Epoch [6/200], Batch [500/750], Loss: 0.1960\n",
            "Epoch [6/200], Batch [600/750], Loss: 0.2733\n",
            "Epoch [6/200], Batch [700/750], Loss: 0.2727\n",
            "Epoch [6/200] Total train Cost: 241.07554452121258\n",
            "---------------------------------------------\n",
            "Epoch [7/200], Batch [100/750], Loss: 0.3543\n",
            "Epoch [7/200], Batch [200/750], Loss: 0.3623\n",
            "Epoch [7/200], Batch [300/750], Loss: 0.3664\n",
            "Epoch [7/200], Batch [400/750], Loss: 0.2255\n",
            "Epoch [7/200], Batch [500/750], Loss: 0.3915\n",
            "Epoch [7/200], Batch [600/750], Loss: 0.2708\n",
            "Epoch [7/200], Batch [700/750], Loss: 0.2088\n",
            "Epoch [7/200] Total train Cost: 229.55283672362566\n",
            "---------------------------------------------\n",
            "Epoch [8/200], Batch [100/750], Loss: 0.2730\n",
            "Epoch [8/200], Batch [200/750], Loss: 0.3902\n",
            "Epoch [8/200], Batch [300/750], Loss: 0.2091\n",
            "Epoch [8/200], Batch [400/750], Loss: 0.4300\n",
            "Epoch [8/200], Batch [500/750], Loss: 0.2180\n",
            "Epoch [8/200], Batch [600/750], Loss: 0.3034\n",
            "Epoch [8/200], Batch [700/750], Loss: 0.4550\n",
            "Epoch [8/200] Total train Cost: 219.76345118135214\n",
            "---------------------------------------------\n",
            "Epoch [9/200], Batch [100/750], Loss: 0.2630\n",
            "Epoch [9/200], Batch [200/750], Loss: 0.5230\n",
            "Epoch [9/200], Batch [300/750], Loss: 0.3868\n",
            "Epoch [9/200], Batch [400/750], Loss: 0.1040\n",
            "Epoch [9/200], Batch [500/750], Loss: 0.4075\n",
            "Epoch [9/200], Batch [600/750], Loss: 0.3999\n",
            "Epoch [9/200], Batch [700/750], Loss: 0.4006\n",
            "Epoch [9/200] Total train Cost: 211.36860490590334\n",
            "---------------------------------------------\n",
            "Epoch [10/200], Batch [100/750], Loss: 0.1584\n",
            "Epoch [10/200], Batch [200/750], Loss: 0.1917\n",
            "Epoch [10/200], Batch [300/750], Loss: 0.3825\n",
            "Epoch [10/200], Batch [400/750], Loss: 0.3094\n",
            "Epoch [10/200], Batch [500/750], Loss: 0.3148\n",
            "Epoch [10/200], Batch [600/750], Loss: 0.2468\n",
            "Epoch [10/200], Batch [700/750], Loss: 0.3981\n",
            "Epoch [10/200] Total train Cost: 203.60719468444586\n",
            "---------------------------------------------\n",
            "Epoch [11/200], Batch [100/750], Loss: 0.1575\n",
            "Epoch [11/200], Batch [200/750], Loss: 0.3513\n",
            "Epoch [11/200], Batch [300/750], Loss: 0.1613\n",
            "Epoch [11/200], Batch [400/750], Loss: 0.2315\n",
            "Epoch [11/200], Batch [500/750], Loss: 0.2183\n",
            "Epoch [11/200], Batch [600/750], Loss: 0.5704\n",
            "Epoch [11/200], Batch [700/750], Loss: 0.2533\n",
            "Epoch [11/200] Total train Cost: 196.54554353654385\n",
            "---------------------------------------------\n",
            "Epoch [12/200], Batch [100/750], Loss: 0.1743\n",
            "Epoch [12/200], Batch [200/750], Loss: 0.4884\n",
            "Epoch [12/200], Batch [300/750], Loss: 0.3523\n",
            "Epoch [12/200], Batch [400/750], Loss: 0.3385\n",
            "Epoch [12/200], Batch [500/750], Loss: 0.3749\n",
            "Epoch [12/200], Batch [600/750], Loss: 0.2225\n",
            "Epoch [12/200], Batch [700/750], Loss: 0.2643\n",
            "Epoch [12/200] Total train Cost: 189.8708026483655\n",
            "---------------------------------------------\n",
            "Epoch [13/200], Batch [100/750], Loss: 0.1830\n",
            "Epoch [13/200], Batch [200/750], Loss: 0.2252\n",
            "Epoch [13/200], Batch [300/750], Loss: 0.2797\n",
            "Epoch [13/200], Batch [400/750], Loss: 0.1682\n",
            "Epoch [13/200], Batch [500/750], Loss: 0.2352\n",
            "Epoch [13/200], Batch [600/750], Loss: 0.3953\n",
            "Epoch [13/200], Batch [700/750], Loss: 0.1760\n",
            "Epoch [13/200] Total train Cost: 183.67214623838663\n",
            "---------------------------------------------\n",
            "Epoch [14/200], Batch [100/750], Loss: 0.3310\n",
            "Epoch [14/200], Batch [200/750], Loss: 0.1145\n",
            "Epoch [14/200], Batch [300/750], Loss: 0.2955\n",
            "Epoch [14/200], Batch [400/750], Loss: 0.1582\n",
            "Epoch [14/200], Batch [500/750], Loss: 0.1865\n",
            "Epoch [14/200], Batch [600/750], Loss: 0.2667\n",
            "Epoch [14/200], Batch [700/750], Loss: 0.2938\n",
            "Epoch [14/200] Total train Cost: 177.90437063202262\n",
            "---------------------------------------------\n",
            "Epoch [15/200], Batch [100/750], Loss: 0.1765\n",
            "Epoch [15/200], Batch [200/750], Loss: 0.2155\n",
            "Epoch [15/200], Batch [300/750], Loss: 0.1229\n",
            "Epoch [15/200], Batch [400/750], Loss: 0.2538\n",
            "Epoch [15/200], Batch [500/750], Loss: 0.1898\n",
            "Epoch [15/200], Batch [600/750], Loss: 0.2966\n",
            "Epoch [15/200], Batch [700/750], Loss: 0.3375\n",
            "Epoch [15/200] Total train Cost: 172.22421498969197\n",
            "---------------------------------------------\n",
            "Epoch [16/200], Batch [100/750], Loss: 0.2357\n",
            "Epoch [16/200], Batch [200/750], Loss: 0.1539\n",
            "Epoch [16/200], Batch [300/750], Loss: 0.2090\n",
            "Epoch [16/200], Batch [400/750], Loss: 0.1169\n",
            "Epoch [16/200], Batch [500/750], Loss: 0.2138\n",
            "Epoch [16/200], Batch [600/750], Loss: 0.3027\n",
            "Epoch [16/200], Batch [700/750], Loss: 0.3071\n",
            "Epoch [16/200] Total train Cost: 167.22025363892317\n",
            "---------------------------------------------\n",
            "Epoch [17/200], Batch [100/750], Loss: 0.2535\n",
            "Epoch [17/200], Batch [200/750], Loss: 0.1642\n",
            "Epoch [17/200], Batch [300/750], Loss: 0.1622\n",
            "Epoch [17/200], Batch [400/750], Loss: 0.1992\n",
            "Epoch [17/200], Batch [500/750], Loss: 0.2395\n",
            "Epoch [17/200], Batch [600/750], Loss: 0.1448\n",
            "Epoch [17/200], Batch [700/750], Loss: 0.2716\n",
            "Epoch [17/200] Total train Cost: 162.12572536617517\n",
            "---------------------------------------------\n",
            "Epoch [18/200], Batch [100/750], Loss: 0.2354\n",
            "Epoch [18/200], Batch [200/750], Loss: 0.0882\n",
            "Epoch [18/200], Batch [300/750], Loss: 0.2249\n",
            "Epoch [18/200], Batch [400/750], Loss: 0.0992\n",
            "Epoch [18/200], Batch [500/750], Loss: 0.4372\n",
            "Epoch [18/200], Batch [600/750], Loss: 0.1256\n",
            "Epoch [18/200], Batch [700/750], Loss: 0.1133\n",
            "Epoch [18/200] Total train Cost: 157.42952761799097\n",
            "---------------------------------------------\n",
            "Epoch [19/200], Batch [100/750], Loss: 0.1655\n",
            "Epoch [19/200], Batch [200/750], Loss: 0.1459\n",
            "Epoch [19/200], Batch [300/750], Loss: 0.1449\n",
            "Epoch [19/200], Batch [400/750], Loss: 0.2764\n",
            "Epoch [19/200], Batch [500/750], Loss: 0.2271\n",
            "Epoch [19/200], Batch [600/750], Loss: 0.2160\n",
            "Epoch [19/200], Batch [700/750], Loss: 0.1831\n",
            "Epoch [19/200] Total train Cost: 152.98963503167033\n",
            "---------------------------------------------\n",
            "Epoch [20/200], Batch [100/750], Loss: 0.2126\n",
            "Epoch [20/200], Batch [200/750], Loss: 0.0794\n",
            "Epoch [20/200], Batch [300/750], Loss: 0.1154\n",
            "Epoch [20/200], Batch [400/750], Loss: 0.2637\n",
            "Epoch [20/200], Batch [500/750], Loss: 0.3401\n",
            "Epoch [20/200], Batch [600/750], Loss: 0.1815\n",
            "Epoch [20/200], Batch [700/750], Loss: 0.0811\n",
            "Epoch [20/200] Total train Cost: 148.6886426769197\n",
            "---------------------------------------------\n",
            "Epoch [21/200], Batch [100/750], Loss: 0.0660\n",
            "Epoch [21/200], Batch [200/750], Loss: 0.1288\n",
            "Epoch [21/200], Batch [300/750], Loss: 0.1642\n",
            "Epoch [21/200], Batch [400/750], Loss: 0.2129\n",
            "Epoch [21/200], Batch [500/750], Loss: 0.2032\n",
            "Epoch [21/200], Batch [600/750], Loss: 0.1776\n",
            "Epoch [21/200], Batch [700/750], Loss: 0.1378\n",
            "Epoch [21/200] Total train Cost: 144.42991160973907\n",
            "---------------------------------------------\n",
            "Epoch [22/200], Batch [100/750], Loss: 0.1386\n",
            "Epoch [22/200], Batch [200/750], Loss: 0.2107\n",
            "Epoch [22/200], Batch [300/750], Loss: 0.1237\n",
            "Epoch [22/200], Batch [400/750], Loss: 0.1053\n",
            "Epoch [22/200], Batch [500/750], Loss: 0.1366\n",
            "Epoch [22/200], Batch [600/750], Loss: 0.2490\n",
            "Epoch [22/200], Batch [700/750], Loss: 0.2297\n",
            "Epoch [22/200] Total train Cost: 140.61373303458095\n",
            "---------------------------------------------\n",
            "Epoch [23/200], Batch [100/750], Loss: 0.1743\n",
            "Epoch [23/200], Batch [200/750], Loss: 0.1699\n",
            "Epoch [23/200], Batch [300/750], Loss: 0.0860\n",
            "Epoch [23/200], Batch [400/750], Loss: 0.1370\n",
            "Epoch [23/200], Batch [500/750], Loss: 0.1174\n",
            "Epoch [23/200], Batch [600/750], Loss: 0.1726\n",
            "Epoch [23/200], Batch [700/750], Loss: 0.1137\n",
            "Epoch [23/200] Total train Cost: 136.78794230893254\n",
            "---------------------------------------------\n",
            "Epoch [24/200], Batch [100/750], Loss: 0.2863\n",
            "Epoch [24/200], Batch [200/750], Loss: 0.2394\n",
            "Epoch [24/200], Batch [300/750], Loss: 0.1300\n",
            "Epoch [24/200], Batch [400/750], Loss: 0.0760\n",
            "Epoch [24/200], Batch [500/750], Loss: 0.2096\n",
            "Epoch [24/200], Batch [600/750], Loss: 0.1117\n",
            "Epoch [24/200], Batch [700/750], Loss: 0.1458\n",
            "Epoch [24/200] Total train Cost: 133.24608867242932\n",
            "---------------------------------------------\n",
            "Epoch [25/200], Batch [100/750], Loss: 0.3522\n",
            "Epoch [25/200], Batch [200/750], Loss: 0.2931\n",
            "Epoch [25/200], Batch [300/750], Loss: 0.1177\n",
            "Epoch [25/200], Batch [400/750], Loss: 0.2226\n",
            "Epoch [25/200], Batch [500/750], Loss: 0.1937\n",
            "Epoch [25/200], Batch [600/750], Loss: 0.1153\n",
            "Epoch [25/200], Batch [700/750], Loss: 0.2510\n",
            "Epoch [25/200] Total train Cost: 129.72950493730605\n",
            "---------------------------------------------\n",
            "Epoch [26/200], Batch [100/750], Loss: 0.1173\n",
            "Epoch [26/200], Batch [200/750], Loss: 0.2854\n",
            "Epoch [26/200], Batch [300/750], Loss: 0.3061\n",
            "Epoch [26/200], Batch [400/750], Loss: 0.0790\n",
            "Epoch [26/200], Batch [500/750], Loss: 0.3471\n",
            "Epoch [26/200], Batch [600/750], Loss: 0.2191\n",
            "Epoch [26/200], Batch [700/750], Loss: 0.1810\n",
            "Epoch [26/200] Total train Cost: 126.55458846315742\n",
            "---------------------------------------------\n",
            "Epoch [27/200], Batch [100/750], Loss: 0.1728\n",
            "Epoch [27/200], Batch [200/750], Loss: 0.1140\n",
            "Epoch [27/200], Batch [300/750], Loss: 0.1806\n",
            "Epoch [27/200], Batch [400/750], Loss: 0.4317\n",
            "Epoch [27/200], Batch [500/750], Loss: 0.1259\n",
            "Epoch [27/200], Batch [600/750], Loss: 0.3291\n",
            "Epoch [27/200], Batch [700/750], Loss: 0.1943\n",
            "Epoch [27/200] Total train Cost: 123.38910874351859\n",
            "---------------------------------------------\n",
            "Epoch [28/200], Batch [100/750], Loss: 0.2532\n",
            "Epoch [28/200], Batch [200/750], Loss: 0.1926\n",
            "Epoch [28/200], Batch [300/750], Loss: 0.2765\n",
            "Epoch [28/200], Batch [400/750], Loss: 0.1156\n",
            "Epoch [28/200], Batch [500/750], Loss: 0.2083\n",
            "Epoch [28/200], Batch [600/750], Loss: 0.1398\n",
            "Epoch [28/200], Batch [700/750], Loss: 0.1569\n",
            "Epoch [28/200] Total train Cost: 120.36427786201239\n",
            "---------------------------------------------\n",
            "Epoch [29/200], Batch [100/750], Loss: 0.1819\n",
            "Epoch [29/200], Batch [200/750], Loss: 0.3141\n",
            "Epoch [29/200], Batch [300/750], Loss: 0.1378\n",
            "Epoch [29/200], Batch [400/750], Loss: 0.4723\n",
            "Epoch [29/200], Batch [500/750], Loss: 0.0838\n",
            "Epoch [29/200], Batch [600/750], Loss: 0.0701\n",
            "Epoch [29/200], Batch [700/750], Loss: 0.1815\n",
            "Epoch [29/200] Total train Cost: 117.56011407263577\n",
            "---------------------------------------------\n",
            "Epoch [30/200], Batch [100/750], Loss: 0.0336\n",
            "Epoch [30/200], Batch [200/750], Loss: 0.1333\n",
            "Epoch [30/200], Batch [300/750], Loss: 0.0703\n",
            "Epoch [30/200], Batch [400/750], Loss: 0.0574\n",
            "Epoch [30/200], Batch [500/750], Loss: 0.2138\n",
            "Epoch [30/200], Batch [600/750], Loss: 0.0458\n",
            "Epoch [30/200], Batch [700/750], Loss: 0.0878\n",
            "Epoch [30/200] Total train Cost: 114.71603590808809\n",
            "---------------------------------------------\n",
            "Epoch [31/200], Batch [100/750], Loss: 0.1261\n",
            "Epoch [31/200], Batch [200/750], Loss: 0.1747\n",
            "Epoch [31/200], Batch [300/750], Loss: 0.0921\n",
            "Epoch [31/200], Batch [400/750], Loss: 0.2451\n",
            "Epoch [31/200], Batch [500/750], Loss: 0.0730\n",
            "Epoch [31/200], Batch [600/750], Loss: 0.0902\n",
            "Epoch [31/200], Batch [700/750], Loss: 0.0491\n",
            "Epoch [31/200] Total train Cost: 112.09349688328803\n",
            "---------------------------------------------\n",
            "Epoch [32/200], Batch [100/750], Loss: 0.2067\n",
            "Epoch [32/200], Batch [200/750], Loss: 0.0870\n",
            "Epoch [32/200], Batch [300/750], Loss: 0.1360\n",
            "Epoch [32/200], Batch [400/750], Loss: 0.1106\n",
            "Epoch [32/200], Batch [500/750], Loss: 0.1127\n",
            "Epoch [32/200], Batch [600/750], Loss: 0.3008\n",
            "Epoch [32/200], Batch [700/750], Loss: 0.3201\n",
            "Epoch [32/200] Total train Cost: 109.50563645735383\n",
            "---------------------------------------------\n",
            "Epoch [33/200], Batch [100/750], Loss: 0.1663\n",
            "Epoch [33/200], Batch [200/750], Loss: 0.0784\n",
            "Epoch [33/200], Batch [300/750], Loss: 0.0897\n",
            "Epoch [33/200], Batch [400/750], Loss: 0.1591\n",
            "Epoch [33/200], Batch [500/750], Loss: 0.2233\n",
            "Epoch [33/200], Batch [600/750], Loss: 0.1283\n",
            "Epoch [33/200], Batch [700/750], Loss: 0.0715\n",
            "Epoch [33/200] Total train Cost: 107.186403112486\n",
            "---------------------------------------------\n",
            "Epoch [34/200], Batch [100/750], Loss: 0.0655\n",
            "Epoch [34/200], Batch [200/750], Loss: 0.2054\n",
            "Epoch [34/200], Batch [300/750], Loss: 0.4852\n",
            "Epoch [34/200], Batch [400/750], Loss: 0.1997\n",
            "Epoch [34/200], Batch [500/750], Loss: 0.3065\n",
            "Epoch [34/200], Batch [600/750], Loss: 0.0888\n",
            "Epoch [34/200], Batch [700/750], Loss: 0.1666\n",
            "Epoch [34/200] Total train Cost: 104.69182505644858\n",
            "---------------------------------------------\n",
            "Epoch [35/200], Batch [100/750], Loss: 0.2470\n",
            "Epoch [35/200], Batch [200/750], Loss: 0.1249\n",
            "Epoch [35/200], Batch [300/750], Loss: 0.0963\n",
            "Epoch [35/200], Batch [400/750], Loss: 0.1007\n",
            "Epoch [35/200], Batch [500/750], Loss: 0.0822\n",
            "Epoch [35/200], Batch [600/750], Loss: 0.1341\n",
            "Epoch [35/200], Batch [700/750], Loss: 0.0678\n",
            "Epoch [35/200] Total train Cost: 102.50179974362254\n",
            "---------------------------------------------\n",
            "Epoch [36/200], Batch [100/750], Loss: 0.1601\n",
            "Epoch [36/200], Batch [200/750], Loss: 0.1066\n",
            "Epoch [36/200], Batch [300/750], Loss: 0.1061\n",
            "Epoch [36/200], Batch [400/750], Loss: 0.0891\n",
            "Epoch [36/200], Batch [500/750], Loss: 0.0637\n",
            "Epoch [36/200], Batch [600/750], Loss: 0.1586\n",
            "Epoch [36/200], Batch [700/750], Loss: 0.2500\n",
            "Epoch [36/200] Total train Cost: 100.48729690350592\n",
            "---------------------------------------------\n",
            "Epoch [37/200], Batch [100/750], Loss: 0.0472\n",
            "Epoch [37/200], Batch [200/750], Loss: 0.0815\n",
            "Epoch [37/200], Batch [300/750], Loss: 0.0988\n",
            "Epoch [37/200], Batch [400/750], Loss: 0.2081\n",
            "Epoch [37/200], Batch [500/750], Loss: 0.1673\n",
            "Epoch [37/200], Batch [600/750], Loss: 0.0786\n",
            "Epoch [37/200], Batch [700/750], Loss: 0.0661\n",
            "Epoch [37/200] Total train Cost: 98.31714713200927\n",
            "---------------------------------------------\n",
            "Epoch [38/200], Batch [100/750], Loss: 0.0537\n",
            "Epoch [38/200], Batch [200/750], Loss: 0.0940\n",
            "Epoch [38/200], Batch [300/750], Loss: 0.1232\n",
            "Epoch [38/200], Batch [400/750], Loss: 0.1926\n",
            "Epoch [38/200], Batch [500/750], Loss: 0.0760\n",
            "Epoch [38/200], Batch [600/750], Loss: 0.1397\n",
            "Epoch [38/200], Batch [700/750], Loss: 0.0806\n",
            "Epoch [38/200] Total train Cost: 96.28093734197319\n",
            "---------------------------------------------\n",
            "Epoch [39/200], Batch [100/750], Loss: 0.2128\n",
            "Epoch [39/200], Batch [200/750], Loss: 0.0691\n",
            "Epoch [39/200], Batch [300/750], Loss: 0.1789\n",
            "Epoch [39/200], Batch [400/750], Loss: 0.1278\n",
            "Epoch [39/200], Batch [500/750], Loss: 0.1474\n",
            "Epoch [39/200], Batch [600/750], Loss: 0.2641\n",
            "Epoch [39/200], Batch [700/750], Loss: 0.0769\n",
            "Epoch [39/200] Total train Cost: 94.3387903533876\n",
            "---------------------------------------------\n",
            "Epoch [40/200], Batch [100/750], Loss: 0.2215\n",
            "Epoch [40/200], Batch [200/750], Loss: 0.1186\n",
            "Epoch [40/200], Batch [300/750], Loss: 0.0776\n",
            "Epoch [40/200], Batch [400/750], Loss: 0.1804\n",
            "Epoch [40/200], Batch [500/750], Loss: 0.1739\n",
            "Epoch [40/200], Batch [600/750], Loss: 0.1576\n",
            "Epoch [40/200], Batch [700/750], Loss: 0.1366\n",
            "Epoch [40/200] Total train Cost: 92.44491555541754\n",
            "---------------------------------------------\n",
            "Epoch [41/200], Batch [100/750], Loss: 0.0579\n",
            "Epoch [41/200], Batch [200/750], Loss: 0.2589\n",
            "Epoch [41/200], Batch [300/750], Loss: 0.1046\n",
            "Epoch [41/200], Batch [400/750], Loss: 0.2645\n",
            "Epoch [41/200], Batch [500/750], Loss: 0.1151\n",
            "Epoch [41/200], Batch [600/750], Loss: 0.1182\n",
            "Epoch [41/200], Batch [700/750], Loss: 0.0791\n",
            "Epoch [41/200] Total train Cost: 90.74460201151669\n",
            "---------------------------------------------\n",
            "Epoch [42/200], Batch [100/750], Loss: 0.1529\n",
            "Epoch [42/200], Batch [200/750], Loss: 0.0754\n",
            "Epoch [42/200], Batch [300/750], Loss: 0.1670\n",
            "Epoch [42/200], Batch [400/750], Loss: 0.1061\n",
            "Epoch [42/200], Batch [500/750], Loss: 0.2373\n",
            "Epoch [42/200], Batch [600/750], Loss: 0.0901\n",
            "Epoch [42/200], Batch [700/750], Loss: 0.1406\n",
            "Epoch [42/200] Total train Cost: 88.94034805521369\n",
            "---------------------------------------------\n",
            "Epoch [43/200], Batch [100/750], Loss: 0.0997\n",
            "Epoch [43/200], Batch [200/750], Loss: 0.0925\n",
            "Epoch [43/200], Batch [300/750], Loss: 0.0863\n",
            "Epoch [43/200], Batch [400/750], Loss: 0.0995\n",
            "Epoch [43/200], Batch [500/750], Loss: 0.0837\n",
            "Epoch [43/200], Batch [600/750], Loss: 0.1320\n",
            "Epoch [43/200], Batch [700/750], Loss: 0.1432\n",
            "Epoch [43/200] Total train Cost: 87.3588328845799\n",
            "---------------------------------------------\n",
            "Epoch [44/200], Batch [100/750], Loss: 0.0952\n",
            "Epoch [44/200], Batch [200/750], Loss: 0.0792\n",
            "Epoch [44/200], Batch [300/750], Loss: 0.1155\n",
            "Epoch [44/200], Batch [400/750], Loss: 0.1215\n",
            "Epoch [44/200], Batch [500/750], Loss: 0.0620\n",
            "Epoch [44/200], Batch [600/750], Loss: 0.1108\n",
            "Epoch [44/200], Batch [700/750], Loss: 0.0420\n",
            "Epoch [44/200] Total train Cost: 85.67226017452776\n",
            "---------------------------------------------\n",
            "Epoch [45/200], Batch [100/750], Loss: 0.0788\n",
            "Epoch [45/200], Batch [200/750], Loss: 0.1872\n",
            "Epoch [45/200], Batch [300/750], Loss: 0.0884\n",
            "Epoch [45/200], Batch [400/750], Loss: 0.1085\n",
            "Epoch [45/200], Batch [500/750], Loss: 0.1368\n",
            "Epoch [45/200], Batch [600/750], Loss: 0.1652\n",
            "Epoch [45/200], Batch [700/750], Loss: 0.0856\n",
            "Epoch [45/200] Total train Cost: 84.0491098575294\n",
            "---------------------------------------------\n",
            "Epoch [46/200], Batch [100/750], Loss: 0.0626\n",
            "Epoch [46/200], Batch [200/750], Loss: 0.1966\n",
            "Epoch [46/200], Batch [300/750], Loss: 0.0530\n",
            "Epoch [46/200], Batch [400/750], Loss: 0.0538\n",
            "Epoch [46/200], Batch [500/750], Loss: 0.2312\n",
            "Epoch [46/200], Batch [600/750], Loss: 0.1771\n",
            "Epoch [46/200], Batch [700/750], Loss: 0.2202\n",
            "Epoch [46/200] Total train Cost: 82.61492641083896\n",
            "---------------------------------------------\n",
            "Epoch [47/200], Batch [100/750], Loss: 0.1446\n",
            "Epoch [47/200], Batch [200/750], Loss: 0.0277\n",
            "Epoch [47/200], Batch [300/750], Loss: 0.1227\n",
            "Epoch [47/200], Batch [400/750], Loss: 0.0859\n",
            "Epoch [47/200], Batch [500/750], Loss: 0.1427\n",
            "Epoch [47/200], Batch [600/750], Loss: 0.1335\n",
            "Epoch [47/200], Batch [700/750], Loss: 0.1296\n",
            "Epoch [47/200] Total train Cost: 81.09750138223171\n",
            "---------------------------------------------\n",
            "Epoch [48/200], Batch [100/750], Loss: 0.0856\n",
            "Epoch [48/200], Batch [200/750], Loss: 0.2372\n",
            "Epoch [48/200], Batch [300/750], Loss: 0.0520\n",
            "Epoch [48/200], Batch [400/750], Loss: 0.0958\n",
            "Epoch [48/200], Batch [500/750], Loss: 0.1607\n",
            "Epoch [48/200], Batch [600/750], Loss: 0.1693\n",
            "Epoch [48/200], Batch [700/750], Loss: 0.0542\n",
            "Epoch [48/200] Total train Cost: 79.64993480965495\n",
            "---------------------------------------------\n",
            "Epoch [49/200], Batch [100/750], Loss: 0.0874\n",
            "Epoch [49/200], Batch [200/750], Loss: 0.1700\n",
            "Epoch [49/200], Batch [300/750], Loss: 0.0932\n",
            "Epoch [49/200], Batch [400/750], Loss: 0.0753\n",
            "Epoch [49/200], Batch [500/750], Loss: 0.0996\n",
            "Epoch [49/200], Batch [600/750], Loss: 0.1028\n",
            "Epoch [49/200], Batch [700/750], Loss: 0.1353\n",
            "Epoch [49/200] Total train Cost: 78.23411157540977\n",
            "---------------------------------------------\n",
            "Epoch [50/200], Batch [100/750], Loss: 0.0329\n",
            "Epoch [50/200], Batch [200/750], Loss: 0.1620\n",
            "Epoch [50/200], Batch [300/750], Loss: 0.0370\n",
            "Epoch [50/200], Batch [400/750], Loss: 0.0778\n",
            "Epoch [50/200], Batch [500/750], Loss: 0.1019\n",
            "Epoch [50/200], Batch [600/750], Loss: 0.1218\n",
            "Epoch [50/200], Batch [700/750], Loss: 0.0626\n",
            "Epoch [50/200] Total train Cost: 76.8412784524262\n",
            "---------------------------------------------\n",
            "Epoch [51/200], Batch [100/750], Loss: 0.0639\n",
            "Epoch [51/200], Batch [200/750], Loss: 0.0894\n",
            "Epoch [51/200], Batch [300/750], Loss: 0.0366\n",
            "Epoch [51/200], Batch [400/750], Loss: 0.1161\n",
            "Epoch [51/200], Batch [500/750], Loss: 0.0747\n",
            "Epoch [51/200], Batch [600/750], Loss: 0.0312\n",
            "Epoch [51/200], Batch [700/750], Loss: 0.0523\n",
            "Epoch [51/200] Total train Cost: 75.57264587190002\n",
            "---------------------------------------------\n",
            "Epoch [52/200], Batch [100/750], Loss: 0.0345\n",
            "Epoch [52/200], Batch [200/750], Loss: 0.0938\n",
            "Epoch [52/200], Batch [300/750], Loss: 0.0265\n",
            "Epoch [52/200], Batch [400/750], Loss: 0.0739\n",
            "Epoch [52/200], Batch [500/750], Loss: 0.0499\n",
            "Epoch [52/200], Batch [600/750], Loss: 0.0656\n",
            "Epoch [52/200], Batch [700/750], Loss: 0.0424\n",
            "Epoch [52/200] Total train Cost: 74.32866477780044\n",
            "---------------------------------------------\n",
            "Epoch [53/200], Batch [100/750], Loss: 0.0187\n",
            "Epoch [53/200], Batch [200/750], Loss: 0.1067\n",
            "Epoch [53/200], Batch [300/750], Loss: 0.0775\n",
            "Epoch [53/200], Batch [400/750], Loss: 0.1956\n",
            "Epoch [53/200], Batch [500/750], Loss: 0.0469\n",
            "Epoch [53/200], Batch [600/750], Loss: 0.0968\n",
            "Epoch [53/200], Batch [700/750], Loss: 0.1506\n",
            "Epoch [53/200] Total train Cost: 73.1108226608485\n",
            "---------------------------------------------\n",
            "Epoch [54/200], Batch [100/750], Loss: 0.0899\n",
            "Epoch [54/200], Batch [200/750], Loss: 0.0236\n",
            "Epoch [54/200], Batch [300/750], Loss: 0.0873\n",
            "Epoch [54/200], Batch [400/750], Loss: 0.0948\n",
            "Epoch [54/200], Batch [500/750], Loss: 0.1143\n",
            "Epoch [54/200], Batch [600/750], Loss: 0.0802\n",
            "Epoch [54/200], Batch [700/750], Loss: 0.0560\n",
            "Epoch [54/200] Total train Cost: 71.87100581079721\n",
            "---------------------------------------------\n",
            "Epoch [55/200], Batch [100/750], Loss: 0.0594\n",
            "Epoch [55/200], Batch [200/750], Loss: 0.0758\n",
            "Epoch [55/200], Batch [300/750], Loss: 0.0630\n",
            "Epoch [55/200], Batch [400/750], Loss: 0.0843\n",
            "Epoch [55/200], Batch [500/750], Loss: 0.0518\n",
            "Epoch [55/200], Batch [600/750], Loss: 0.0749\n",
            "Epoch [55/200], Batch [700/750], Loss: 0.1179\n",
            "Epoch [55/200] Total train Cost: 70.70379730314016\n",
            "---------------------------------------------\n",
            "Epoch [56/200], Batch [100/750], Loss: 0.1057\n",
            "Epoch [56/200], Batch [200/750], Loss: 0.1313\n",
            "Epoch [56/200], Batch [300/750], Loss: 0.0839\n",
            "Epoch [56/200], Batch [400/750], Loss: 0.0996\n",
            "Epoch [56/200], Batch [500/750], Loss: 0.0504\n",
            "Epoch [56/200], Batch [600/750], Loss: 0.0727\n",
            "Epoch [56/200], Batch [700/750], Loss: 0.2383\n",
            "Epoch [56/200] Total train Cost: 69.56710933148861\n",
            "---------------------------------------------\n",
            "Epoch [57/200], Batch [100/750], Loss: 0.1082\n",
            "Epoch [57/200], Batch [200/750], Loss: 0.1764\n",
            "Epoch [57/200], Batch [300/750], Loss: 0.0958\n",
            "Epoch [57/200], Batch [400/750], Loss: 0.0655\n",
            "Epoch [57/200], Batch [500/750], Loss: 0.0971\n",
            "Epoch [57/200], Batch [600/750], Loss: 0.0427\n",
            "Epoch [57/200], Batch [700/750], Loss: 0.0571\n",
            "Epoch [57/200] Total train Cost: 68.4375316677615\n",
            "---------------------------------------------\n",
            "Epoch [58/200], Batch [100/750], Loss: 0.0552\n",
            "Epoch [58/200], Batch [200/750], Loss: 0.0386\n",
            "Epoch [58/200], Batch [300/750], Loss: 0.0455\n",
            "Epoch [58/200], Batch [400/750], Loss: 0.0456\n",
            "Epoch [58/200], Batch [500/750], Loss: 0.0360\n",
            "Epoch [58/200], Batch [600/750], Loss: 0.0418\n",
            "Epoch [58/200], Batch [700/750], Loss: 0.0625\n",
            "Epoch [58/200] Total train Cost: 67.2892014440149\n",
            "---------------------------------------------\n",
            "Epoch [59/200], Batch [100/750], Loss: 0.0752\n",
            "Epoch [59/200], Batch [200/750], Loss: 0.1287\n",
            "Epoch [59/200], Batch [300/750], Loss: 0.0773\n",
            "Epoch [59/200], Batch [400/750], Loss: 0.0484\n",
            "Epoch [59/200], Batch [500/750], Loss: 0.0295\n",
            "Epoch [59/200], Batch [600/750], Loss: 0.1224\n",
            "Epoch [59/200], Batch [700/750], Loss: 0.0672\n",
            "Epoch [59/200] Total train Cost: 66.31470938771963\n",
            "---------------------------------------------\n",
            "Epoch [60/200], Batch [100/750], Loss: 0.1450\n",
            "Epoch [60/200], Batch [200/750], Loss: 0.0609\n",
            "Epoch [60/200], Batch [300/750], Loss: 0.1013\n",
            "Epoch [60/200], Batch [400/750], Loss: 0.1068\n",
            "Epoch [60/200], Batch [500/750], Loss: 0.1258\n",
            "Epoch [60/200], Batch [600/750], Loss: 0.1464\n",
            "Epoch [60/200], Batch [700/750], Loss: 0.0470\n",
            "Epoch [60/200] Total train Cost: 65.29093614406884\n",
            "---------------------------------------------\n",
            "Epoch [61/200], Batch [100/750], Loss: 0.1432\n",
            "Epoch [61/200], Batch [200/750], Loss: 0.0336\n",
            "Epoch [61/200], Batch [300/750], Loss: 0.1059\n",
            "Epoch [61/200], Batch [400/750], Loss: 0.0727\n",
            "Epoch [61/200], Batch [500/750], Loss: 0.1427\n",
            "Epoch [61/200], Batch [600/750], Loss: 0.2732\n",
            "Epoch [61/200], Batch [700/750], Loss: 0.1494\n",
            "Epoch [61/200] Total train Cost: 64.25781156215817\n",
            "---------------------------------------------\n",
            "Epoch [62/200], Batch [100/750], Loss: 0.0638\n",
            "Epoch [62/200], Batch [200/750], Loss: 0.1182\n",
            "Epoch [62/200], Batch [300/750], Loss: 0.0901\n",
            "Epoch [62/200], Batch [400/750], Loss: 0.0241\n",
            "Epoch [62/200], Batch [500/750], Loss: 0.0498\n",
            "Epoch [62/200], Batch [600/750], Loss: 0.1470\n",
            "Epoch [62/200], Batch [700/750], Loss: 0.0309\n",
            "Epoch [62/200] Total train Cost: 63.30226066149771\n",
            "---------------------------------------------\n",
            "Epoch [63/200], Batch [100/750], Loss: 0.1330\n",
            "Epoch [63/200], Batch [200/750], Loss: 0.0259\n",
            "Epoch [63/200], Batch [300/750], Loss: 0.0839\n",
            "Epoch [63/200], Batch [400/750], Loss: 0.0548\n",
            "Epoch [63/200], Batch [500/750], Loss: 0.0606\n",
            "Epoch [63/200], Batch [600/750], Loss: 0.1166\n",
            "Epoch [63/200], Batch [700/750], Loss: 0.0757\n",
            "Epoch [63/200] Total train Cost: 62.327100835740566\n",
            "---------------------------------------------\n",
            "Epoch [64/200], Batch [100/750], Loss: 0.1336\n",
            "Epoch [64/200], Batch [200/750], Loss: 0.0733\n",
            "Epoch [64/200], Batch [300/750], Loss: 0.0616\n",
            "Epoch [64/200], Batch [400/750], Loss: 0.0272\n",
            "Epoch [64/200], Batch [500/750], Loss: 0.0476\n",
            "Epoch [64/200], Batch [600/750], Loss: 0.0711\n",
            "Epoch [64/200], Batch [700/750], Loss: 0.0632\n",
            "Epoch [64/200] Total train Cost: 61.44615437835455\n",
            "---------------------------------------------\n",
            "Epoch [65/200], Batch [100/750], Loss: 0.0200\n",
            "Epoch [65/200], Batch [200/750], Loss: 0.0728\n",
            "Epoch [65/200], Batch [300/750], Loss: 0.1198\n",
            "Epoch [65/200], Batch [400/750], Loss: 0.1408\n",
            "Epoch [65/200], Batch [500/750], Loss: 0.0436\n",
            "Epoch [65/200], Batch [600/750], Loss: 0.1478\n",
            "Epoch [65/200], Batch [700/750], Loss: 0.0246\n",
            "Epoch [65/200] Total train Cost: 60.50806860439479\n",
            "---------------------------------------------\n",
            "Epoch [66/200], Batch [100/750], Loss: 0.0385\n",
            "Epoch [66/200], Batch [200/750], Loss: 0.2124\n",
            "Epoch [66/200], Batch [300/750], Loss: 0.1823\n",
            "Epoch [66/200], Batch [400/750], Loss: 0.3064\n",
            "Epoch [66/200], Batch [500/750], Loss: 0.0939\n",
            "Epoch [66/200], Batch [600/750], Loss: 0.0757\n",
            "Epoch [66/200], Batch [700/750], Loss: 0.0267\n",
            "Epoch [66/200] Total train Cost: 59.62485930509865\n",
            "---------------------------------------------\n",
            "Epoch [67/200], Batch [100/750], Loss: 0.0435\n",
            "Epoch [67/200], Batch [200/750], Loss: 0.0776\n",
            "Epoch [67/200], Batch [300/750], Loss: 0.0583\n",
            "Epoch [67/200], Batch [400/750], Loss: 0.0196\n",
            "Epoch [67/200], Batch [500/750], Loss: 0.0715\n",
            "Epoch [67/200], Batch [600/750], Loss: 0.1065\n",
            "Epoch [67/200], Batch [700/750], Loss: 0.1809\n",
            "Epoch [67/200] Total train Cost: 58.7796481391415\n",
            "---------------------------------------------\n",
            "Epoch [68/200], Batch [100/750], Loss: 0.1626\n",
            "Epoch [68/200], Batch [200/750], Loss: 0.0537\n",
            "Epoch [68/200], Batch [300/750], Loss: 0.0771\n",
            "Epoch [68/200], Batch [400/750], Loss: 0.0634\n",
            "Epoch [68/200], Batch [500/750], Loss: 0.0335\n",
            "Epoch [68/200], Batch [600/750], Loss: 0.1140\n",
            "Epoch [68/200], Batch [700/750], Loss: 0.0347\n",
            "Epoch [68/200] Total train Cost: 57.90381994843483\n",
            "---------------------------------------------\n",
            "Epoch [69/200], Batch [100/750], Loss: 0.0423\n",
            "Epoch [69/200], Batch [200/750], Loss: 0.0265\n",
            "Epoch [69/200], Batch [300/750], Loss: 0.0746\n",
            "Epoch [69/200], Batch [400/750], Loss: 0.0349\n",
            "Epoch [69/200], Batch [500/750], Loss: 0.0726\n",
            "Epoch [69/200], Batch [600/750], Loss: 0.1087\n",
            "Epoch [69/200], Batch [700/750], Loss: 0.0581\n",
            "Epoch [69/200] Total train Cost: 57.10778188984841\n",
            "---------------------------------------------\n",
            "Epoch [70/200], Batch [100/750], Loss: 0.0749\n",
            "Epoch [70/200], Batch [200/750], Loss: 0.0818\n",
            "Epoch [70/200], Batch [300/750], Loss: 0.1400\n",
            "Epoch [70/200], Batch [400/750], Loss: 0.0464\n",
            "Epoch [70/200], Batch [500/750], Loss: 0.0718\n",
            "Epoch [70/200], Batch [600/750], Loss: 0.0999\n",
            "Epoch [70/200], Batch [700/750], Loss: 0.0687\n",
            "Epoch [70/200] Total train Cost: 56.303356904536486\n",
            "---------------------------------------------\n",
            "Epoch [71/200], Batch [100/750], Loss: 0.1074\n",
            "Epoch [71/200], Batch [200/750], Loss: 0.0977\n",
            "Epoch [71/200], Batch [300/750], Loss: 0.0793\n",
            "Epoch [71/200], Batch [400/750], Loss: 0.1029\n",
            "Epoch [71/200], Batch [500/750], Loss: 0.0387\n",
            "Epoch [71/200], Batch [600/750], Loss: 0.0290\n",
            "Epoch [71/200], Batch [700/750], Loss: 0.0394\n",
            "Epoch [71/200] Total train Cost: 55.47944999393076\n",
            "---------------------------------------------\n",
            "Epoch [72/200], Batch [100/750], Loss: 0.0318\n",
            "Epoch [72/200], Batch [200/750], Loss: 0.0406\n",
            "Epoch [72/200], Batch [300/750], Loss: 0.0874\n",
            "Epoch [72/200], Batch [400/750], Loss: 0.1172\n",
            "Epoch [72/200], Batch [500/750], Loss: 0.0501\n",
            "Epoch [72/200], Batch [600/750], Loss: 0.1630\n",
            "Epoch [72/200], Batch [700/750], Loss: 0.2280\n",
            "Epoch [72/200] Total train Cost: 54.675428816117346\n",
            "---------------------------------------------\n",
            "Epoch [73/200], Batch [100/750], Loss: 0.0751\n",
            "Epoch [73/200], Batch [200/750], Loss: 0.0461\n",
            "Epoch [73/200], Batch [300/750], Loss: 0.0569\n",
            "Epoch [73/200], Batch [400/750], Loss: 0.0611\n",
            "Epoch [73/200], Batch [500/750], Loss: 0.0434\n",
            "Epoch [73/200], Batch [600/750], Loss: 0.0495\n",
            "Epoch [73/200], Batch [700/750], Loss: 0.0330\n",
            "Epoch [73/200] Total train Cost: 53.964166822843254\n",
            "---------------------------------------------\n",
            "Epoch [74/200], Batch [100/750], Loss: 0.0504\n",
            "Epoch [74/200], Batch [200/750], Loss: 0.0716\n",
            "Epoch [74/200], Batch [300/750], Loss: 0.0334\n",
            "Epoch [74/200], Batch [400/750], Loss: 0.1105\n",
            "Epoch [74/200], Batch [500/750], Loss: 0.1109\n",
            "Epoch [74/200], Batch [600/750], Loss: 0.0383\n",
            "Epoch [74/200], Batch [700/750], Loss: 0.0342\n",
            "Epoch [74/200] Total train Cost: 53.21815203409642\n",
            "---------------------------------------------\n",
            "Epoch [75/200], Batch [100/750], Loss: 0.0586\n",
            "Epoch [75/200], Batch [200/750], Loss: 0.1217\n",
            "Epoch [75/200], Batch [300/750], Loss: 0.0657\n",
            "Epoch [75/200], Batch [400/750], Loss: 0.1000\n",
            "Epoch [75/200], Batch [500/750], Loss: 0.0793\n",
            "Epoch [75/200], Batch [600/750], Loss: 0.1435\n",
            "Epoch [75/200], Batch [700/750], Loss: 0.0612\n",
            "Epoch [75/200] Total train Cost: 52.51136807119474\n",
            "---------------------------------------------\n",
            "Epoch [76/200], Batch [100/750], Loss: 0.0790\n",
            "Epoch [76/200], Batch [200/750], Loss: 0.0393\n",
            "Epoch [76/200], Batch [300/750], Loss: 0.0992\n",
            "Epoch [76/200], Batch [400/750], Loss: 0.0680\n",
            "Epoch [76/200], Batch [500/750], Loss: 0.0354\n",
            "Epoch [76/200], Batch [600/750], Loss: 0.1632\n",
            "Epoch [76/200], Batch [700/750], Loss: 0.0591\n",
            "Epoch [76/200] Total train Cost: 51.77728958660737\n",
            "---------------------------------------------\n",
            "Epoch [77/200], Batch [100/750], Loss: 0.0166\n",
            "Epoch [77/200], Batch [200/750], Loss: 0.0645\n",
            "Epoch [77/200], Batch [300/750], Loss: 0.1999\n",
            "Epoch [77/200], Batch [400/750], Loss: 0.0772\n",
            "Epoch [77/200], Batch [500/750], Loss: 0.0481\n",
            "Epoch [77/200], Batch [600/750], Loss: 0.0944\n",
            "Epoch [77/200], Batch [700/750], Loss: 0.1049\n",
            "Epoch [77/200] Total train Cost: 51.10230372380465\n",
            "---------------------------------------------\n",
            "Epoch [78/200], Batch [100/750], Loss: 0.0320\n",
            "Epoch [78/200], Batch [200/750], Loss: 0.0310\n",
            "Epoch [78/200], Batch [300/750], Loss: 0.0196\n",
            "Epoch [78/200], Batch [400/750], Loss: 0.0783\n",
            "Epoch [78/200], Batch [500/750], Loss: 0.2482\n",
            "Epoch [78/200], Batch [600/750], Loss: 0.1158\n",
            "Epoch [78/200], Batch [700/750], Loss: 0.1041\n",
            "Epoch [78/200] Total train Cost: 50.356609389185905\n",
            "---------------------------------------------\n",
            "Epoch [79/200], Batch [100/750], Loss: 0.0433\n",
            "Epoch [79/200], Batch [200/750], Loss: 0.0268\n",
            "Epoch [79/200], Batch [300/750], Loss: 0.0771\n",
            "Epoch [79/200], Batch [400/750], Loss: 0.0354\n",
            "Epoch [79/200], Batch [500/750], Loss: 0.1429\n",
            "Epoch [79/200], Batch [600/750], Loss: 0.0882\n",
            "Epoch [79/200], Batch [700/750], Loss: 0.0271\n",
            "Epoch [79/200] Total train Cost: 49.712699465453625\n",
            "---------------------------------------------\n",
            "Epoch [80/200], Batch [100/750], Loss: 0.0310\n",
            "Epoch [80/200], Batch [200/750], Loss: 0.0449\n",
            "Epoch [80/200], Batch [300/750], Loss: 0.0299\n",
            "Epoch [80/200], Batch [400/750], Loss: 0.0362\n",
            "Epoch [80/200], Batch [500/750], Loss: 0.0178\n",
            "Epoch [80/200], Batch [600/750], Loss: 0.0392\n",
            "Epoch [80/200], Batch [700/750], Loss: 0.0150\n",
            "Epoch [80/200] Total train Cost: 49.084605569019914\n",
            "---------------------------------------------\n",
            "Epoch [81/200], Batch [100/750], Loss: 0.0454\n",
            "Epoch [81/200], Batch [200/750], Loss: 0.0508\n",
            "Epoch [81/200], Batch [300/750], Loss: 0.1927\n",
            "Epoch [81/200], Batch [400/750], Loss: 0.0758\n",
            "Epoch [81/200], Batch [500/750], Loss: 0.0614\n",
            "Epoch [81/200], Batch [600/750], Loss: 0.0268\n",
            "Epoch [81/200], Batch [700/750], Loss: 0.0913\n",
            "Epoch [81/200] Total train Cost: 48.440094775520265\n",
            "---------------------------------------------\n",
            "Epoch [82/200], Batch [100/750], Loss: 0.0229\n",
            "Epoch [82/200], Batch [200/750], Loss: 0.0996\n",
            "Epoch [82/200], Batch [300/750], Loss: 0.0572\n",
            "Epoch [82/200], Batch [400/750], Loss: 0.1189\n",
            "Epoch [82/200], Batch [500/750], Loss: 0.0655\n",
            "Epoch [82/200], Batch [600/750], Loss: 0.1650\n",
            "Epoch [82/200], Batch [700/750], Loss: 0.0551\n",
            "Epoch [82/200] Total train Cost: 47.78151213284582\n",
            "---------------------------------------------\n",
            "Epoch [83/200], Batch [100/750], Loss: 0.0387\n",
            "Epoch [83/200], Batch [200/750], Loss: 0.0417\n",
            "Epoch [83/200], Batch [300/750], Loss: 0.0497\n",
            "Epoch [83/200], Batch [400/750], Loss: 0.0552\n",
            "Epoch [83/200], Batch [500/750], Loss: 0.0951\n",
            "Epoch [83/200], Batch [600/750], Loss: 0.0714\n",
            "Epoch [83/200], Batch [700/750], Loss: 0.0746\n",
            "Epoch [83/200] Total train Cost: 47.151379332877696\n",
            "---------------------------------------------\n",
            "Epoch [84/200], Batch [100/750], Loss: 0.0376\n",
            "Epoch [84/200], Batch [200/750], Loss: 0.0189\n",
            "Epoch [84/200], Batch [300/750], Loss: 0.0542\n",
            "Epoch [84/200], Batch [400/750], Loss: 0.0919\n",
            "Epoch [84/200], Batch [500/750], Loss: 0.0665\n",
            "Epoch [84/200], Batch [600/750], Loss: 0.0501\n",
            "Epoch [84/200], Batch [700/750], Loss: 0.1106\n",
            "Epoch [84/200] Total train Cost: 46.62774766702205\n",
            "---------------------------------------------\n",
            "Epoch [85/200], Batch [100/750], Loss: 0.1120\n",
            "Epoch [85/200], Batch [200/750], Loss: 0.0311\n",
            "Epoch [85/200], Batch [300/750], Loss: 0.0442\n",
            "Epoch [85/200], Batch [400/750], Loss: 0.0222\n",
            "Epoch [85/200], Batch [500/750], Loss: 0.0338\n",
            "Epoch [85/200], Batch [600/750], Loss: 0.0164\n",
            "Epoch [85/200], Batch [700/750], Loss: 0.0341\n",
            "Epoch [85/200] Total train Cost: 45.95823308639228\n",
            "---------------------------------------------\n",
            "Epoch [86/200], Batch [100/750], Loss: 0.0585\n",
            "Epoch [86/200], Batch [200/750], Loss: 0.0257\n",
            "Epoch [86/200], Batch [300/750], Loss: 0.0553\n",
            "Epoch [86/200], Batch [400/750], Loss: 0.1109\n",
            "Epoch [86/200], Batch [500/750], Loss: 0.0730\n",
            "Epoch [86/200], Batch [600/750], Loss: 0.0466\n",
            "Epoch [86/200], Batch [700/750], Loss: 0.0979\n",
            "Epoch [86/200] Total train Cost: 45.386595860123634\n",
            "---------------------------------------------\n",
            "Epoch [87/200], Batch [100/750], Loss: 0.1030\n",
            "Epoch [87/200], Batch [200/750], Loss: 0.1134\n",
            "Epoch [87/200], Batch [300/750], Loss: 0.0456\n",
            "Epoch [87/200], Batch [400/750], Loss: 0.1696\n",
            "Epoch [87/200], Batch [500/750], Loss: 0.0890\n",
            "Epoch [87/200], Batch [600/750], Loss: 0.0308\n",
            "Epoch [87/200], Batch [700/750], Loss: 0.0281\n",
            "Epoch [87/200] Total train Cost: 44.85338389594108\n",
            "---------------------------------------------\n",
            "Epoch [88/200], Batch [100/750], Loss: 0.0244\n",
            "Epoch [88/200], Batch [200/750], Loss: 0.1222\n",
            "Epoch [88/200], Batch [300/750], Loss: 0.0455\n",
            "Epoch [88/200], Batch [400/750], Loss: 0.0388\n",
            "Epoch [88/200], Batch [500/750], Loss: 0.0504\n",
            "Epoch [88/200], Batch [600/750], Loss: 0.0232\n",
            "Epoch [88/200], Batch [700/750], Loss: 0.0615\n",
            "Epoch [88/200] Total train Cost: 44.34566241502762\n",
            "---------------------------------------------\n",
            "Epoch [89/200], Batch [100/750], Loss: 0.0558\n",
            "Epoch [89/200], Batch [200/750], Loss: 0.0561\n",
            "Epoch [89/200], Batch [300/750], Loss: 0.0839\n",
            "Epoch [89/200], Batch [400/750], Loss: 0.0581\n",
            "Epoch [89/200], Batch [500/750], Loss: 0.0471\n",
            "Epoch [89/200], Batch [600/750], Loss: 0.0470\n",
            "Epoch [89/200], Batch [700/750], Loss: 0.0505\n",
            "Epoch [89/200] Total train Cost: 43.76970903761685\n",
            "---------------------------------------------\n",
            "Epoch [90/200], Batch [100/750], Loss: 0.0836\n",
            "Epoch [90/200], Batch [200/750], Loss: 0.0281\n",
            "Epoch [90/200], Batch [300/750], Loss: 0.0513\n",
            "Epoch [90/200], Batch [400/750], Loss: 0.1634\n",
            "Epoch [90/200], Batch [500/750], Loss: 0.0263\n",
            "Epoch [90/200], Batch [600/750], Loss: 0.0868\n",
            "Epoch [90/200], Batch [700/750], Loss: 0.0337\n",
            "Epoch [90/200] Total train Cost: 43.230516551062465\n",
            "---------------------------------------------\n",
            "Epoch [91/200], Batch [100/750], Loss: 0.0711\n",
            "Epoch [91/200], Batch [200/750], Loss: 0.0307\n",
            "Epoch [91/200], Batch [300/750], Loss: 0.0517\n",
            "Epoch [91/200], Batch [400/750], Loss: 0.0335\n",
            "Epoch [91/200], Batch [500/750], Loss: 0.0844\n",
            "Epoch [91/200], Batch [600/750], Loss: 0.0661\n",
            "Epoch [91/200], Batch [700/750], Loss: 0.0318\n",
            "Epoch [91/200] Total train Cost: 42.71338662225753\n",
            "---------------------------------------------\n",
            "Epoch [92/200], Batch [100/750], Loss: 0.0310\n",
            "Epoch [92/200], Batch [200/750], Loss: 0.0567\n",
            "Epoch [92/200], Batch [300/750], Loss: 0.0350\n",
            "Epoch [92/200], Batch [400/750], Loss: 0.1026\n",
            "Epoch [92/200], Batch [500/750], Loss: 0.0429\n",
            "Epoch [92/200], Batch [600/750], Loss: 0.0886\n",
            "Epoch [92/200], Batch [700/750], Loss: 0.0331\n",
            "Epoch [92/200] Total train Cost: 42.22763361549005\n",
            "---------------------------------------------\n",
            "Epoch [93/200], Batch [100/750], Loss: 0.0639\n",
            "Epoch [93/200], Batch [200/750], Loss: 0.0411\n",
            "Epoch [93/200], Batch [300/750], Loss: 0.0593\n",
            "Epoch [93/200], Batch [400/750], Loss: 0.0465\n",
            "Epoch [93/200], Batch [500/750], Loss: 0.0694\n",
            "Epoch [93/200], Batch [600/750], Loss: 0.0159\n",
            "Epoch [93/200], Batch [700/750], Loss: 0.0205\n",
            "Epoch [93/200] Total train Cost: 41.718912380281836\n",
            "---------------------------------------------\n",
            "Epoch [94/200], Batch [100/750], Loss: 0.0626\n",
            "Epoch [94/200], Batch [200/750], Loss: 0.1109\n",
            "Epoch [94/200], Batch [300/750], Loss: 0.0715\n",
            "Epoch [94/200], Batch [400/750], Loss: 0.0563\n",
            "Epoch [94/200], Batch [500/750], Loss: 0.0249\n",
            "Epoch [94/200], Batch [600/750], Loss: 0.0210\n",
            "Epoch [94/200], Batch [700/750], Loss: 0.0288\n",
            "Epoch [94/200] Total train Cost: 41.20213501295075\n",
            "---------------------------------------------\n",
            "Epoch [95/200], Batch [100/750], Loss: 0.0330\n",
            "Epoch [95/200], Batch [200/750], Loss: 0.0408\n",
            "Epoch [95/200], Batch [300/750], Loss: 0.0204\n",
            "Epoch [95/200], Batch [400/750], Loss: 0.0255\n",
            "Epoch [95/200], Batch [500/750], Loss: 0.0948\n",
            "Epoch [95/200], Batch [600/750], Loss: 0.0303\n",
            "Epoch [95/200], Batch [700/750], Loss: 0.0325\n",
            "Epoch [95/200] Total train Cost: 40.698223527520895\n",
            "---------------------------------------------\n",
            "Epoch [96/200], Batch [100/750], Loss: 0.0084\n",
            "Epoch [96/200], Batch [200/750], Loss: 0.0487\n",
            "Epoch [96/200], Batch [300/750], Loss: 0.0134\n",
            "Epoch [96/200], Batch [400/750], Loss: 0.0894\n",
            "Epoch [96/200], Batch [500/750], Loss: 0.0182\n",
            "Epoch [96/200], Batch [600/750], Loss: 0.0621\n",
            "Epoch [96/200], Batch [700/750], Loss: 0.0486\n",
            "Epoch [96/200] Total train Cost: 40.25413112482056\n",
            "---------------------------------------------\n",
            "Epoch [97/200], Batch [100/750], Loss: 0.0230\n",
            "Epoch [97/200], Batch [200/750], Loss: 0.0349\n",
            "Epoch [97/200], Batch [300/750], Loss: 0.0292\n",
            "Epoch [97/200], Batch [400/750], Loss: 0.0429\n",
            "Epoch [97/200], Batch [500/750], Loss: 0.0566\n",
            "Epoch [97/200], Batch [600/750], Loss: 0.0246\n",
            "Epoch [97/200], Batch [700/750], Loss: 0.0989\n",
            "Epoch [97/200] Total train Cost: 39.75314562721178\n",
            "---------------------------------------------\n",
            "Epoch [98/200], Batch [100/750], Loss: 0.0812\n",
            "Epoch [98/200], Batch [200/750], Loss: 0.0506\n",
            "Epoch [98/200], Batch [300/750], Loss: 0.0583\n",
            "Epoch [98/200], Batch [400/750], Loss: 0.1319\n",
            "Epoch [98/200], Batch [500/750], Loss: 0.0250\n",
            "Epoch [98/200], Batch [600/750], Loss: 0.0207\n",
            "Epoch [98/200], Batch [700/750], Loss: 0.0295\n",
            "Epoch [98/200] Total train Cost: 39.28078343020752\n",
            "---------------------------------------------\n",
            "Epoch [99/200], Batch [100/750], Loss: 0.0157\n",
            "Epoch [99/200], Batch [200/750], Loss: 0.0282\n",
            "Epoch [99/200], Batch [300/750], Loss: 0.0263\n",
            "Epoch [99/200], Batch [400/750], Loss: 0.0172\n",
            "Epoch [99/200], Batch [500/750], Loss: 0.0477\n",
            "Epoch [99/200], Batch [600/750], Loss: 0.0142\n",
            "Epoch [99/200], Batch [700/750], Loss: 0.1237\n",
            "Epoch [99/200] Total train Cost: 38.852546805515885\n",
            "---------------------------------------------\n",
            "Epoch [100/200], Batch [100/750], Loss: 0.0566\n",
            "Epoch [100/200], Batch [200/750], Loss: 0.0970\n",
            "Epoch [100/200], Batch [300/750], Loss: 0.0344\n",
            "Epoch [100/200], Batch [400/750], Loss: 0.0379\n",
            "Epoch [100/200], Batch [500/750], Loss: 0.0783\n",
            "Epoch [100/200], Batch [600/750], Loss: 0.0978\n",
            "Epoch [100/200], Batch [700/750], Loss: 0.0562\n",
            "Epoch [100/200] Total train Cost: 38.4621866364032\n",
            "---------------------------------------------\n",
            "Epoch [101/200], Batch [100/750], Loss: 0.1002\n",
            "Epoch [101/200], Batch [200/750], Loss: 0.1245\n",
            "Epoch [101/200], Batch [300/750], Loss: 0.0340\n",
            "Epoch [101/200], Batch [400/750], Loss: 0.0525\n",
            "Epoch [101/200], Batch [500/750], Loss: 0.0140\n",
            "Epoch [101/200], Batch [600/750], Loss: 0.0468\n",
            "Epoch [101/200], Batch [700/750], Loss: 0.0195\n",
            "Epoch [101/200] Total train Cost: 37.87313141161576\n",
            "---------------------------------------------\n",
            "Epoch [102/200], Batch [100/750], Loss: 0.0436\n",
            "Epoch [102/200], Batch [200/750], Loss: 0.0392\n",
            "Epoch [102/200], Batch [300/750], Loss: 0.0349\n",
            "Epoch [102/200], Batch [400/750], Loss: 0.1566\n",
            "Epoch [102/200], Batch [500/750], Loss: 0.0157\n",
            "Epoch [102/200], Batch [600/750], Loss: 0.0333\n",
            "Epoch [102/200], Batch [700/750], Loss: 0.1273\n",
            "Epoch [102/200] Total train Cost: 37.53627966204658\n",
            "---------------------------------------------\n",
            "Epoch [103/200], Batch [100/750], Loss: 0.0077\n",
            "Epoch [103/200], Batch [200/750], Loss: 0.0474\n",
            "Epoch [103/200], Batch [300/750], Loss: 0.0195\n",
            "Epoch [103/200], Batch [400/750], Loss: 0.0183\n",
            "Epoch [103/200], Batch [500/750], Loss: 0.0172\n",
            "Epoch [103/200], Batch [600/750], Loss: 0.0316\n",
            "Epoch [103/200], Batch [700/750], Loss: 0.0340\n",
            "Epoch [103/200] Total train Cost: 37.1287094540894\n",
            "---------------------------------------------\n",
            "Epoch [104/200], Batch [100/750], Loss: 0.0468\n",
            "Epoch [104/200], Batch [200/750], Loss: 0.0275\n",
            "Epoch [104/200], Batch [300/750], Loss: 0.0357\n",
            "Epoch [104/200], Batch [400/750], Loss: 0.0677\n",
            "Epoch [104/200], Batch [500/750], Loss: 0.0424\n",
            "Epoch [104/200], Batch [600/750], Loss: 0.0198\n",
            "Epoch [104/200], Batch [700/750], Loss: 0.0149\n",
            "Epoch [104/200] Total train Cost: 36.69370413804427\n",
            "---------------------------------------------\n",
            "Epoch [105/200], Batch [100/750], Loss: 0.0640\n",
            "Epoch [105/200], Batch [200/750], Loss: 0.0449\n",
            "Epoch [105/200], Batch [300/750], Loss: 0.0458\n",
            "Epoch [105/200], Batch [400/750], Loss: 0.0805\n",
            "Epoch [105/200], Batch [500/750], Loss: 0.0362\n",
            "Epoch [105/200], Batch [600/750], Loss: 0.0113\n",
            "Epoch [105/200], Batch [700/750], Loss: 0.0421\n",
            "Epoch [105/200] Total train Cost: 36.277962169609964\n",
            "---------------------------------------------\n",
            "Epoch [106/200], Batch [100/750], Loss: 0.0420\n",
            "Epoch [106/200], Batch [200/750], Loss: 0.0567\n",
            "Epoch [106/200], Batch [300/750], Loss: 0.0265\n",
            "Epoch [106/200], Batch [400/750], Loss: 0.0765\n",
            "Epoch [106/200], Batch [500/750], Loss: 0.0777\n",
            "Epoch [106/200], Batch [600/750], Loss: 0.0421\n",
            "Epoch [106/200], Batch [700/750], Loss: 0.0502\n",
            "Epoch [106/200] Total train Cost: 35.8714209725149\n",
            "---------------------------------------------\n",
            "Epoch [107/200], Batch [100/750], Loss: 0.0734\n",
            "Epoch [107/200], Batch [200/750], Loss: 0.0383\n",
            "Epoch [107/200], Batch [300/750], Loss: 0.0256\n",
            "Epoch [107/200], Batch [400/750], Loss: 0.0164\n",
            "Epoch [107/200], Batch [500/750], Loss: 0.0375\n",
            "Epoch [107/200], Batch [600/750], Loss: 0.0186\n",
            "Epoch [107/200], Batch [700/750], Loss: 0.0201\n",
            "Epoch [107/200] Total train Cost: 35.46050102543086\n",
            "---------------------------------------------\n",
            "Epoch [108/200], Batch [100/750], Loss: 0.0158\n",
            "Epoch [108/200], Batch [200/750], Loss: 0.0522\n",
            "Epoch [108/200], Batch [300/750], Loss: 0.0445\n",
            "Epoch [108/200], Batch [400/750], Loss: 0.0231\n",
            "Epoch [108/200], Batch [500/750], Loss: 0.1072\n",
            "Epoch [108/200], Batch [600/750], Loss: 0.0211\n",
            "Epoch [108/200], Batch [700/750], Loss: 0.0401\n",
            "Epoch [108/200] Total train Cost: 35.12561747897416\n",
            "---------------------------------------------\n",
            "Epoch [109/200], Batch [100/750], Loss: 0.0267\n",
            "Epoch [109/200], Batch [200/750], Loss: 0.0769\n",
            "Epoch [109/200], Batch [300/750], Loss: 0.0720\n",
            "Epoch [109/200], Batch [400/750], Loss: 0.0141\n",
            "Epoch [109/200], Batch [500/750], Loss: 0.0672\n",
            "Epoch [109/200], Batch [600/750], Loss: 0.0091\n",
            "Epoch [109/200], Batch [700/750], Loss: 0.0135\n",
            "Epoch [109/200] Total train Cost: 34.718132857233286\n",
            "---------------------------------------------\n",
            "Epoch [110/200], Batch [100/750], Loss: 0.0146\n",
            "Epoch [110/200], Batch [200/750], Loss: 0.0184\n",
            "Epoch [110/200], Batch [300/750], Loss: 0.0147\n",
            "Epoch [110/200], Batch [400/750], Loss: 0.0585\n",
            "Epoch [110/200], Batch [500/750], Loss: 0.0689\n",
            "Epoch [110/200], Batch [600/750], Loss: 0.0410\n",
            "Epoch [110/200], Batch [700/750], Loss: 0.0441\n",
            "Epoch [110/200] Total train Cost: 34.37625262653455\n",
            "---------------------------------------------\n",
            "Epoch [111/200], Batch [100/750], Loss: 0.0385\n",
            "Epoch [111/200], Batch [200/750], Loss: 0.0553\n",
            "Epoch [111/200], Batch [300/750], Loss: 0.0379\n",
            "Epoch [111/200], Batch [400/750], Loss: 0.0111\n",
            "Epoch [111/200], Batch [500/750], Loss: 0.0201\n",
            "Epoch [111/200], Batch [600/750], Loss: 0.0103\n",
            "Epoch [111/200], Batch [700/750], Loss: 0.0194\n",
            "Epoch [111/200] Total train Cost: 33.973798831459135\n",
            "---------------------------------------------\n",
            "Epoch [112/200], Batch [100/750], Loss: 0.0428\n",
            "Epoch [112/200], Batch [200/750], Loss: 0.0332\n",
            "Epoch [112/200], Batch [300/750], Loss: 0.0415\n",
            "Epoch [112/200], Batch [400/750], Loss: 0.0289\n",
            "Epoch [112/200], Batch [500/750], Loss: 0.0722\n",
            "Epoch [112/200], Batch [600/750], Loss: 0.0541\n",
            "Epoch [112/200], Batch [700/750], Loss: 0.0216\n",
            "Epoch [112/200] Total train Cost: 33.59224377386272\n",
            "---------------------------------------------\n",
            "Epoch [113/200], Batch [100/750], Loss: 0.0189\n",
            "Epoch [113/200], Batch [200/750], Loss: 0.0309\n",
            "Epoch [113/200], Batch [300/750], Loss: 0.0448\n",
            "Epoch [113/200], Batch [400/750], Loss: 0.0564\n",
            "Epoch [113/200], Batch [500/750], Loss: 0.0820\n",
            "Epoch [113/200], Batch [600/750], Loss: 0.0242\n",
            "Epoch [113/200], Batch [700/750], Loss: 0.0106\n",
            "Epoch [113/200] Total train Cost: 33.23275205353275\n",
            "---------------------------------------------\n",
            "Epoch [114/200], Batch [100/750], Loss: 0.0340\n",
            "Epoch [114/200], Batch [200/750], Loss: 0.0258\n",
            "Epoch [114/200], Batch [300/750], Loss: 0.0288\n",
            "Epoch [114/200], Batch [400/750], Loss: 0.0296\n",
            "Epoch [114/200], Batch [500/750], Loss: 0.0664\n",
            "Epoch [114/200], Batch [600/750], Loss: 0.0416\n",
            "Epoch [114/200], Batch [700/750], Loss: 0.0133\n",
            "Epoch [114/200] Total train Cost: 32.92025329079479\n",
            "---------------------------------------------\n",
            "Epoch [115/200], Batch [100/750], Loss: 0.0647\n",
            "Epoch [115/200], Batch [200/750], Loss: 0.0093\n",
            "Epoch [115/200], Batch [300/750], Loss: 0.0153\n",
            "Epoch [115/200], Batch [400/750], Loss: 0.0277\n",
            "Epoch [115/200], Batch [500/750], Loss: 0.0226\n",
            "Epoch [115/200], Batch [600/750], Loss: 0.0521\n",
            "Epoch [115/200], Batch [700/750], Loss: 0.1030\n",
            "Epoch [115/200] Total train Cost: 32.525640728883445\n",
            "---------------------------------------------\n",
            "Epoch [116/200], Batch [100/750], Loss: 0.0692\n",
            "Epoch [116/200], Batch [200/750], Loss: 0.0244\n",
            "Epoch [116/200], Batch [300/750], Loss: 0.0275\n",
            "Epoch [116/200], Batch [400/750], Loss: 0.0257\n",
            "Epoch [116/200], Batch [500/750], Loss: 0.0434\n",
            "Epoch [116/200], Batch [600/750], Loss: 0.0119\n",
            "Epoch [116/200], Batch [700/750], Loss: 0.0230\n",
            "Epoch [116/200] Total train Cost: 32.22630720818415\n",
            "---------------------------------------------\n",
            "Epoch [117/200], Batch [100/750], Loss: 0.0879\n",
            "Epoch [117/200], Batch [200/750], Loss: 0.0195\n",
            "Epoch [117/200], Batch [300/750], Loss: 0.0939\n",
            "Epoch [117/200], Batch [400/750], Loss: 0.0361\n",
            "Epoch [117/200], Batch [500/750], Loss: 0.0759\n",
            "Epoch [117/200], Batch [600/750], Loss: 0.0126\n",
            "Epoch [117/200], Batch [700/750], Loss: 0.0115\n",
            "Epoch [117/200] Total train Cost: 31.886781126260757\n",
            "---------------------------------------------\n",
            "Epoch [118/200], Batch [100/750], Loss: 0.0534\n",
            "Epoch [118/200], Batch [200/750], Loss: 0.0426\n",
            "Epoch [118/200], Batch [300/750], Loss: 0.0155\n",
            "Epoch [118/200], Batch [400/750], Loss: 0.0151\n",
            "Epoch [118/200], Batch [500/750], Loss: 0.0091\n",
            "Epoch [118/200], Batch [600/750], Loss: 0.0753\n",
            "Epoch [118/200], Batch [700/750], Loss: 0.0218\n",
            "Epoch [118/200] Total train Cost: 31.524425266310573\n",
            "---------------------------------------------\n",
            "Epoch [119/200], Batch [100/750], Loss: 0.0278\n",
            "Epoch [119/200], Batch [200/750], Loss: 0.0104\n",
            "Epoch [119/200], Batch [300/750], Loss: 0.0815\n",
            "Epoch [119/200], Batch [400/750], Loss: 0.0168\n",
            "Epoch [119/200], Batch [500/750], Loss: 0.0094\n",
            "Epoch [119/200], Batch [600/750], Loss: 0.0529\n",
            "Epoch [119/200], Batch [700/750], Loss: 0.0111\n",
            "Epoch [119/200] Total train Cost: 31.200398755725473\n",
            "---------------------------------------------\n",
            "Epoch [120/200], Batch [100/750], Loss: 0.0221\n",
            "Epoch [120/200], Batch [200/750], Loss: 0.0596\n",
            "Epoch [120/200], Batch [300/750], Loss: 0.0167\n",
            "Epoch [120/200], Batch [400/750], Loss: 0.0156\n",
            "Epoch [120/200], Batch [500/750], Loss: 0.0354\n",
            "Epoch [120/200], Batch [600/750], Loss: 0.0225\n",
            "Epoch [120/200], Batch [700/750], Loss: 0.0772\n",
            "Epoch [120/200] Total train Cost: 30.91281393636018\n",
            "---------------------------------------------\n",
            "Epoch [121/200], Batch [100/750], Loss: 0.0342\n",
            "Epoch [121/200], Batch [200/750], Loss: 0.0266\n",
            "Epoch [121/200], Batch [300/750], Loss: 0.0314\n",
            "Epoch [121/200], Batch [400/750], Loss: 0.0108\n",
            "Epoch [121/200], Batch [500/750], Loss: 0.0438\n",
            "Epoch [121/200], Batch [600/750], Loss: 0.0433\n",
            "Epoch [121/200], Batch [700/750], Loss: 0.0175\n",
            "Epoch [121/200] Total train Cost: 30.59814359410666\n",
            "---------------------------------------------\n",
            "Epoch [122/200], Batch [100/750], Loss: 0.0387\n",
            "Epoch [122/200], Batch [200/750], Loss: 0.0213\n",
            "Epoch [122/200], Batch [300/750], Loss: 0.0182\n",
            "Epoch [122/200], Batch [400/750], Loss: 0.0284\n",
            "Epoch [122/200], Batch [500/750], Loss: 0.0585\n",
            "Epoch [122/200], Batch [600/750], Loss: 0.0243\n",
            "Epoch [122/200], Batch [700/750], Loss: 0.0216\n",
            "Epoch [122/200] Total train Cost: 30.262847676407546\n",
            "---------------------------------------------\n",
            "Epoch [123/200], Batch [100/750], Loss: 0.0286\n",
            "Epoch [123/200], Batch [200/750], Loss: 0.0642\n",
            "Epoch [123/200], Batch [300/750], Loss: 0.0245\n",
            "Epoch [123/200], Batch [400/750], Loss: 0.1045\n",
            "Epoch [123/200], Batch [500/750], Loss: 0.0556\n",
            "Epoch [123/200], Batch [600/750], Loss: 0.0543\n",
            "Epoch [123/200], Batch [700/750], Loss: 0.0283\n",
            "Epoch [123/200] Total train Cost: 29.935552979353815\n",
            "---------------------------------------------\n",
            "Epoch [124/200], Batch [100/750], Loss: 0.0597\n",
            "Epoch [124/200], Batch [200/750], Loss: 0.0308\n",
            "Epoch [124/200], Batch [300/750], Loss: 0.0331\n",
            "Epoch [124/200], Batch [400/750], Loss: 0.0331\n",
            "Epoch [124/200], Batch [500/750], Loss: 0.0387\n",
            "Epoch [124/200], Batch [600/750], Loss: 0.0345\n",
            "Epoch [124/200], Batch [700/750], Loss: 0.0547\n",
            "Epoch [124/200] Total train Cost: 29.615044658537954\n",
            "---------------------------------------------\n",
            "Epoch [125/200], Batch [100/750], Loss: 0.0097\n",
            "Epoch [125/200], Batch [200/750], Loss: 0.0590\n",
            "Epoch [125/200], Batch [300/750], Loss: 0.0514\n",
            "Epoch [125/200], Batch [400/750], Loss: 0.0203\n",
            "Epoch [125/200], Batch [500/750], Loss: 0.0847\n",
            "Epoch [125/200], Batch [600/750], Loss: 0.0164\n",
            "Epoch [125/200], Batch [700/750], Loss: 0.0287\n",
            "Epoch [125/200] Total train Cost: 29.277345156297088\n",
            "---------------------------------------------\n",
            "Epoch [126/200], Batch [100/750], Loss: 0.1129\n",
            "Epoch [126/200], Batch [200/750], Loss: 0.0241\n",
            "Epoch [126/200], Batch [300/750], Loss: 0.0147\n",
            "Epoch [126/200], Batch [400/750], Loss: 0.0230\n",
            "Epoch [126/200], Batch [500/750], Loss: 0.0537\n",
            "Epoch [126/200], Batch [600/750], Loss: 0.1591\n",
            "Epoch [126/200], Batch [700/750], Loss: 0.0376\n",
            "Epoch [126/200] Total train Cost: 29.027151747606695\n",
            "---------------------------------------------\n",
            "Epoch [127/200], Batch [100/750], Loss: 0.0187\n",
            "Epoch [127/200], Batch [200/750], Loss: 0.0684\n",
            "Epoch [127/200], Batch [300/750], Loss: 0.0277\n",
            "Epoch [127/200], Batch [400/750], Loss: 0.0121\n",
            "Epoch [127/200], Batch [500/750], Loss: 0.0272\n",
            "Epoch [127/200], Batch [600/750], Loss: 0.0350\n",
            "Epoch [127/200], Batch [700/750], Loss: 0.0527\n",
            "Epoch [127/200] Total train Cost: 28.75302093056962\n",
            "---------------------------------------------\n",
            "Epoch [128/200], Batch [100/750], Loss: 0.0276\n",
            "Epoch [128/200], Batch [200/750], Loss: 0.0415\n",
            "Epoch [128/200], Batch [300/750], Loss: 0.0202\n",
            "Epoch [128/200], Batch [400/750], Loss: 0.0413\n",
            "Epoch [128/200], Batch [500/750], Loss: 0.0396\n",
            "Epoch [128/200], Batch [600/750], Loss: 0.0197\n",
            "Epoch [128/200], Batch [700/750], Loss: 0.0390\n",
            "Epoch [128/200] Total train Cost: 28.46296392334625\n",
            "---------------------------------------------\n",
            "Epoch [129/200], Batch [100/750], Loss: 0.0370\n",
            "Epoch [129/200], Batch [200/750], Loss: 0.0329\n",
            "Epoch [129/200], Batch [300/750], Loss: 0.0285\n",
            "Epoch [129/200], Batch [400/750], Loss: 0.0334\n",
            "Epoch [129/200], Batch [500/750], Loss: 0.0159\n",
            "Epoch [129/200], Batch [600/750], Loss: 0.0252\n",
            "Epoch [129/200], Batch [700/750], Loss: 0.0130\n",
            "Epoch [129/200] Total train Cost: 28.17341070389375\n",
            "---------------------------------------------\n",
            "Epoch [130/200], Batch [100/750], Loss: 0.0307\n",
            "Epoch [130/200], Batch [200/750], Loss: 0.0876\n",
            "Epoch [130/200], Batch [300/750], Loss: 0.0735\n",
            "Epoch [130/200], Batch [400/750], Loss: 0.0530\n",
            "Epoch [130/200], Batch [500/750], Loss: 0.0130\n",
            "Epoch [130/200], Batch [600/750], Loss: 0.0289\n",
            "Epoch [130/200], Batch [700/750], Loss: 0.0835\n",
            "Epoch [130/200] Total train Cost: 27.887757788412273\n",
            "---------------------------------------------\n",
            "Epoch [131/200], Batch [100/750], Loss: 0.0515\n",
            "Epoch [131/200], Batch [200/750], Loss: 0.0117\n",
            "Epoch [131/200], Batch [300/750], Loss: 0.0227\n",
            "Epoch [131/200], Batch [400/750], Loss: 0.0118\n",
            "Epoch [131/200], Batch [500/750], Loss: 0.0217\n",
            "Epoch [131/200], Batch [600/750], Loss: 0.0372\n",
            "Epoch [131/200], Batch [700/750], Loss: 0.0288\n",
            "Epoch [131/200] Total train Cost: 27.643207841087133\n",
            "---------------------------------------------\n",
            "Epoch [132/200], Batch [100/750], Loss: 0.0253\n",
            "Epoch [132/200], Batch [200/750], Loss: 0.0376\n",
            "Epoch [132/200], Batch [300/750], Loss: 0.0426\n",
            "Epoch [132/200], Batch [400/750], Loss: 0.0523\n",
            "Epoch [132/200], Batch [500/750], Loss: 0.0438\n",
            "Epoch [132/200], Batch [600/750], Loss: 0.0246\n",
            "Epoch [132/200], Batch [700/750], Loss: 0.0271\n",
            "Epoch [132/200] Total train Cost: 27.369751723948866\n",
            "---------------------------------------------\n",
            "Epoch [133/200], Batch [100/750], Loss: 0.0255\n",
            "Epoch [133/200], Batch [200/750], Loss: 0.0252\n",
            "Epoch [133/200], Batch [300/750], Loss: 0.0162\n",
            "Epoch [133/200], Batch [400/750], Loss: 0.0154\n",
            "Epoch [133/200], Batch [500/750], Loss: 0.0095\n",
            "Epoch [133/200], Batch [600/750], Loss: 0.0313\n",
            "Epoch [133/200], Batch [700/750], Loss: 0.0296\n",
            "Epoch [133/200] Total train Cost: 27.102891898248345\n",
            "---------------------------------------------\n",
            "Epoch [134/200], Batch [100/750], Loss: 0.0399\n",
            "Epoch [134/200], Batch [200/750], Loss: 0.0327\n",
            "Epoch [134/200], Batch [300/750], Loss: 0.0320\n",
            "Epoch [134/200], Batch [400/750], Loss: 0.0625\n",
            "Epoch [134/200], Batch [500/750], Loss: 0.0268\n",
            "Epoch [134/200], Batch [600/750], Loss: 0.0557\n",
            "Epoch [134/200], Batch [700/750], Loss: 0.0644\n",
            "Epoch [134/200] Total train Cost: 26.830970334354788\n",
            "---------------------------------------------\n",
            "Epoch [135/200], Batch [100/750], Loss: 0.0261\n",
            "Epoch [135/200], Batch [200/750], Loss: 0.0190\n",
            "Epoch [135/200], Batch [300/750], Loss: 0.0327\n",
            "Epoch [135/200], Batch [400/750], Loss: 0.0786\n",
            "Epoch [135/200], Batch [500/750], Loss: 0.0095\n",
            "Epoch [135/200], Batch [600/750], Loss: 0.0242\n",
            "Epoch [135/200], Batch [700/750], Loss: 0.0304\n",
            "Epoch [135/200] Total train Cost: 26.56817843997851\n",
            "---------------------------------------------\n",
            "Epoch [136/200], Batch [100/750], Loss: 0.0114\n",
            "Epoch [136/200], Batch [200/750], Loss: 0.0216\n",
            "Epoch [136/200], Batch [300/750], Loss: 0.0280\n",
            "Epoch [136/200], Batch [400/750], Loss: 0.0270\n",
            "Epoch [136/200], Batch [500/750], Loss: 0.0377\n",
            "Epoch [136/200], Batch [600/750], Loss: 0.0164\n",
            "Epoch [136/200], Batch [700/750], Loss: 0.0521\n",
            "Epoch [136/200] Total train Cost: 26.304523094557226\n",
            "---------------------------------------------\n",
            "Epoch [137/200], Batch [100/750], Loss: 0.0176\n",
            "Epoch [137/200], Batch [200/750], Loss: 0.0459\n",
            "Epoch [137/200], Batch [300/750], Loss: 0.0230\n",
            "Epoch [137/200], Batch [400/750], Loss: 0.0265\n",
            "Epoch [137/200], Batch [500/750], Loss: 0.0289\n",
            "Epoch [137/200], Batch [600/750], Loss: 0.0633\n",
            "Epoch [137/200], Batch [700/750], Loss: 0.0198\n",
            "Epoch [137/200] Total train Cost: 26.0756784027908\n",
            "---------------------------------------------\n",
            "Epoch [138/200], Batch [100/750], Loss: 0.0270\n",
            "Epoch [138/200], Batch [200/750], Loss: 0.0500\n",
            "Epoch [138/200], Batch [300/750], Loss: 0.0346\n",
            "Epoch [138/200], Batch [400/750], Loss: 0.0545\n",
            "Epoch [138/200], Batch [500/750], Loss: 0.0615\n",
            "Epoch [138/200], Batch [600/750], Loss: 0.0219\n",
            "Epoch [138/200], Batch [700/750], Loss: 0.0243\n",
            "Epoch [138/200] Total train Cost: 25.777359111933038\n",
            "---------------------------------------------\n",
            "Epoch [139/200], Batch [100/750], Loss: 0.0275\n",
            "Epoch [139/200], Batch [200/750], Loss: 0.0493\n",
            "Epoch [139/200], Batch [300/750], Loss: 0.0156\n",
            "Epoch [139/200], Batch [400/750], Loss: 0.0152\n",
            "Epoch [139/200], Batch [500/750], Loss: 0.0329\n",
            "Epoch [139/200], Batch [600/750], Loss: 0.0140\n",
            "Epoch [139/200], Batch [700/750], Loss: 0.0744\n",
            "Epoch [139/200] Total train Cost: 25.533935341984034\n",
            "---------------------------------------------\n",
            "Epoch [140/200], Batch [100/750], Loss: 0.0120\n",
            "Epoch [140/200], Batch [200/750], Loss: 0.0190\n",
            "Epoch [140/200], Batch [300/750], Loss: 0.0105\n",
            "Epoch [140/200], Batch [400/750], Loss: 0.0206\n",
            "Epoch [140/200], Batch [500/750], Loss: 0.0122\n",
            "Epoch [140/200], Batch [600/750], Loss: 0.0665\n",
            "Epoch [140/200], Batch [700/750], Loss: 0.0217\n",
            "Epoch [140/200] Total train Cost: 25.322437851224095\n",
            "---------------------------------------------\n",
            "Epoch [141/200], Batch [100/750], Loss: 0.0196\n",
            "Epoch [141/200], Batch [200/750], Loss: 0.0299\n",
            "Epoch [141/200], Batch [300/750], Loss: 0.0519\n",
            "Epoch [141/200], Batch [400/750], Loss: 0.1029\n",
            "Epoch [141/200], Batch [500/750], Loss: 0.0089\n",
            "Epoch [141/200], Batch [600/750], Loss: 0.0288\n",
            "Epoch [141/200], Batch [700/750], Loss: 0.0473\n",
            "Epoch [141/200] Total train Cost: 25.083093041786924\n",
            "---------------------------------------------\n",
            "Epoch [142/200], Batch [100/750], Loss: 0.0269\n",
            "Epoch [142/200], Batch [200/750], Loss: 0.0198\n",
            "Epoch [142/200], Batch [300/750], Loss: 0.0249\n",
            "Epoch [142/200], Batch [400/750], Loss: 0.0181\n",
            "Epoch [142/200], Batch [500/750], Loss: 0.0138\n",
            "Epoch [142/200], Batch [600/750], Loss: 0.0347\n",
            "Epoch [142/200], Batch [700/750], Loss: 0.0485\n",
            "Epoch [142/200] Total train Cost: 24.83983914833516\n",
            "---------------------------------------------\n",
            "Epoch [143/200], Batch [100/750], Loss: 0.0243\n",
            "Epoch [143/200], Batch [200/750], Loss: 0.0194\n",
            "Epoch [143/200], Batch [300/750], Loss: 0.0166\n",
            "Epoch [143/200], Batch [400/750], Loss: 0.0436\n",
            "Epoch [143/200], Batch [500/750], Loss: 0.1215\n",
            "Epoch [143/200], Batch [600/750], Loss: 0.0346\n",
            "Epoch [143/200], Batch [700/750], Loss: 0.0479\n",
            "Epoch [143/200] Total train Cost: 24.55786599428393\n",
            "---------------------------------------------\n",
            "Epoch [144/200], Batch [100/750], Loss: 0.0102\n",
            "Epoch [144/200], Batch [200/750], Loss: 0.0346\n",
            "Epoch [144/200], Batch [300/750], Loss: 0.0170\n",
            "Epoch [144/200], Batch [400/750], Loss: 0.0529\n",
            "Epoch [144/200], Batch [500/750], Loss: 0.0495\n",
            "Epoch [144/200], Batch [600/750], Loss: 0.0133\n",
            "Epoch [144/200], Batch [700/750], Loss: 0.0244\n",
            "Epoch [144/200] Total train Cost: 24.376413353253156\n",
            "---------------------------------------------\n",
            "Epoch [145/200], Batch [100/750], Loss: 0.0330\n",
            "Epoch [145/200], Batch [200/750], Loss: 0.0457\n",
            "Epoch [145/200], Batch [300/750], Loss: 0.0519\n",
            "Epoch [145/200], Batch [400/750], Loss: 0.0078\n",
            "Epoch [145/200], Batch [500/750], Loss: 0.0264\n",
            "Epoch [145/200], Batch [600/750], Loss: 0.0287\n",
            "Epoch [145/200], Batch [700/750], Loss: 0.0137\n",
            "Epoch [145/200] Total train Cost: 24.162331548286602\n",
            "---------------------------------------------\n",
            "Epoch [146/200], Batch [100/750], Loss: 0.0696\n",
            "Epoch [146/200], Batch [200/750], Loss: 0.0224\n",
            "Epoch [146/200], Batch [300/750], Loss: 0.0186\n",
            "Epoch [146/200], Batch [400/750], Loss: 0.0227\n",
            "Epoch [146/200], Batch [500/750], Loss: 0.0161\n",
            "Epoch [146/200], Batch [600/750], Loss: 0.0185\n",
            "Epoch [146/200], Batch [700/750], Loss: 0.0252\n",
            "Epoch [146/200] Total train Cost: 23.924639785662293\n",
            "---------------------------------------------\n",
            "Epoch [147/200], Batch [100/750], Loss: 0.0256\n",
            "Epoch [147/200], Batch [200/750], Loss: 0.0160\n",
            "Epoch [147/200], Batch [300/750], Loss: 0.0381\n",
            "Epoch [147/200], Batch [400/750], Loss: 0.0700\n",
            "Epoch [147/200], Batch [500/750], Loss: 0.0296\n",
            "Epoch [147/200], Batch [600/750], Loss: 0.0535\n",
            "Epoch [147/200], Batch [700/750], Loss: 0.0152\n",
            "Epoch [147/200] Total train Cost: 23.7140008113347\n",
            "---------------------------------------------\n",
            "Epoch [148/200], Batch [100/750], Loss: 0.0284\n",
            "Epoch [148/200], Batch [200/750], Loss: 0.0429\n",
            "Epoch [148/200], Batch [300/750], Loss: 0.0261\n",
            "Epoch [148/200], Batch [400/750], Loss: 0.0633\n",
            "Epoch [148/200], Batch [500/750], Loss: 0.0784\n",
            "Epoch [148/200], Batch [600/750], Loss: 0.0331\n",
            "Epoch [148/200], Batch [700/750], Loss: 0.0067\n",
            "Epoch [148/200] Total train Cost: 23.443409664090723\n",
            "---------------------------------------------\n",
            "Epoch [149/200], Batch [100/750], Loss: 0.0146\n",
            "Epoch [149/200], Batch [200/750], Loss: 0.0093\n",
            "Epoch [149/200], Batch [300/750], Loss: 0.0124\n",
            "Epoch [149/200], Batch [400/750], Loss: 0.0195\n",
            "Epoch [149/200], Batch [500/750], Loss: 0.0155\n",
            "Epoch [149/200], Batch [600/750], Loss: 0.0450\n",
            "Epoch [149/200], Batch [700/750], Loss: 0.0397\n",
            "Epoch [149/200] Total train Cost: 23.235370689770207\n",
            "---------------------------------------------\n",
            "Epoch [150/200], Batch [100/750], Loss: 0.0287\n",
            "Epoch [150/200], Batch [200/750], Loss: 0.0244\n",
            "Epoch [150/200], Batch [300/750], Loss: 0.0353\n",
            "Epoch [150/200], Batch [400/750], Loss: 0.0133\n",
            "Epoch [150/200], Batch [500/750], Loss: 0.0721\n",
            "Epoch [150/200], Batch [600/750], Loss: 0.0130\n",
            "Epoch [150/200], Batch [700/750], Loss: 0.0183\n",
            "Epoch [150/200] Total train Cost: 23.070279450155795\n",
            "---------------------------------------------\n",
            "Epoch [151/200], Batch [100/750], Loss: 0.0485\n",
            "Epoch [151/200], Batch [200/750], Loss: 0.0173\n",
            "Epoch [151/200], Batch [300/750], Loss: 0.0392\n",
            "Epoch [151/200], Batch [400/750], Loss: 0.0266\n",
            "Epoch [151/200], Batch [500/750], Loss: 0.0357\n",
            "Epoch [151/200], Batch [600/750], Loss: 0.0951\n",
            "Epoch [151/200], Batch [700/750], Loss: 0.0218\n",
            "Epoch [151/200] Total train Cost: 22.848702117567882\n",
            "---------------------------------------------\n",
            "Epoch [152/200], Batch [100/750], Loss: 0.0139\n",
            "Epoch [152/200], Batch [200/750], Loss: 0.0390\n",
            "Epoch [152/200], Batch [300/750], Loss: 0.0303\n",
            "Epoch [152/200], Batch [400/750], Loss: 0.0234\n",
            "Epoch [152/200], Batch [500/750], Loss: 0.0098\n",
            "Epoch [152/200], Batch [600/750], Loss: 0.0149\n",
            "Epoch [152/200], Batch [700/750], Loss: 0.0351\n",
            "Epoch [152/200] Total train Cost: 22.59769800119102\n",
            "---------------------------------------------\n",
            "Epoch [153/200], Batch [100/750], Loss: 0.0237\n",
            "Epoch [153/200], Batch [200/750], Loss: 0.0073\n",
            "Epoch [153/200], Batch [300/750], Loss: 0.0777\n",
            "Epoch [153/200], Batch [400/750], Loss: 0.0084\n",
            "Epoch [153/200], Batch [500/750], Loss: 0.0175\n",
            "Epoch [153/200], Batch [600/750], Loss: 0.0182\n",
            "Epoch [153/200], Batch [700/750], Loss: 0.0171\n",
            "Epoch [153/200] Total train Cost: 22.39687617518939\n",
            "---------------------------------------------\n",
            "Epoch [154/200], Batch [100/750], Loss: 0.0175\n",
            "Epoch [154/200], Batch [200/750], Loss: 0.0300\n",
            "Epoch [154/200], Batch [300/750], Loss: 0.0167\n",
            "Epoch [154/200], Batch [400/750], Loss: 0.0450\n",
            "Epoch [154/200], Batch [500/750], Loss: 0.0147\n",
            "Epoch [154/200], Batch [600/750], Loss: 0.0404\n",
            "Epoch [154/200], Batch [700/750], Loss: 0.0218\n",
            "Epoch [154/200] Total train Cost: 22.20683111785911\n",
            "---------------------------------------------\n",
            "Epoch [155/200], Batch [100/750], Loss: 0.0443\n",
            "Epoch [155/200], Batch [200/750], Loss: 0.0217\n",
            "Epoch [155/200], Batch [300/750], Loss: 0.0216\n",
            "Epoch [155/200], Batch [400/750], Loss: 0.0278\n",
            "Epoch [155/200], Batch [500/750], Loss: 0.0127\n",
            "Epoch [155/200], Batch [600/750], Loss: 0.0168\n",
            "Epoch [155/200], Batch [700/750], Loss: 0.0686\n",
            "Epoch [155/200] Total train Cost: 22.034485610434785\n",
            "---------------------------------------------\n",
            "Epoch [156/200], Batch [100/750], Loss: 0.0184\n",
            "Epoch [156/200], Batch [200/750], Loss: 0.0183\n",
            "Epoch [156/200], Batch [300/750], Loss: 0.0144\n",
            "Epoch [156/200], Batch [400/750], Loss: 0.0145\n",
            "Epoch [156/200], Batch [500/750], Loss: 0.0272\n",
            "Epoch [156/200], Batch [600/750], Loss: 0.0607\n",
            "Epoch [156/200], Batch [700/750], Loss: 0.0216\n",
            "Epoch [156/200] Total train Cost: 21.822606213157997\n",
            "---------------------------------------------\n",
            "Epoch [157/200], Batch [100/750], Loss: 0.0088\n",
            "Epoch [157/200], Batch [200/750], Loss: 0.0812\n",
            "Epoch [157/200], Batch [300/750], Loss: 0.0462\n",
            "Epoch [157/200], Batch [400/750], Loss: 0.0197\n",
            "Epoch [157/200], Batch [500/750], Loss: 0.0122\n",
            "Epoch [157/200], Batch [600/750], Loss: 0.0296\n",
            "Epoch [157/200], Batch [700/750], Loss: 0.0706\n",
            "Epoch [157/200] Total train Cost: 21.554940023226663\n",
            "---------------------------------------------\n",
            "Epoch [158/200], Batch [100/750], Loss: 0.0742\n",
            "Epoch [158/200], Batch [200/750], Loss: 0.0128\n",
            "Epoch [158/200], Batch [300/750], Loss: 0.0156\n",
            "Epoch [158/200], Batch [400/750], Loss: 0.0313\n",
            "Epoch [158/200], Batch [500/750], Loss: 0.1172\n",
            "Epoch [158/200], Batch [600/750], Loss: 0.0544\n",
            "Epoch [158/200], Batch [700/750], Loss: 0.0279\n",
            "Epoch [158/200] Total train Cost: 21.424139274517074\n",
            "---------------------------------------------\n",
            "Epoch [159/200], Batch [100/750], Loss: 0.0236\n",
            "Epoch [159/200], Batch [200/750], Loss: 0.0089\n",
            "Epoch [159/200], Batch [300/750], Loss: 0.0072\n",
            "Epoch [159/200], Batch [400/750], Loss: 0.0438\n",
            "Epoch [159/200], Batch [500/750], Loss: 0.0245\n",
            "Epoch [159/200], Batch [600/750], Loss: 0.0108\n",
            "Epoch [159/200], Batch [700/750], Loss: 0.0389\n",
            "Epoch [159/200] Total train Cost: 21.242902046535164\n",
            "---------------------------------------------\n",
            "Epoch [160/200], Batch [100/750], Loss: 0.0225\n",
            "Epoch [160/200], Batch [200/750], Loss: 0.0123\n",
            "Epoch [160/200], Batch [300/750], Loss: 0.1254\n",
            "Epoch [160/200], Batch [400/750], Loss: 0.0232\n",
            "Epoch [160/200], Batch [500/750], Loss: 0.0340\n",
            "Epoch [160/200], Batch [600/750], Loss: 0.1381\n",
            "Epoch [160/200], Batch [700/750], Loss: 0.0171\n",
            "Epoch [160/200] Total train Cost: 21.043294705683365\n",
            "---------------------------------------------\n",
            "Epoch [161/200], Batch [100/750], Loss: 0.0114\n",
            "Epoch [161/200], Batch [200/750], Loss: 0.0114\n",
            "Epoch [161/200], Batch [300/750], Loss: 0.0247\n",
            "Epoch [161/200], Batch [400/750], Loss: 0.0205\n",
            "Epoch [161/200], Batch [500/750], Loss: 0.0199\n",
            "Epoch [161/200], Batch [600/750], Loss: 0.0773\n",
            "Epoch [161/200], Batch [700/750], Loss: 0.0050\n",
            "Epoch [161/200] Total train Cost: 20.877120376564562\n",
            "---------------------------------------------\n",
            "Epoch [162/200], Batch [100/750], Loss: 0.0264\n",
            "Epoch [162/200], Batch [200/750], Loss: 0.0982\n",
            "Epoch [162/200], Batch [300/750], Loss: 0.0373\n",
            "Epoch [162/200], Batch [400/750], Loss: 0.0178\n",
            "Epoch [162/200], Batch [500/750], Loss: 0.0162\n",
            "Epoch [162/200], Batch [600/750], Loss: 0.0082\n",
            "Epoch [162/200], Batch [700/750], Loss: 0.0206\n",
            "Epoch [162/200] Total train Cost: 20.6722586969845\n",
            "---------------------------------------------\n",
            "Epoch [163/200], Batch [100/750], Loss: 0.0125\n",
            "Epoch [163/200], Batch [200/750], Loss: 0.1305\n",
            "Epoch [163/200], Batch [300/750], Loss: 0.0115\n",
            "Epoch [163/200], Batch [400/750], Loss: 0.0083\n",
            "Epoch [163/200], Batch [500/750], Loss: 0.0230\n",
            "Epoch [163/200], Batch [600/750], Loss: 0.0161\n",
            "Epoch [163/200], Batch [700/750], Loss: 0.0976\n",
            "Epoch [163/200] Total train Cost: 20.48894188599661\n",
            "---------------------------------------------\n",
            "Epoch [164/200], Batch [100/750], Loss: 0.0221\n",
            "Epoch [164/200], Batch [200/750], Loss: 0.0168\n",
            "Epoch [164/200], Batch [300/750], Loss: 0.0040\n",
            "Epoch [164/200], Batch [400/750], Loss: 0.0378\n",
            "Epoch [164/200], Batch [500/750], Loss: 0.0118\n",
            "Epoch [164/200], Batch [600/750], Loss: 0.0262\n",
            "Epoch [164/200], Batch [700/750], Loss: 0.0287\n",
            "Epoch [164/200] Total train Cost: 20.304633361287415\n",
            "---------------------------------------------\n",
            "Epoch [165/200], Batch [100/750], Loss: 0.0133\n",
            "Epoch [165/200], Batch [200/750], Loss: 0.0218\n",
            "Epoch [165/200], Batch [300/750], Loss: 0.0272\n",
            "Epoch [165/200], Batch [400/750], Loss: 0.0074\n",
            "Epoch [165/200], Batch [500/750], Loss: 0.0230\n",
            "Epoch [165/200], Batch [600/750], Loss: 0.0254\n",
            "Epoch [165/200], Batch [700/750], Loss: 0.0222\n",
            "Epoch [165/200] Total train Cost: 20.12228586222045\n",
            "---------------------------------------------\n",
            "Epoch [166/200], Batch [100/750], Loss: 0.0232\n",
            "Epoch [166/200], Batch [200/750], Loss: 0.0249\n",
            "Epoch [166/200], Batch [300/750], Loss: 0.0284\n",
            "Epoch [166/200], Batch [400/750], Loss: 0.0125\n",
            "Epoch [166/200], Batch [500/750], Loss: 0.0111\n",
            "Epoch [166/200], Batch [600/750], Loss: 0.0209\n",
            "Epoch [166/200], Batch [700/750], Loss: 0.0354\n",
            "Epoch [166/200] Total train Cost: 19.971077667782083\n",
            "---------------------------------------------\n",
            "Epoch [167/200], Batch [100/750], Loss: 0.1250\n",
            "Epoch [167/200], Batch [200/750], Loss: 0.0708\n",
            "Epoch [167/200], Batch [300/750], Loss: 0.0147\n",
            "Epoch [167/200], Batch [400/750], Loss: 0.0145\n",
            "Epoch [167/200], Batch [500/750], Loss: 0.0359\n",
            "Epoch [167/200], Batch [600/750], Loss: 0.0167\n",
            "Epoch [167/200], Batch [700/750], Loss: 0.0104\n",
            "Epoch [167/200] Total train Cost: 19.794165403582156\n",
            "---------------------------------------------\n",
            "Epoch [168/200], Batch [100/750], Loss: 0.0370\n",
            "Epoch [168/200], Batch [200/750], Loss: 0.0478\n",
            "Epoch [168/200], Batch [300/750], Loss: 0.0228\n",
            "Epoch [168/200], Batch [400/750], Loss: 0.0236\n",
            "Epoch [168/200], Batch [500/750], Loss: 0.0146\n",
            "Epoch [168/200], Batch [600/750], Loss: 0.0159\n",
            "Epoch [168/200], Batch [700/750], Loss: 0.0163\n",
            "Epoch [168/200] Total train Cost: 19.64055443368852\n",
            "---------------------------------------------\n",
            "Epoch [169/200], Batch [100/750], Loss: 0.0242\n",
            "Epoch [169/200], Batch [200/750], Loss: 0.0306\n",
            "Epoch [169/200], Batch [300/750], Loss: 0.0131\n",
            "Epoch [169/200], Batch [400/750], Loss: 0.0314\n",
            "Epoch [169/200], Batch [500/750], Loss: 0.0083\n",
            "Epoch [169/200], Batch [600/750], Loss: 0.0114\n",
            "Epoch [169/200], Batch [700/750], Loss: 0.0153\n",
            "Epoch [169/200] Total train Cost: 19.42966121667996\n",
            "---------------------------------------------\n",
            "Epoch [170/200], Batch [100/750], Loss: 0.0165\n",
            "Epoch [170/200], Batch [200/750], Loss: 0.0167\n",
            "Epoch [170/200], Batch [300/750], Loss: 0.0794\n",
            "Epoch [170/200], Batch [400/750], Loss: 0.0210\n",
            "Epoch [170/200], Batch [500/750], Loss: 0.0104\n",
            "Epoch [170/200], Batch [600/750], Loss: 0.0092\n",
            "Epoch [170/200], Batch [700/750], Loss: 0.0059\n",
            "Epoch [170/200] Total train Cost: 19.278554175514728\n",
            "---------------------------------------------\n",
            "Epoch [171/200], Batch [100/750], Loss: 0.0321\n",
            "Epoch [171/200], Batch [200/750], Loss: 0.0246\n",
            "Epoch [171/200], Batch [300/750], Loss: 0.0389\n",
            "Epoch [171/200], Batch [400/750], Loss: 0.0402\n",
            "Epoch [171/200], Batch [500/750], Loss: 0.0355\n",
            "Epoch [171/200], Batch [600/750], Loss: 0.0155\n",
            "Epoch [171/200], Batch [700/750], Loss: 0.0136\n",
            "Epoch [171/200] Total train Cost: 19.08764840569347\n",
            "---------------------------------------------\n",
            "Epoch [172/200], Batch [100/750], Loss: 0.0111\n",
            "Epoch [172/200], Batch [200/750], Loss: 0.1024\n",
            "Epoch [172/200], Batch [300/750], Loss: 0.0144\n",
            "Epoch [172/200], Batch [400/750], Loss: 0.0162\n",
            "Epoch [172/200], Batch [500/750], Loss: 0.0278\n",
            "Epoch [172/200], Batch [600/750], Loss: 0.0072\n",
            "Epoch [172/200], Batch [700/750], Loss: 0.0402\n",
            "Epoch [172/200] Total train Cost: 18.923494937596843\n",
            "---------------------------------------------\n",
            "Epoch [173/200], Batch [100/750], Loss: 0.0094\n",
            "Epoch [173/200], Batch [200/750], Loss: 0.0236\n",
            "Epoch [173/200], Batch [300/750], Loss: 0.0096\n",
            "Epoch [173/200], Batch [400/750], Loss: 0.0305\n",
            "Epoch [173/200], Batch [500/750], Loss: 0.0247\n",
            "Epoch [173/200], Batch [600/750], Loss: 0.0276\n",
            "Epoch [173/200], Batch [700/750], Loss: 0.0270\n",
            "Epoch [173/200] Total train Cost: 18.79326777625829\n",
            "---------------------------------------------\n",
            "Epoch [174/200], Batch [100/750], Loss: 0.0100\n",
            "Epoch [174/200], Batch [200/750], Loss: 0.0443\n",
            "Epoch [174/200], Batch [300/750], Loss: 0.0646\n",
            "Epoch [174/200], Batch [400/750], Loss: 0.0205\n",
            "Epoch [174/200], Batch [500/750], Loss: 0.0178\n",
            "Epoch [174/200], Batch [600/750], Loss: 0.0145\n",
            "Epoch [174/200], Batch [700/750], Loss: 0.0237\n",
            "Epoch [174/200] Total train Cost: 18.63462995295413\n",
            "---------------------------------------------\n",
            "Epoch [175/200], Batch [100/750], Loss: 0.0203\n",
            "Epoch [175/200], Batch [200/750], Loss: 0.0301\n",
            "Epoch [175/200], Batch [300/750], Loss: 0.0112\n",
            "Epoch [175/200], Batch [400/750], Loss: 0.0198\n",
            "Epoch [175/200], Batch [500/750], Loss: 0.0294\n",
            "Epoch [175/200], Batch [600/750], Loss: 0.0193\n",
            "Epoch [175/200], Batch [700/750], Loss: 0.0495\n",
            "Epoch [175/200] Total train Cost: 18.474107378860936\n",
            "---------------------------------------------\n",
            "Epoch [176/200], Batch [100/750], Loss: 0.0941\n",
            "Epoch [176/200], Batch [200/750], Loss: 0.0077\n",
            "Epoch [176/200], Batch [300/750], Loss: 0.0219\n",
            "Epoch [176/200], Batch [400/750], Loss: 0.0495\n",
            "Epoch [176/200], Batch [500/750], Loss: 0.0494\n",
            "Epoch [176/200], Batch [600/750], Loss: 0.0084\n",
            "Epoch [176/200], Batch [700/750], Loss: 0.0208\n",
            "Epoch [176/200] Total train Cost: 18.31517717638053\n",
            "---------------------------------------------\n",
            "Epoch [177/200], Batch [100/750], Loss: 0.0136\n",
            "Epoch [177/200], Batch [200/750], Loss: 0.0478\n",
            "Epoch [177/200], Batch [300/750], Loss: 0.0080\n",
            "Epoch [177/200], Batch [400/750], Loss: 0.0306\n",
            "Epoch [177/200], Batch [500/750], Loss: 0.0331\n",
            "Epoch [177/200], Batch [600/750], Loss: 0.0203\n",
            "Epoch [177/200], Batch [700/750], Loss: 0.0337\n",
            "Epoch [177/200] Total train Cost: 18.161453880136833\n",
            "---------------------------------------------\n",
            "Epoch [178/200], Batch [100/750], Loss: 0.0275\n",
            "Epoch [178/200], Batch [200/750], Loss: 0.0701\n",
            "Epoch [178/200], Batch [300/750], Loss: 0.0213\n",
            "Epoch [178/200], Batch [400/750], Loss: 0.0863\n",
            "Epoch [178/200], Batch [500/750], Loss: 0.0145\n",
            "Epoch [178/200], Batch [600/750], Loss: 0.0096\n",
            "Epoch [178/200], Batch [700/750], Loss: 0.0414\n",
            "Epoch [178/200] Total train Cost: 18.015358864329755\n",
            "---------------------------------------------\n",
            "Epoch [179/200], Batch [100/750], Loss: 0.0093\n",
            "Epoch [179/200], Batch [200/750], Loss: 0.0145\n",
            "Epoch [179/200], Batch [300/750], Loss: 0.0345\n",
            "Epoch [179/200], Batch [400/750], Loss: 0.0178\n",
            "Epoch [179/200], Batch [500/750], Loss: 0.1163\n",
            "Epoch [179/200], Batch [600/750], Loss: 0.0691\n",
            "Epoch [179/200], Batch [700/750], Loss: 0.0243\n",
            "Epoch [179/200] Total train Cost: 17.86657846090384\n",
            "---------------------------------------------\n",
            "Epoch [180/200], Batch [100/750], Loss: 0.0236\n",
            "Epoch [180/200], Batch [200/750], Loss: 0.0099\n",
            "Epoch [180/200], Batch [300/750], Loss: 0.0673\n",
            "Epoch [180/200], Batch [400/750], Loss: 0.0154\n",
            "Epoch [180/200], Batch [500/750], Loss: 0.0174\n",
            "Epoch [180/200], Batch [600/750], Loss: 0.0104\n",
            "Epoch [180/200], Batch [700/750], Loss: 0.0055\n",
            "Epoch [180/200] Total train Cost: 17.714435929898173\n",
            "---------------------------------------------\n",
            "Epoch [181/200], Batch [100/750], Loss: 0.0230\n",
            "Epoch [181/200], Batch [200/750], Loss: 0.0372\n",
            "Epoch [181/200], Batch [300/750], Loss: 0.0493\n",
            "Epoch [181/200], Batch [400/750], Loss: 0.0636\n",
            "Epoch [181/200], Batch [500/750], Loss: 0.0095\n",
            "Epoch [181/200], Batch [600/750], Loss: 0.0082\n",
            "Epoch [181/200], Batch [700/750], Loss: 0.0100\n",
            "Epoch [181/200] Total train Cost: 17.576760163065046\n",
            "---------------------------------------------\n",
            "Epoch [182/200], Batch [100/750], Loss: 0.0079\n",
            "Epoch [182/200], Batch [200/750], Loss: 0.0405\n",
            "Epoch [182/200], Batch [300/750], Loss: 0.0102\n",
            "Epoch [182/200], Batch [400/750], Loss: 0.0112\n",
            "Epoch [182/200], Batch [500/750], Loss: 0.0199\n",
            "Epoch [182/200], Batch [600/750], Loss: 0.0171\n",
            "Epoch [182/200], Batch [700/750], Loss: 0.0699\n",
            "Epoch [182/200] Total train Cost: 17.402827543905005\n",
            "---------------------------------------------\n",
            "Epoch [183/200], Batch [100/750], Loss: 0.0105\n",
            "Epoch [183/200], Batch [200/750], Loss: 0.0069\n",
            "Epoch [183/200], Batch [300/750], Loss: 0.0165\n",
            "Epoch [183/200], Batch [400/750], Loss: 0.0122\n",
            "Epoch [183/200], Batch [500/750], Loss: 0.0124\n",
            "Epoch [183/200], Batch [600/750], Loss: 0.0180\n",
            "Epoch [183/200], Batch [700/750], Loss: 0.0285\n",
            "Epoch [183/200] Total train Cost: 17.289286793442443\n",
            "---------------------------------------------\n",
            "Epoch [184/200], Batch [100/750], Loss: 0.0263\n",
            "Epoch [184/200], Batch [200/750], Loss: 0.0094\n",
            "Epoch [184/200], Batch [300/750], Loss: 0.0472\n",
            "Epoch [184/200], Batch [400/750], Loss: 0.0251\n",
            "Epoch [184/200], Batch [500/750], Loss: 0.0856\n",
            "Epoch [184/200], Batch [600/750], Loss: 0.0157\n",
            "Epoch [184/200], Batch [700/750], Loss: 0.0167\n",
            "Epoch [184/200] Total train Cost: 17.143626738339663\n",
            "---------------------------------------------\n",
            "Epoch [185/200], Batch [100/750], Loss: 0.0112\n",
            "Epoch [185/200], Batch [200/750], Loss: 0.0143\n",
            "Epoch [185/200], Batch [300/750], Loss: 0.0220\n",
            "Epoch [185/200], Batch [400/750], Loss: 0.0092\n",
            "Epoch [185/200], Batch [500/750], Loss: 0.0154\n",
            "Epoch [185/200], Batch [600/750], Loss: 0.0261\n",
            "Epoch [185/200], Batch [700/750], Loss: 0.0078\n",
            "Epoch [185/200] Total train Cost: 16.996625894214958\n",
            "---------------------------------------------\n",
            "Epoch [186/200], Batch [100/750], Loss: 0.0273\n",
            "Epoch [186/200], Batch [200/750], Loss: 0.0200\n",
            "Epoch [186/200], Batch [300/750], Loss: 0.0105\n",
            "Epoch [186/200], Batch [400/750], Loss: 0.0250\n",
            "Epoch [186/200], Batch [500/750], Loss: 0.0165\n",
            "Epoch [186/200], Batch [600/750], Loss: 0.0115\n",
            "Epoch [186/200], Batch [700/750], Loss: 0.0094\n",
            "Epoch [186/200] Total train Cost: 16.882965627359226\n",
            "---------------------------------------------\n",
            "Epoch [187/200], Batch [100/750], Loss: 0.0142\n",
            "Epoch [187/200], Batch [200/750], Loss: 0.0188\n",
            "Epoch [187/200], Batch [300/750], Loss: 0.0390\n",
            "Epoch [187/200], Batch [400/750], Loss: 0.0045\n",
            "Epoch [187/200], Batch [500/750], Loss: 0.0083\n",
            "Epoch [187/200], Batch [600/750], Loss: 0.0195\n",
            "Epoch [187/200], Batch [700/750], Loss: 0.0088\n",
            "Epoch [187/200] Total train Cost: 16.713416278827935\n",
            "---------------------------------------------\n",
            "Epoch [188/200], Batch [100/750], Loss: 0.0183\n",
            "Epoch [188/200], Batch [200/750], Loss: 0.0258\n",
            "Epoch [188/200], Batch [300/750], Loss: 0.0173\n",
            "Epoch [188/200], Batch [400/750], Loss: 0.0063\n",
            "Epoch [188/200], Batch [500/750], Loss: 0.0087\n",
            "Epoch [188/200], Batch [600/750], Loss: 0.0112\n",
            "Epoch [188/200], Batch [700/750], Loss: 0.0053\n",
            "Epoch [188/200] Total train Cost: 16.603944523492828\n",
            "---------------------------------------------\n",
            "Epoch [189/200], Batch [100/750], Loss: 0.0429\n",
            "Epoch [189/200], Batch [200/750], Loss: 0.0254\n",
            "Epoch [189/200], Batch [300/750], Loss: 0.0106\n",
            "Epoch [189/200], Batch [400/750], Loss: 0.0113\n",
            "Epoch [189/200], Batch [500/750], Loss: 0.0316\n",
            "Epoch [189/200], Batch [600/750], Loss: 0.0234\n",
            "Epoch [189/200], Batch [700/750], Loss: 0.0298\n",
            "Epoch [189/200] Total train Cost: 16.425243796780705\n",
            "---------------------------------------------\n",
            "Epoch [190/200], Batch [100/750], Loss: 0.0184\n",
            "Epoch [190/200], Batch [200/750], Loss: 0.0744\n",
            "Epoch [190/200], Batch [300/750], Loss: 0.0349\n",
            "Epoch [190/200], Batch [400/750], Loss: 0.0169\n",
            "Epoch [190/200], Batch [500/750], Loss: 0.0237\n",
            "Epoch [190/200], Batch [600/750], Loss: 0.0101\n",
            "Epoch [190/200], Batch [700/750], Loss: 0.0221\n",
            "Epoch [190/200] Total train Cost: 16.326255032559857\n",
            "---------------------------------------------\n",
            "Epoch [191/200], Batch [100/750], Loss: 0.0330\n",
            "Epoch [191/200], Batch [200/750], Loss: 0.0052\n",
            "Epoch [191/200], Batch [300/750], Loss: 0.0406\n",
            "Epoch [191/200], Batch [400/750], Loss: 0.0068\n",
            "Epoch [191/200], Batch [500/750], Loss: 0.0087\n",
            "Epoch [191/200], Batch [600/750], Loss: 0.0179\n",
            "Epoch [191/200], Batch [700/750], Loss: 0.0118\n",
            "Epoch [191/200] Total train Cost: 16.189390974119306\n",
            "---------------------------------------------\n",
            "Epoch [192/200], Batch [100/750], Loss: 0.0134\n",
            "Epoch [192/200], Batch [200/750], Loss: 0.0291\n",
            "Epoch [192/200], Batch [300/750], Loss: 0.0241\n",
            "Epoch [192/200], Batch [400/750], Loss: 0.0426\n",
            "Epoch [192/200], Batch [500/750], Loss: 0.0142\n",
            "Epoch [192/200], Batch [600/750], Loss: 0.0083\n",
            "Epoch [192/200], Batch [700/750], Loss: 0.0203\n",
            "Epoch [192/200] Total train Cost: 16.044937280472368\n",
            "---------------------------------------------\n",
            "Epoch [193/200], Batch [100/750], Loss: 0.0274\n",
            "Epoch [193/200], Batch [200/750], Loss: 0.0250\n",
            "Epoch [193/200], Batch [300/750], Loss: 0.0187\n",
            "Epoch [193/200], Batch [400/750], Loss: 0.0107\n",
            "Epoch [193/200], Batch [500/750], Loss: 0.0143\n",
            "Epoch [193/200], Batch [600/750], Loss: 0.0163\n",
            "Epoch [193/200], Batch [700/750], Loss: 0.0281\n",
            "Epoch [193/200] Total train Cost: 15.938522614073008\n",
            "---------------------------------------------\n",
            "Epoch [194/200], Batch [100/750], Loss: 0.0214\n",
            "Epoch [194/200], Batch [200/750], Loss: 0.0119\n",
            "Epoch [194/200], Batch [300/750], Loss: 0.0253\n",
            "Epoch [194/200], Batch [400/750], Loss: 0.0208\n",
            "Epoch [194/200], Batch [500/750], Loss: 0.0251\n",
            "Epoch [194/200], Batch [600/750], Loss: 0.0103\n",
            "Epoch [194/200], Batch [700/750], Loss: 0.0564\n",
            "Epoch [194/200] Total train Cost: 15.804887834354304\n",
            "---------------------------------------------\n",
            "Epoch [195/200], Batch [100/750], Loss: 0.0094\n",
            "Epoch [195/200], Batch [200/750], Loss: 0.0107\n",
            "Epoch [195/200], Batch [300/750], Loss: 0.0052\n",
            "Epoch [195/200], Batch [400/750], Loss: 0.0306\n",
            "Epoch [195/200], Batch [500/750], Loss: 0.0169\n",
            "Epoch [195/200], Batch [600/750], Loss: 0.0113\n",
            "Epoch [195/200], Batch [700/750], Loss: 0.0242\n",
            "Epoch [195/200] Total train Cost: 15.687498617451638\n",
            "---------------------------------------------\n",
            "Epoch [196/200], Batch [100/750], Loss: 0.0154\n",
            "Epoch [196/200], Batch [200/750], Loss: 0.0038\n",
            "Epoch [196/200], Batch [300/750], Loss: 0.0157\n",
            "Epoch [196/200], Batch [400/750], Loss: 0.0501\n",
            "Epoch [196/200], Batch [500/750], Loss: 0.0104\n",
            "Epoch [196/200], Batch [600/750], Loss: 0.0098\n",
            "Epoch [196/200], Batch [700/750], Loss: 0.0593\n",
            "Epoch [196/200] Total train Cost: 15.551935001160018\n",
            "---------------------------------------------\n",
            "Epoch [197/200], Batch [100/750], Loss: 0.0082\n",
            "Epoch [197/200], Batch [200/750], Loss: 0.0244\n",
            "Epoch [197/200], Batch [300/750], Loss: 0.0324\n",
            "Epoch [197/200], Batch [400/750], Loss: 0.0152\n",
            "Epoch [197/200], Batch [500/750], Loss: 0.0418\n",
            "Epoch [197/200], Batch [600/750], Loss: 0.0178\n",
            "Epoch [197/200], Batch [700/750], Loss: 0.0109\n",
            "Epoch [197/200] Total train Cost: 15.455838414491154\n",
            "---------------------------------------------\n",
            "Epoch [198/200], Batch [100/750], Loss: 0.0150\n",
            "Epoch [198/200], Batch [200/750], Loss: 0.0093\n",
            "Epoch [198/200], Batch [300/750], Loss: 0.0393\n",
            "Epoch [198/200], Batch [400/750], Loss: 0.0211\n",
            "Epoch [198/200], Batch [500/750], Loss: 0.0167\n",
            "Epoch [198/200], Batch [600/750], Loss: 0.0270\n",
            "Epoch [198/200], Batch [700/750], Loss: 0.0146\n",
            "Epoch [198/200] Total train Cost: 15.31919709034264\n",
            "---------------------------------------------\n",
            "Epoch [199/200], Batch [100/750], Loss: 0.0260\n",
            "Epoch [199/200], Batch [200/750], Loss: 0.0066\n",
            "Epoch [199/200], Batch [300/750], Loss: 0.0264\n",
            "Epoch [199/200], Batch [400/750], Loss: 0.0096\n",
            "Epoch [199/200], Batch [500/750], Loss: 0.0180\n",
            "Epoch [199/200], Batch [600/750], Loss: 0.0117\n",
            "Epoch [199/200], Batch [700/750], Loss: 0.0165\n",
            "Epoch [199/200] Total train Cost: 15.182223603827879\n",
            "---------------------------------------------\n",
            "Epoch [200/200], Batch [100/750], Loss: 0.0185\n",
            "Epoch [200/200], Batch [200/750], Loss: 0.0382\n",
            "Epoch [200/200], Batch [300/750], Loss: 0.0119\n",
            "Epoch [200/200], Batch [400/750], Loss: 0.0091\n",
            "Epoch [200/200], Batch [500/750], Loss: 0.0074\n",
            "Epoch [200/200], Batch [600/750], Loss: 0.0215\n",
            "Epoch [200/200], Batch [700/750], Loss: 0.0250\n",
            "Epoch [200/200] Total train Cost: 15.070394722977653\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.01\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = MNIST_Neural_Network(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_batches = len(train_loader)\n",
        "\n",
        "batch_loss_list = []\n",
        "epoch_loss_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    current_loss = 0.\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_loss_list.append(loss.item())\n",
        "        current_loss += loss.item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{n_total_batches}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    epoch_loss_list.append(current_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}] Total train Cost: {current_loss}')\n",
        "    print(\"-\" * 45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "jCpcg4FITdXy",
        "outputId": "d2cf5240-f30b-450c-96bd-2402f5e37b51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Epoch Loss')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "ax[0].plot(range(len(batch_loss_list)), (batch_loss_list), label='Batch Loss')\n",
        "ax[0].set_xlabel('Iterations')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].set_title('Batch Loss')\n",
        "\n",
        "ax[1].plot(range(len(epoch_loss_list)), (epoch_loss_list), label='Epoch Loss')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_title('Epoch Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Xk2Z4UpQbX"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "\n",
        "for i, (images, labels) in enumerate(val_loader):\n",
        "  # origin shape: [100, 1, 28, 28]\n",
        "  # resized: [100, 784]\n",
        "  images = images.reshape(-1, 28*28).to(device)\n",
        "  labels = labels.to(device)\n",
        "  with torch.no_grad():\n",
        "  # Forward pass\n",
        "    outputs = model(images)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  predictions.append(predicted)\n",
        "\n",
        "predictions = torch.cat(predictions, dim=0).to(torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFq6a2dNqEQy"
      },
      "outputs": [],
      "source": [
        "val_labels = []\n",
        "for i, (images, labels) in enumerate(val_loader):\n",
        "  val_labels.extend(labels.tolist())\n",
        "actual_values = torch.tensor(val_labels, dtype=torch.float64).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "y_true = actual_values.detach().cpu().numpy()\n",
        "y_pred = predictions.detach().cpu().numpy()\n",
        "\n",
        "print(\"Accuracy Score:\")\n",
        "print(accuracy_score(y_true, y_pred))\n",
        "\n",
        "print(\"Classification report:\")\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RqXcPO_Uhaq",
        "outputId": "a8cd04e8-fac9-47bf-c100-52add5ab58e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score:\n",
            "0.9760833333333333\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.99      1169\n",
            "         1.0       0.98      0.99      0.99      1328\n",
            "         2.0       0.97      0.97      0.97      1181\n",
            "         3.0       0.97      0.97      0.97      1136\n",
            "         4.0       0.97      0.97      0.97      1217\n",
            "         5.0       0.98      0.97      0.97      1123\n",
            "         6.0       0.98      0.99      0.98      1208\n",
            "         7.0       0.98      0.97      0.98      1269\n",
            "         8.0       0.98      0.97      0.98      1194\n",
            "         9.0       0.96      0.97      0.97      1175\n",
            "\n",
            "    accuracy                           0.98     12000\n",
            "   macro avg       0.98      0.98      0.98     12000\n",
            "weighted avg       0.98      0.98      0.98     12000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bài 3:\n",
        "\n",
        "Why softmax use exponential instead of numerical number ??\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Monotonically increasing — To ensure that larger inputs are mapped to larger outputs.\n",
        "Non-negative outputs — Because probability values must be non-negative.\n",
        "The outputs should sum to one — This can be achieved by simply dividing each element of the output by the sum of all elements of the output.\n",
        "The derivative of exponential is still exponential"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
